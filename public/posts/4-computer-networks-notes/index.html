<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>CS6250 - Computer Networks - Notes | Nathan Embaugh | codetrails</title>
<meta name="keywords" content="school, OMSCS, Computer Networks, notes">
<meta name="description" content="My notes on Computer Networks from Georgia Tech&rsquo;s OMSCS.">
<meta name="author" content="Nathan Embaugh">
<link rel="canonical" href="https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/">
<link crossorigin="anonymous" href="/codetrails/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://nathanemb.github.io/codetrails/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://nathanemb.github.io/codetrails/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://nathanemb.github.io/codetrails/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://nathanemb.github.io/codetrails/apple-touch-icon.png">
<link rel="mask-icon" href="https://nathanemb.github.io/codetrails/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-TR2MH8J8BF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TR2MH8J8BF');
        }
      </script><meta property="og:url" content="https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/">
  <meta property="og:site_name" content="Nathan Embaugh | codetrails">
  <meta property="og:title" content="CS6250 - Computer Networks - Notes">
  <meta property="og:description" content="My notes on Computer Networks from Georgia Tech’s OMSCS.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-05-24T20:48:59-04:00">
    <meta property="article:modified_time" content="2025-05-24T20:48:59-04:00">
    <meta property="article:tag" content="School">
    <meta property="article:tag" content="OMSCS">
    <meta property="article:tag" content="Computer Networks">
    <meta property="article:tag" content="Notes">
    <meta property="og:image" content="https://nathanemb.github.io/codetrails/osi_model_7_layers.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://nathanemb.github.io/codetrails/osi_model_7_layers.png">
<meta name="twitter:title" content="CS6250 - Computer Networks - Notes">
<meta name="twitter:description" content="My notes on Computer Networks from Georgia Tech&rsquo;s OMSCS.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://nathanemb.github.io/codetrails/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "CS6250 - Computer Networks - Notes",
      "item": "https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "CS6250 - Computer Networks - Notes",
  "name": "CS6250 - Computer Networks - Notes",
  "description": "My notes on Computer Networks from Georgia Tech\u0026rsquo;s OMSCS.",
  "keywords": [
    "school", "OMSCS", "Computer Networks", "notes"
  ],
  "articleBody": "Lesson 1 - Introduction, History, and Internet Architecture History of the internet The internet began as many things in tech did, from DARPA.\nSpecifically:\nJ.C.R. Licklider proposed the “Galactic Network” (1962) Attached a computer in Stanford to a computer at MIT, thus beginning computers talking to each other The ARPANET (1969) UCSB, UCLA, Stanford, and U of Utah interlink Network Control Protocol (NCP), an initial ARPANET host-to-host protocol (1970) The first protocol was designed to handle increasing number of computers, first app built on this was email Inter-networking and TCP/IP (1973) NCP became TCP/IP, IP for addressing and forwarding packets, TCP for flow control and recovery from lost packets The Domain Name System (DNS) (1983) and the World Wide Web (WWW) (1990) As the internet exploded with content and endpoints, they needed a way to turn domains into IP addresses. In walks DNS. Internet Architecture The internet was built in layers. Each layer is supposed to have its own job, and not rely on any of the layers above or below it.\nThink of a person as a bit of data, then watch them fly from one airport to another and you get the idea.\nSo there is an originally designed theoretical layer named the OSI model, which had 7 layers, and then the layers that were actually implemented, known as the Internet Protocol Stack.\nThese layers are not as perfect as we would hope, specifically sometimes they do rely on the other layers or they both have methods of solving the same problem like error recovery.\nNotice that the Session and Presentation layers disappear in the Internet Protocol Stack, those are handled in the ports of each network device. The logic that is accomplished in those layers still happens, just all in one place.\nApplication Layer The data here is a message.\nThis is the layer we all interact with all the time.\nHTTP (web) SMTP (e-mail) FTP (transfers files between two end hosts) DNS (translates domain names to IP addresses) Takes the content that we want to ship around, and does all the encoding and decoding needed to actually USE it.\nThe Presentation Layer The presentation layer plays the intermediate role of formatting the information that it receives from the layer below and delivering it to the application layer. For example, some functionalities of this layer are formatting a video stream or translating integers from big endian to little endian format.\nThe Session Layer The session layer is responsible for the mechanism that manages the different transport streams that belong to the same session between end-user application processes. For example, in the case of a teleconference application, it is responsible to tie together the audio stream and the video stream.\nThe Transport Layer The data here is a segment.\nEnd to End communication between hosts.\nTransmission Control Protocol (TCP) User Datagram Protocol (UDP) TCP is better connection-oriented services, guarantees delivery, manages flow control, and controls congestion. This is the USPS, slow but reliable (except TCP doesn’t lose mail like the USPS).\nUDP is fast and guarantees nothing. Receivers and Senders using UDP must be able to handle segments getting dropped, delayed, or not making it entirely. But they should be faster when everything is working compared to TCP.\nThe Network Layer The data here is a datagram.\nThis is where IP comes into play. This layer is responsible for connecting one computer to another, via the IP address that everyone has.\nThe Data Link Layer The data here is a frame.\nThis layer is responsible for moving the frames from one node (host or router/switch) to the next node. This uses things like:\nEthernet Point-to-point Protocol (PPP) Wi-Fi The Physical Layer The actual hardware translation. Translating electricity into bits based on ethernet, coax, fiber, etc.\nEncapsulation These layers work on the idea of encapsulation and de-encapsulation. So encapsulation is to take a chunk of data, package it up, add a header to it and pass it on. Then de-encapsulation is using the headers to decode each chunk of data, until all you’re left with is the data/message.\nThis method is what allows people to build upon the existing infrastructure of the internet, but still make new things.\nThe End to End (e2e) Principle The e2e principle shaped the internet as we know it today.\nEssentially the principle is that 99% of the complexity should be at the ends of the communications. This allows the underlying infrastructure to be simple, but expandable, and allows people working at the different ends to iterate and create new things quickly.\nIf they had to change the underlying architecture every time they wanted to change anything it would bring development speed to a crawl.\nBeneficial excerpt from the lecture:\nMany people argue that the e2e principle allowed the internet to grow rapidly because evolving innovation took place at the network edge, in the form of numerous applications and a plethora of services, rather than in the middle of the network, which could be hard to modify later.\nWhat were the designers’ original goals that led to the e2e principle?\nMoving functions and services closer to the applications that use them increases the flexibility and the autonomy of the application designer to offer these services to the needs of the specific application.\nThus, the higher-level protocol layers are more specific to an application. Whereas the lower-level protocol layers are free to organize the lower-level network resources to achieve application design goals more efficiently and independently of the specific application.\nViolations of e2e All rules are meant to be broken.\nFirewalls, NAT boxes, and traffic filters all break the e2e principle, and usually for good reason.\nNAT routers provide a way to make up for the fact that there aren’t that many IP addresses available in IPv4. Instead of EVERY device having its own worldwide public IP address, you give your home 1 IP address, and then every device behind that has its own local address.\nThis means that whenever a message is sent to your PC it goes:\nWeb \u003e Router (Public IP)\u003e End Device (local IP)\nThe router is breaking some rules of e2e, because it is intervening and inspecting data.\nThis is the notes’ reasoning for why:\nWhy do NAT boxes violate the e2e principle? The hosts behind NAT boxes are not globally addressable or routable. As a result, it is not possible for other hosts on the public Internet to initiate connections to these devices. So, if we have a host behind a NAT and a host on the public Internet, they cannot communicate by default without the intervention of a NAT box. Some workarounds allow hosts to initiate connections to hosts that exist behind NATs. For example, Session Traversal Utilities for NAT, or STUN, is a tool that enables hosts to discover NATs and the public IP address and port number that the NAT has allocated for the applications for which the host wants to communicate. Also, UDP hole punching establishes bidirectional UDP connections between hosts behind NATs.\nThe Hourglass Shape of the Internet The internet is curvy.\nNo really, there’s a ton on each end of it, but the middle is pretty narrow. Specifically, TCP, UDP, IP are really the backbone of literally everything. See below:\nAll roads lead to IP, and TCP/UDP. Researchers have actually done a lot of work to see why this is. They called it the evolutionary architecture model. They did a bunch of in depth quantifications of why/what the internet is and how they got there and drew some interesting conclusions.\nIn an ideal world where we could do it all over they came up with the following:\nFinally, in terms of future and entirely new Internet architectures, the EvoArch model predicts that even if these brand-new architectures do not have the shape of an hourglass initially, they will probably do so as they evolve, which will lead to new ossified protocols. The model suggests that one way to proactively avoid these ossification effects that we now experience with TCP/IP is for a network architect to design the functionality of each layer so that the waist is wider, consisting of several protocols that offer largely non-overlapping but general services, so that they do not compete with each other.\nInterconnecting Hosts and Networks Talking about how to theoretically communicate between computers is important, but hardware actually makes the physical connections.\nThose are:\nRepeaters and Hubs They operate on the physical layer (L1) as they receive and forward digital signals to connect different Ethernet segments. They provide connectivity between hosts that are directly connected (in the same network). The advantage is that they are simple and inexpensive devices, and they can be arranged in a hierarchy. Unfortunately, hosts that are connected through these devices belong to the same collision domain, meaning that they compete for access to the same link.\nBridges and Layer-2 Switches These devices can enable communication between hosts that are not directly connected. They operate on the data link layer (L2) based on MAC addresses. They receive packets and forward them to the appropriate destination. A limitation is the finite bandwidth of the outputs. If the arrival rate of the traffic is higher than the capacity of the outputs, then packets are temporarily stored in buffers. But if the buffer space gets full, then this can lead to packet drops.\nRouters and Layer-3 Switches These are devices that operate on the network layer (L3).\nLearning Bridges A bridge is a piece of hardware that manages the connection between many devices, connected to the same piece of hardware.\nThe bridge is able to understand what devices are on port 1, what devices are on port 2, and so on. This is like a home network switch. You can connect many devices to it, and it handles knowing where the data needs to end up.\nThe Looping Problem The problem with these bridges, is that you can create a loop.\nif A connects to B which connects to C which connects to A, you’ve created a loop. This can result in never ending looping!\nThis is handled by running a spanning tree algorithm. The goal of the spanning tree algorithm is to identify which ports when used will eliminate any endless looping.\nThis works by operating in rounds, and then by removing bridges from the network until you only have one path to every node. This is accomplished by running in rounds the following process:\nEvery node sends: Sender Node ID Root ID as perceived by sender Distance from root node Each node selects the best configuration in order of If root of the one configuration has a smaller ID If roots have equal IDs choose one with smaller distance to the root If they have the same distance, choose configuration with smallest sender ID A node stops sending configuration messages over a link (port) when it receives a configuration message from a neighbor that is: either closer to the root has the same distance from the root, but it has a smaller ID. We can see this process completed in the following images:\nThen after tree spanning:\nLesson 2 - The Transport Layer (TCP) This lesson is going to talk about the actual protocol responsible for transporting data from one location to another, TCP. The logical connection between two hosts is done in the transport layer.\nThe transport layer receives a message from the application layer and appends its own header on to it. This is known as a segment. The segment is then sent to the Network layer where it happily bounces through all the routers, bridges, and switches that might be on its path.\nTransport Layer intro Why do we need a transport layer? Why not just send messages directly from the application layer to the network layer? Because the network layer guarantees nothing. The transport layer guarantees delivery, and data integrity in a way that wouldn’t have been done otherwise.\nAs mentioned previously there are two main transport layer protocols User Datagram Protocol (UDP) and Transmission Control Protocol (TCP).\nUDP just tries to quickly send data, and doesn’t do much else. As such it provides no guarantees and puts the responsibility on the application layer to do things like verify integrity and handle dropped messages.\nTCP on the other hand does have these extra bells and whistles built in and thus it is much more reliable, if not a tad slower than UDP.\nMultiplexing Multiplexing is the ability for many hosts to use the same network simultaneously. Consider two computers browsing the internet at the same time, or better yet, a computer that is simultaneously browsing the internet and streaming music, it has two incoming data sources, and used in two different ways.\nWe need to be able to handle this complexity. The Transport layer uses ports to do this. Each application gets one port, and listens only to that port.\nThere is Connectionless and Connection Oriented multiplexing. One based on a constant connection, and one is not.\nWe have names for each direction of this multiplexing operation.\nDemultiplexing - Delivering data to the appropriate socket.\nMultiplexing - Taking data from all the sockets and putting it into the network layer.\nConnectionless Multiplexing Connectionless multiplexing is the simpler case. The transport layer has a segment which has the content, a source and source port, and a destination and a destination port. It receives the data from the source port, and makes its best effort at delivering to the destination port.\nIf the destination receives it, great, the network layer will route it to the correct port, and then the message will have been successfully delivered.\nThese are UDP sockets. It’s very direct, with no oversight as to what actually happens to the message.\nConnection Oriented Multiplexing Connection Oriented multiplexing brings in a lot more complexity.\nTCP requires going through a TCP server. The TCP server has a listener process that waits for incoming connection requests, and when it gets it handles setting everything up so that the destination is ready to receive the message.\nNote: If a server has many clients contacting it on the same port, it’s not an issue because they have unique IP addresses (hopefully) and they can distinguish the difference between the two that way.\nA word on UDP UDP lacks reliability of TCP mainly because it doesn’t require establishing a connection.\nThat lack of reliability makes it better for the following reasons:\nNo congestion control - No process watches every packet to make sure it should be sent No connection management - We don’t have to wait for a socket to be opened, so it just sends quickly Both of these result in lower latency transmission, which is good for some things. Things like multiplayer video games, DNS servers, and other networking hosts, all like to use higher speed protocols.\nThis puts the onus on the developers on each end to ensure quality, and handle if errors occur, but when things are working well, then things are very speedy.\nThe one quality mechanism UDP provides is a checksum, so you can in fact check that the data that’s sent is what it was supposed to be. It creates a checksum by adding together the bits of the source port, destination port and the length of the packet. It then performs a ones complement. That is the checksum.\nThe receiver takes the source port, destination port, length of packet, and the checksum and adds them all together. Because the checksum is the ones complement, when they are added together it should end up as all ones.\nTCP Three way handshake Step 1: The TCP client sends a special segment (containing no data) with the SYN bit set to 1. The client also generates an initial sequence number (client_isn) and includes it in this special TCP SYN segment. Step 2: The server, upon receiving this packet, allocates the required resources for the connection and sends back the special “connection-granted” segment which we call SYNACK segment. This packet has the SYN bit set to 1, the acknowledgement field of the TCP segment header set to client_isn+1, and a randomly chosen initial sequence number (server_isn) for the server.\nStep 3: When the client receives the SYNACK segment, it also allocates buffer and resources for the connection and sends an acknowledgment with SYN bit set to 0.\nConnection tear down Connection Teardown\nStep 1: When the client wants to end the connection, it sends a segment with FIN bit set to 1 to the server.\nStep 2: The server acknowledges that it has received the connection closing request and is now working on closing the connection.\nStep 3: The server then sends a segment with FIN bit set to 1, indicating that connection is closed.\nStep 4: The client sends an ACK for it to the server. It also waits for some time to resend this acknowledgment in case the first ACK segment is lost.\nReliable Transmission (TCP) TCP guarantees all packets delivered in order. This is a very helpful reliability for developers to build on.\nTo do this the sender must know what the receiver successfully got. This is accomplished via ARQ (Automatic Repeat Request). If a sender doesn’t get a message that ARQ1 was received in a certain timeframe, then it will re-send it.\nStop and Wait ARQ\nGuess how long it should take, if you don’t get a response, send it again. This can work but is tricky. If you send too much you’re retransmitting for no reason, and wait too long your connection is slow.\nTCP uses Selective ACK which basically waits for the receiver to say hey I didn’t get this packet yet, and if it reaches a certain threshold like 3, then it will quickly resend that particular packet. This allows most of the time to be spent actively sending data, and the ability to recover from dropped packets.\nThis does require the ability to buffer packets until you have everything you need in order.\nTransmission Control (TCP) Deciding how much of a link bandwidth to use is a bit complicated. If you send too much for the receiver that could be an issue, or maybe the network can’t handle it, or any other amount of things that could go wrong.\nSo TCP implements a couple things to help that.\nFlow Control Flow control is where TCP tries to identify the receiver’s buffer that it is receiving data with, and tries to match the sender window size to that. Every ACK message includes a rwnd value which says how much buffer space is available.\nThe sender uses this value to ensure it never sends more bytes than is available in the receiver buffer.\nIf this value hits zero it would stop, but TCP instead sends packets of 1 byte until it gets a response with a rwnd greater than zero.\nCongestion Control Congestion control is making sure we don’t overload any of the links on the way from one host to another.\nGood congestion control is:\nEfficient - use most of the network Fair - everyone gets equal amounts Low delay - Low delay is good for things that need to have small lag like video conferences Fast convergence - everyone gets their bandwidth quickly Network Assisted Network assisted congestion control relies on pieces of the network sending feedback about what’s happening. This could fail when the network is heavily congested though, kind of rendering it useless.\nEnd to End End to end congestion control gets nothing from the network and instead infers congestion from the hosts. This supports the general principle of making the complexity be at the ends of the networks.\nThis is mostly done via packet delay (how long did it take to get here) and packet loss (how many times do I need to resend). With these two things you have a rough understanding of network performance at any given moment.\nIt employs a congestion window, a number indicating roughly how much space is left in the network. This increases until congestion is detected, and then the window is made smaller to reduce congestion.\nUltimately the max size of a TCP packet is the minimum of the receiver buffer and the congestion window.\nThere are many different methods of increasing congestion window size:\nAdditive Multiplicative TCP Reno AIMD Many of these employ “Slow start” where they start at a low-ish speed and ramp up. This protects from overwhelming the network right at the start. With timeouts or dropped connections being common you can see why this would be useful.\nTCP isn’t always fair, but using some of these congestion methods will do a pretty good job of it.\nTCP Throughput TCP Throughput looks like a sawtooth because of these congestion control mechanisms.\nIt gets up to the limit, then drops off, then gets up to the limit then drops off.\nLesson 3 - Intradomain Routing (The Network Layer) This session focuses on the act of routing on the network layer in a single domain. Ideally we understand what it takes for two hosts to share data by the end of this.\nWe’ll talk about:\nIntradomain Routing Algorithms Link state Distance vector Intradomain Protocols Open Shortest Path First (OSPF) Routing Information Protocol (RIP) Routing Given two hosts that share the same default router (first-hop router) we know that one host will send a packet to the default router, but what happens next?\nIn a network with many routers, whenever a router receives a packet, it must consult the forwarding table it maintains, and send the packet to the next router in line. This is referred to as forwarding and is not necessarily the same as routing.\nRouting is the act of determining the best path to be traveled from one location to another. Intradomain routing is what we will focus on and it is what happens when both hosts are in the same administrative domain.\nInterior Gateway Protocols (IGP) are what handle this type of routing. The two major types we’ll cover are link-state and distance-vector routing algorithms. They are graph theory algorithms with edges and nodes.\nLink State Routing Surprise, Dijkstra’s algorithm is here again.\nIn link state, all link costs are known and the network topology is also fully known.\nFrom the lecture directly.\nLet’s introduce some basic terminology. By u, we represent our source node. By v, we represent every other node in the network. By D(v), we represent the cost of the current least cost path from u to v. By p(v), we represent the previous node along the current least cost path from u to v. By c(u,v), we represent the cost from u to directly attached neighbor v. By N’, we represent the subset of nodes along the current least-cost path from u to v.\nBasically we initialize with either:\nKnown cost because it’s a link directly connected to the node we’re initializing Infinity cost, because we know it will be less than that but we have something to compare against Then we continue looping through the network, looking for a path with lower costs than our current cost, until we don’t find one. This is a fun application of Dijkstra’s algorithm, where each router essentially computes Dijkstra’s algorithm from itself to all other routers in the network.\nThis is a pretty costly algorithm at O(n^2) complexity. It also requires that you know everything about the network which is probably why this is intradomain and not interdomain.\nDistance Vector Routing The DV algorithm is iterative, asynchronous, and distributed.\nDV is based on the Bellman Ford algorithm. Every node maintains a distance vector to all of the other nodes, and it occasionally shares that information. When a node receives a new distance vector they use it to update their own vector.\nThe Bellman Ford (BF) equation is the heart of each update: Dx(y) = minv{c(x,v) + Dv(y)}\nSee the pseudocode below:\nSo essentially, continuously the nodes maintain a list of costs for routes to certain nodes, and these costs are updated whenever nodes send their costs. So instead of every node needing to know every cost, it allows the nodes to only know and focus on the costs of its immediate neighbors, and then relies on other nodes sending its current list of costs occasionally.\nThis is different from Link State routing because it is distributed, but they are all still computing the most efficient path through the tree.\nA simple example initialization\nPitfalls of DV What if the link cost changes? In some cases this is handled quickly, and in other cases it can lead to a “count-to-infinity” problem.\nSay a link cost decreases:\nAt time t0, y detects that cost to x has changed from 4 to 1, so it updates its distance vector and sends it to its neighbors. At time t1, z receives the update from y. Now z thinks it can reach x through y with a cost of 2, so it sends its new distance vector to its neighbors. At time t2, y receives the update from z. Y does not change its distance vector, so it does not send any update. The update is fully propagated pretty quickly.\nSay a link cost increases:\nAt t0, y detects that the cost has changed, and now it will update its distance vector thinking that it can still reach x through z with a total cost of 5+1=6. At t1, we have a routing loop where z thinks it can reach x through y, and y thinks it can reach x through z. This will cause the packets to be bouncing back and forth between y and z until their tables change. Nodes z and y keep updating each other about their new cost to reach x. For example, y computes its new cost to be 6 and then informs z. Then z computes its new cost to be 7, and then informs y, and so on. The key here is that Node Z, is saying Hey I can definitely reach X, and the cost as Z knows it, is 5. So Node Y says sweet, if I go through Node Z, it’s the cost of our link (1) + the cost of Z \u003e X, but the cost of Z \u003e X isn’t actually 5 anymore, it’s 50.\nSo they have to iterate until the cost is greater than 50, at which point it will use the real path.\nThe reason that we can’t directly say, “hey no the link cost increased by a ton your table is wrong” is because we don’t know the structure of the network. All we know is X \u003e Y costs a certain value, with no understanding of which links do that.\nSo instead we have to keep iterating through until the costs are actually updated. This can create a lot of packet bouncing.\nThis is solved by something called poison reverse where a node says a cost is infinity if it isn’t the cheapest path to a certain node. This only works for 2 nodes.\nRouting Information Protocol (RIP) RIP is based on Distance Vectors, but instead of maintaining vectors of distances, they instead maintain entire routing tables with one row for each subnet.\nOpen Shortest Path First OSPF is a routing protocol that uses link-state to find the best path between source and destination routers. It was created after RIP by ISPs with extra things like authentication messages, multiple same-cost paths, and support for hierarchical routing within a single domain.\nOSPF will have one AS (Autonomous System) as the backbone, and routes to other OSPF AS on the network. To go from one Area to another, they must move through the backbone router.\nThere’s a lot more in the notes but tbh they’re pretty complicated! It seems that these routers in the send Link State advertisements which communicates the routers local topology. This results in a complete network map, that updates when the network updates.\nThese LSAs are processed as so:\nHot Potato Routing Sometimes you have to leave your local network, and enter into interdomain routing.\nTo do this usually you have to find an egress point and the process of finding that egress point is an intradomain routing problem.\nGenerally hot potato routing is referring to finding the closest/least costly egress point in a given network. The hot potato part of it is that there are many egress points and which one is chosen is not always clear. This routing method of finding the shortest path does make things consistent instead of sometimes going to egress A and sometimes going to egress B.\nLesson 4 - Interdomain Routing and AS Relationships Lesson 3 focused on intradomain routing, but what about when we need to leave our domain?\nThe internet is an ecosystem of thousands if not millions of networks operated independently, but still connected to each other. This lesson we’ll learn about BGP.\nThe Internet The internet started very hierarchical but has been flattening as more IXPs and CDNs have been added.\nEach of the types of infrastructure above can be an Autonomous System (AS) which is a group of routers who are under the same authority. I think like, my house technically is an AS that I manage, but not sure about that.\nRouting between AS’s relies on Border Gateway Protocol (BGP) to exchange information with each other.\nAS Ecosystem There’s two main interactions between AS’s.\nProvider-Customer - Like me paying my ISP for internet Peer - One ISP routing to another ISP because they need their network to get to location x. This requires traffic levels to be pretty similar so that one party isn’t gaining more than the other. See how green cloud ISP can’t peer with orange cloud ISPs, because it’s too large. But all the orange cloud ISPs are peer relationships because they’re similarly sized.\nProviders can charge fixed rate or based on usage, totally up to them.\nInternet Business Importing and Exporting routes is the heart of BGP. Deciding which import/exports to operate and make available is a technical and business decision.\nExporting Routes Export routes come from:\nRoutes from customers Routes from providers Routes from peers Which of these are chosen to advertise to other AS’s is a business decision.\nImporting Routes Again, they’re picky based on which routes are going to bring the most value to the business.\nUsually it’s this order:\nAn AS wants to ensure that routes toward its customers do not traverse other ASes, unnecessarily generating costs. An AS uses routes learned from peers since these are usually “free” (under the peering agreement). An AS resorts to importing routes learned from providers only when necessary for connectivity since these will add to costs. Border Gateway Protocol (BGP) BGP Design Goals Scalability - The internet will never stop growing, try to handle it Express routing policies (ERP) - Allows ASes to make routing decisions and do it privately Allow cooperation among ASes - Allows ASes to make their own decision and let business drive the connections Security - This was added on as it was found to be necessary BGP Basics BGP Peers send messages over BGP Sessions over a semi-permanent TCP port connection. A session is initiated from one router to another with an OPEN message which is then followed by sharing routing tables.\neBGP is an external BGP session, between two ASes. iBGP is an internal BGP session, in a singular AS.\nOnce the session is started they use:\nUPDATE - if any updates are made to the Route table, share it KEEPALIVE - Keeps session going, no changes BGP relies on prefix reachability, a list of IP addresses that prefix all the destinations. This is how the export and import routes are communicated.\nOther parameters:\nPath Attributes are also shared with other providers with parameters like:\nASPATH - Contains Autonomous System Number and helps choose between multiple routes and stops loops NEXT HOP - Provides the next router’s IP address so that other routers can store in their forwarding table the best path iBGP vs eBGP iBGP is meant for sharing paths of how to get out of an AS, it’s not an IGP that gives intradomain networking, but instead a way of telling nodes inside of AS how they can communicate with external ASes.\neBGP is the method of communicating between ASes the available external routes.\nBGP Router Process When a router receives a new list of policies it takes them all in, and then has a decision making process to determine the best routes for it to use.\nThe operator of this router can determine what is important to them (usually cost related) and make decisions based on that. Here’s an example decision process.\nImportant decision makers are:\nLocalPref - Decided by operating AS, things like choose the cheaper route (customers first, then peers, etc) MED - Determined by the neighboring AS, determine which link they would prefer you to use\nBGP Issues Two main things:\nMisconfiguration - Improper configuration can bring networks down for a lot of reasons Can be reduced by limiting size of tables and number of changes Scalability - Large routing tables are problematic. A lot of work went into reducing routing table sizes. They will do things like use default routing, route aggregation, and something called flap damping. Flap damping is a technique that limits the number of updates to a given prefix over time. If it goes over a certain limit, it will silence that prefix’s updates until a set time has passed.\nThis is configurable by domain, allowing you to choose when and where you will accept a lot of updates and when you won’t.\nPeering at IXPs ASes peer with each other, where do they do that? One place is an Internet Exchange Point (IXP). They are purpose built infrastructure to facilitate peering.\nInternet Exchange Points (IXPs) are critical physical infrastructures where Autonomous Systems (ASes) can directly interconnect and exchange traffic. These facilities are typically housed in secure, well-powered data centers and consist of robust switch fabrics to ensure reliability and fault tolerance. ASes participating in IXPs must have a public ASN, a BGP-capable router, and agree to the IXP’s terms. Once connected, ASes can publicly peer and exchange traffic settlement-free, paying only for connection and port usage, not traffic volume. This makes IXPs more cost-effective and efficient than traditional third-party traffic routing.\nIXPs have grown in popularity due to their ability to handle massive volumes of traffic and play a crucial role in improving network performance and reducing costs by keeping local traffic local. They also offer defensive benefits, such as DDoS mitigation, since they observe a large portion of Internet traffic and can help stop malicious activity before it reaches the intended target. Furthermore, IXPs provide a rich environment for research and innovation, particularly in areas like security and Software Defined Networking (SDN), and are evolving into hubs of technology development beyond just traffic exchange.\nIn addition to public and private peering services, IXPs offer a wide range of features such as route servers, SLAs, remote peering via resellers, mobile network peering, and DDoS blackholing. Some IXPs also provide free value-added services like DNS root servers and time distribution. These offerings, along with the ability to form fast and scalable peering agreements, have made IXPs essential infrastructure for global Internet connectivity, performance, and resilience.\nRoute Servers IXPs use route servers to handle the large number of ASes that they service.\nIn summary, a Route Server (RS) does the following:\nIt collects and shares routing information from its peers or participants of the IXP that connect to the RS. It executes its own BGP decision process and re-advertises the resulting information (e.g., best route selection) to all RS’s peer routers. It’s basically offloading all the configuration work from the AS to the IXP operator. It’s what allows people like me to buy a domain and get reliable routing from anywhere in the world to it.\nLesson 5 and 6 - Router Design and Algorithms Routers are what do the heavy lifting for actually moving data from one point to another. The prior lessons established many pieces and parts of that puzzle.\nIn short, a router needs to be able to receive an incoming packet on an input link, read its destination, and then send it to the correct output link. Simple in theory, difficult in practice, and more importantly, at scale. Then add on top of just forwarding requirements things like security requirements, quality of service, and other more advanced things, the job becomes difficult.\nRouter Components The main job of a router is to implement the forwarding plane functions and the control plane functions.\nForwarding (Switching) function The action of transferring a packet from an incoming link, to an outbound link. This should be very fast, on the scale of a few nanoseconds. I believe this is what a nice simple 5 port network switch is, and that’s all it is.\nInput Ports\nInput ports do the following:\nPhysically terminate the link Processes datalink (decapsulating) Performs lookup function, consulting forwarding table to determine where it should go Switching Fabric*\nThis actually moves the packet from the input port, to the output port, using the results from the input port that tells where the packet needs to go.\nThree types of switching fabrics:\nMemory Bus Crossbar Output ports\nAll this does is receive the data from the switching fabric and send it. Specifically:\nQueue the packets for transfer Encapsulate the packets Send them over the physical output port Control Plane function The control plane refers to:\nImplementing routing protocols (like the ones from earlier sessions) Maintaining routing tables Computing the forwarding table All of these functions are written software in the routing processor, or in the case of an SDN, could be implemented by a remote router.\nRouter Architecture Model of a router:\nUsing the image as a guide we can walk through the path that common tasks take. First we lookup the destination of an incoming packet.\nLookup Packet arrives at input link Lookup output link in forwarding table (Forwarding Information Base FIB) Resolve any ambiguities Longest Prefix matching Packet classification Switching After lookup is completed the packet is switched, from input link to output link. Modern routers use crossbar switches for this task. Some complications occur when many inputs want to send to the same output Queuing Using various queuing logics, if an output port is congested, each packet enters the queue to wait its turn to use the hardware.\nTypes of queues used:\nFirst In First Out (FIFO) Weighted Fair Queuing Header Validation and Checksum Check version number, validate checksum, decrement ttl Route processing Build route using protocols like RIP, OSPF, and BGP Protocol Processing (Including:) Simple Network Management Protocol (SNMP) - Counters for remote inspection TCP/UDP for remote communication Internet Control Message Protocol (ICMP) for sending error messages (eg: TTL is exceeded) Switching Fabric The switching fabric is where most of the logic is implemented in a router, forwarding packets from source to destination.\nThere are several ways to accomplish this.\nSwitching via memory Physical I/O ports operate as I/O devices in an operating system.\nInput port receives packet Send interrupt to routing processor Packet written to memory Processor looks at header to get destination address Lookup output port from forwarding table Copy from memory into output ports buffer Switching via bus Bus based switching doesn’t require a processor.\nInput port receives packet Input port marks which destination port it should be for with an internal header Send it to the bus where all output ports receive the packet Only the port it’s supposed to go to accepts it This design is limited by the speed of the bus as only one packet can traverse it at a time.\nSwitching via interconnection network A crossbar switch is an interconnection network that connects N inputs to N outputs using 2N buses.\nThis allows many packets at once to traverse the switching fabric, as long as they have different input and output ports. This is done by giving the switching fabric control of the buses, and closing the connections to make the links only when there is a packet that needs to make that journey.\nRouter Challenges There are a couple fundamental challenges to overcome for routers at scale.\nBandwidth and Internet population scaling Rapidly increasing number of devices (endpoints) Rapidly increasing volume of data New types of links like optical links (fiber) which increase transfer but increase complexity Services at high speeds Common bottlenecks A little bit more detail:\nLongest prefix matching - Due to the ever increasing number of devices on the internet, it’s impossible to hold a table for all of them. So instead devices are grouped into prefixes. But then you need good algorithms to deal with the prefixes.\nService differentiation - If you want to be able to provide priority to some packets and not to others, you need more complex logic to handle that. At scale.\nSwitching Limitations - At high speeds, the hardware can become a problem, causing bottlenecks at the I/O ports or even on the switching hardware.\nBottlenecks about services - Providing a reliable, fast, secure service that is guaranteed is difficult. Entire companies are built around doing this so that others don’t have to.\nPrefix matching Prefixing is a way to group endpoints together to make lookup tables less large.\nPrefix Notation:\nThere are several ways to notate prefixes.\nDot decimal 16 bit (132.234) becomes binary of 1000010011101010 Slash notation A/L, A=Address, L=Length 132.234.0.0/16 Masking 123.234.0.0/16 is written as 123.234.0.0 with a mask 255.255.0.0 The mask 255.255.0.0 denotes that only the first 16 bits are important. This prefixing helped, because we were running out of IP addresses, quickly. But it introduced the issue of longest matching prefix lookup.\nThe main router performance metric is how quickly it can do a full lookup. There are four common problem areas:\nA large amount of traffic is concurrent flows of short duration, making caching not very useful. Lookup speed is important, the most costly part of that is accessing memory An unstable routing protocol may result in more updates to the table and slower updates, adding milliseconds of time to the table update time. Cost vs performance, really expensive memory is fast, cheaper memory is slower how to decide which is which likely depends on application Unibit Tries Given this prefix db:\nResults in this trie:\nThese are the steps we follow to perform a prefix match:\nWe begin the search for a longest prefix match by tracing the trie path. We continue the search until we fail (no match or an empty pointer) When our search fails, the last known successful prefix traced in the path is our match and our returned value. Two notes:\nIf a prefix is a substring of another prefix, the smaller string is stored in the path to the longer (more specific prefix). For example, P4 = 1is a substring of P2 = 111, and thus P4 is stored inside a node towards the path to P2.\nOne-way branches. There may be nodes that only contain one pointer. For example, let’s consider the prefix P3 = 11001. After we match 110 we will be expecting to match 01. But in our prefix database, we don’t have any prefixes that share more than the first 3 bits with P3. So if we had such nodes represented in our trie, we would have nodes with only one pointer. The nodes with only one pointer each are called one-way branches. For efficiency, we compress these one-way branches to a single text string with 2 bits (shown as node P9).\nMultibit Tries Unibit tries are very efficient but it requires a large amount of memory accesses to achieve. For highspeed links it is not plausible to access memory that many times. Instead we use strides. A stride is the number of bits to check at each step.\nSo an alternative to unibit tries are the multibit tries. A multibit trie is a trie where each node has 2k children, where k is the stride. Next, we will see that we can have two flavors of multibit tries: fixed-length stride tries and variable-length stride tries.\nPrefix expansion One quick problem you may run into with multibit, is if you have a stride length of 2, you could miss prefixes like 101* so this is handled via expansion:\nFixed Stride Example Using a fixed stride length of three, let’s do an example. Using the same database as the prior example.\nSome key points to note here:\nEvery element in a trie represents two pieces of information: a pointer and a prefix value. The prefix search moves ahead with the preset length in n-bits (3 in this case) When the path is traced by a pointer, we remember the last matched prefix (if any). Our search ends when an empty pointer is met. At that time, we return the last matched prefix as our final prefix match. Variable Stride Length Variable Stride length allows us to save memory and still get all of the addresses.\nSome key points about variable stride:\nEvery node can have a different number of bits to be explored. The optimizations to the stride length for each node are all done to save trie memory and the least memory accesses. An optimum variable stride is selected by using dynamic programming Packet Classification We’ve talked aout prefix matching and how it attempts to solve the issue of an ever growing internet with many devices and many ip addresses.\nWhat it doesn’t do is provide advanced features like paying attention to source addresses, tcp flags, etc.\nPacket classification tackles those challenges.\nCommon examples:\nFirewalls - Routers implement firewalls to filter inbound and outbound traffic based on a pre-determined set of policies. Resource Reservation Protocols - To reserve bandwidth between a source and destination Routing based on traffic type - If a certain type of traffic is more time sensitive, move it to the front of the queue Simple Classifiers Linear Search - Perform a search through a rules database for every packet, works fine for simple rules, struggles at large amounts of rules Caching - Caching is usefule but has issues Even an 80-90% cache rate still results in many searches A 90% cache rate still has ~0.1 milliseconds of search, which is pretty slow in this context Passing Labels - Setup “Label Switched Paths” between sites, Multiprotocol Label Switching (MPLS) and DiffServ use this MPLS: router A does classification, and then all intermediate routers just read it and use it, instead of doing their own classification DiffServ: Applies special markers at the edges to mark a packet for special quality-of-service Fast Searching - Using Set Pruning Tries Assume a two dimensional rule that only cares about source and destination IPs.\nWe can build a trie (similar to earlier in this section), where each leaf node is another trie\nBy S1, we denote the source prefix of rule R1, S2 of rule R2, etc. Thus for every destination prefix D in the destination trie, we “prune” the set of rules to those compatible with D. We first match the destination IP address in a packet in the destination trie. Then we traverse the corresponding source trie to find the longest prefix match for the source IP. The algorithm keeps track of the lowest-cost matching rule. Finally, the algorithm concludes with the least-cost rule. Challenge: The problem that we need to solve now is which source prefixes to store at the sources tries? For example, let’s consider the destination D = 00*. Both rules R4 and R5 have D as the destination prefix. So the source tries for D will need to include the source prefixes 1* and 11*. But if we restrict to 1* and 11*, this is not sufficient. Because the prefix 0*, also matches 00*, and it is found in rules R1, R2, R3, R7. So we will need to include all the corresponding source prefixes. Moving forward, the problem with the set pruning tries is memory explosion. Because a source prefix can occur in multiple destination tries.\nReducing Memory Using Backtracking Set pruning has a high cost in memory to reduce time. So we can trade memory for time and try to solve this problem.\nFrom the lecture:\nThe set pruning approach has a high cost in memory to reduce time. The opposite approach is to pay in time to reduce memory. Let’s assume a destination prefix D. The backtracking approach has each destination prefix D point to a source trie that stores the rules whose destination field is exactly D. The search algorithm then performs a “backtracking” search on the source tries associated with all ancestors of D. So first, the algorithm goes through the destination trie and finds the longest destination prefix D matching the header. Then it works its way back up the destination trie and searches the source trie associated with every ancestor prefix of D that points to a nonempty source trie. Since each rule is stored exactly once, the memory requirements are lower than the previous scheme. But, the lookup cost for backtracking is worse than for set-pruning tries.\nGrid of Tries We’ve tried Backtracking (high time lower memory), and set pruning (memory explosion). Both fail for their own reasons.\nGrid of tries approach takes backtracking and reduces wasted time by precomputing. When backtracking if there is a failure point in the source trie, we have a “switch pointer” which takes you directly to the next possible source trie containing a matching rule.\nAt places where there may be a failure to get to a matching rule, we can go directly to the next most likely place to find a rule, with precomputed switch pointers.\nScheduling Now we talk about scheduling. Given a N-by-N crossbar switch with N input lines, N output lines, and N2 crosspoint we need to ensure that each input link is only connected to one output link at any given time and we want to maximize throughput by having the as many parallel routes open at one time as possible.\nTake a Ticket Algorithm Every output link has a queue, when an input link would like to use that queue it gets a ticket, and waits until it is called to send its packet and the route is opened.\nRound 1:\nRound 2:\nRound 3: and here is an overview of how this all plays out:\nOne thing to note here is that all of the other messages that are going to other nodes are blocked by the fact that they all wanted to go to output 1 first. This is “Head of line” blocking caused by take a ticket.\nAvoiding Head of Line with Take a Ticket Output Queuing Given an N-by-N crossbar switch can we try to send to an output link without queuing? Then it would only need to block packets which are headed for the same destination. To do this the fabric must run N times faster than the input links.\nA practical approach to this is the knockout scheme. It breaks up packets into fixed sizes k (which is smaller than N). Then if the fabric needs to only run k times as fast as an input link instead of N.\nIn some cases this can be broken and there are primitive switching rules to handle this.\nk = 1 and N = 2. Randomly pick the output that is chosen. The switching element, in this case, is called a concentrator. k = 1 and N \u003e 2. One output is chosen out of N possible outputs. We can use the same strategy of multiple 2-by-2 concentrators in this case. k needs to be chosen out of N possible cells, with k and N arbitrary values. We create k knockout trees to calculate the first k winners. The drawback of this approach is it is complex to implement.\nParallel Iterative Matching This approach still allows queuing but in a way that avoids head-of-line blocking. It starts with taking each incoming link’s queue and breaking it into virtual queues for each output link.\nIf an input receives multiple grants, it randomly picks between the two. This allows more packets to attempt to go through more quickly at the same time, and is more efficient than take-a-ticket.\nScheduling Intro Busy routers rely on scheduling for routing updates, management queries, and data packets. Since linkspeeds are climbing over 40 gigabit, this needs to be done very quickly.\nFIFO with tail drop This is a simple first in first out queue, but if the queue is larger than its limit, the packets at the “tail” are dropped off.\nQuality of Service The FIFO approach has pretty bad quality of service with not guaranteed delivery due to dropping packets in the tail.\nThis is bad for the following reasons:\nRouter support for congestion Congestion in the internet is increasingly possible as the usage has increased faster than the link speeds. While most traffic is based on TCP (which has its own ways to handle congestion), additional router support can improve the throughput of sources by helping handle congestion.\nProviding QoS guarantees to flows During periods of backup, these packets tend to flood the buffers at an output link. If we use FIFO with tail drop, this blocks other flows, resulting in important connections on the clients’ end freezing. This provides a sub-optimal experience to the user, indicating a change is necessary!\nFair sharing of links among competing flows One way to enable fair sharing is to guarantee certain bandwidths to a flow. Another way is to guarantee the delay through a router for a flow. This is noticeably important for video flows – without a bound on delays, live video streaming will not work well.\nBit by Bit Round Robin FIFO might drop packets. So we can use round robin to fix that. Pure round robin struggles though if one link has different packet sizes than the other, which might result in one link getting better service than the other.\nBit by Bit fixes this. The idea is that even though we can’t split packets up bit by bit, we can kind of do it virtually to help inform scheduling decisions. Using a lot of fancy math we can determine the round in which a packet finishes sending.\nThe Bit by Bit round robin then works by sending the packet which has the smallest finishing round number. Consider the following example:\nF is their finishing number, in their respective queues.\nWe can see F=1002 is sent first, because it had the earliers round finishing number. It was the “most starved” packet during the prior scheduling round.\nThis is fair, but introduces new complexities. Specifically maintaining a priority queue becomes very expensive, and takes a long time, which isn’t feasible at gigabit speeds.\nDeficit Round Robin Round robin guaranteed delay and bandwidth fairness, but many applications only care aobut bandwidth fairness. So a simple constant-time round robin could get that done much more simply.\nWe assign a quantum size, Qi, and a deficit counter, Di, for each flow. The quantum size determines the share of bandwidth allocated to that flow. For each turn of round-robin, the algorithm will serve as many packets in the flow i with size less than (Qi + Di). If packets remain in the queue, it will store the remaining bandwidth in Di for the next run. However, if all packets in the queue are serviced in that turn, it will clear Di to 0 for the next turn.\nConsider the following:\nIn this router, there are four flows – F1, F2, F3, and F4. The quantum size for all flows is 500. Initially, the deficit counters for all flows are set to 0. Initially, the round-robin pointer points to the first flow. The first packet of size 200 will be sent through. However, the funds are insufficient to send the second packet of size 750. Thus, a deficit of 300 will remain in D1. For F2, the first packet of size 500 will be sent, leaving D2 empty. Similarly, the first packets of F3 and F4 will be sent with D3 = 400 and D4 = 320 after the first iteration. For the second iteration, the D1+ Q1 = 800, meaning there are sufficient funds to send the second and third packets through. Since there are no remaining packets, D1 will be set to 0 instead of 30 (the actual remaining amount).\nToken Bucket Sometimes we want to limit flows of certain data types without having to put them into another queue.\nToken bucket shaping can accomplish this through things like limiting burstiness of flow by limiting the average rate, and limiting the burst maximum size allowed.\nIf a packet comes and needs to hit the bucket, the bucket has to have enough available tokens, otherwise it fails. That’s how you limit burst.\nThe problem with this is only one queue per flow. If a flow has a full token bucket it may block other flows. Token policing solves this.\nLeaky Bucket (Token Policing) Policing and shaping both help limit the output of a link but in different ways.\nPolicer: When the traffic rate reaches the maximum configured rate, excess traffic is dropped, or the packet’s setting or “marking” is changed. The output rate appears as a saw-toothed wave. Shaper: A shaper typically retains excess packets in a queue or a buffer, and this excess is scheduled for later transmission. The result is that excess traffic is delayed instead of dropped. Thus, the flow is shaped or smoothed when the data rate is higher than the configured rate. Traffic shaping and policing can work in tandem. Leaky bucket refers to the Token Bucket implementation with a constant output rate. If a packet were to make a bucket overflow it is discarded, but the same time things aren’t sent in burst, but at a constant “leak” rate.\nLesson 7 - Software Defined Networking Software Defined Networking (SDN) was borne of the need to separate the control plane from the data plane.\nWhy did SDN arise? There was a need to make computer networks more programmable, because there is a diversity of equipment on every network, and many proprietary technologies.\nDiversity of Equipment Routers, switches, firewalls, network address translators, server load balancers, intrusion detection systems, oh my! These are just some of the types of devices that get put on a network.\nEven with a centralized network controller, there are so many different protocols and interfaces that need support, it creates quite a lot of work to support it.\nProprietary Technologies Switches and routers often ran proprietary software. Likely done to encourage people to buy all of a certain brand, but in instances where that’s not feasible for one reason or another then something has to deal with those differences.\nSDN looks to fix all of these issues with ✨software✨. It does this by separating tasks. Specifically separating the control plane and the data plane.\nHistory of SDNs The history of SDN can be divided into three phases:\nActive networks Control and data plane separation OpenFlow API and network operating systems Active Networks From the mid 1990s until the early 2000s the internet of course exploded. This required new porotocols which were to be created by the Internet Engineering Task Force (IETF). This process sucked and then other things sprung up to fill the holes.\nIt led to the growth of active networks which used wanted a programming interface which exposed many resources and allowed customization of functionalities for subsets of packets passing through the network. This was opposite to the belief that a simple network core was important to internet success.\nThere were two prevalent programming models in active networking with the difference being where code is executed:\nCapsule Model - carried in band pockets Programmable router/switch model - established out of band mechanisms The main pushers of active networks was\nReduction in computation cost, enables more processing Advancement in programming languages, enabled things that were previously not possible, of if they were possible, were unsafe Advances in rapid code compliation and formal methods Funding from DARPA (DARPA just keeps showing up) The main pullers of active networks was:\nNetwork service providers were frustrated with long timelines to deploy new network services Third parties wanting to get more control on an individual level Unified control over middleboxes These pulls are similar pulls to the current pulls for SDN.\nActive networks made three major contributions to CDNs:\nProgrammable functions in the network to lower the barrier to innovation Active networks were one of the first to use the idea of programmable networks to overcome the slow speed of innovation in computer networks. Lots of focus was on programming the control plane, but active networks tried to add some to the data plane This is similar to OpenFlow and other SDN ideas that are being used Network virtualization, the ability to demultiplex software programs based on packet headers Active networking produced a framework that described a platform that would support experimentation, this led to virtualization Unified Architecture for middlebox orchestration Control over middleboxes was never fully realized in Active networks but some of its research is benefitting network function virtualization Active Networks main reason for not beocming main stream is due to the fact that it was too ambitious. It required people to program in Java, which was not guaranteed, and did not have security as a focus from the beginning, which scared people.\nControl and data plane separation Control and data plane separation was from around 2001 to 2007. Network operators were desperate to have better management tools of their traffic as the network popularity exploded.\nIt was identified that many of the main issues had to do with the tight coupling of the control and data planes.\nThe main pushers of control and data plane separation were:\nHigher link speeds in backbone networks Internet service providers had a difficult time meeting the increased reliability and new services Servers had substantially more memory and processing resources than things made even 1 or 2 years earlier Open source routing software lowered the barrier to creating centralized routing controllers These pushes resulted in:\nOpen interface between control and data planes Logically centralized control of the network It was different from active networking in the following ways:\nFocused on spurring innovation by and for network administrators Emphasized programmability in the control domain rather than the data domain Worked towards network-wide visibility and control rather than device level The main pullers of control and data plane separation were:\nSelecting between network paths based on current traffic load Minimizing disruptions during planned routing changes Redirecting/dropping suspected attack traffic (firewall) Allow customers more control over traffic flow Offering value add services for virtual private network customers Most of this work was completed within an ISP, with not much cross ISP interfacing. There were a couple concepts which were taken into SDN design:\nLogically centralized control using an open interface Distributed state management People thought this was a bad idea because what if the controller failed. In addition to this people were nervous about distributed network maps instead of the routers knowing the whole picture.\nOpenFlow API and network operating systems This took place during 2007 to 2010.\nThe OpenFlow API was borne fromm an interest in the idea of network experimentation at scale. It balanced fully programmable networks with real world deployments.\nIt was built on existing hardware but enabled more functions that prior controllers. This dependency was based on hardware flexibility, but it enabled immediate deployment.\nOpenFlow switches follow this:\nEach switch contains a table of packet-handling rules Each rule has a pattern, list of actions, set of counters, and priority Once a packet is recieved it determines the highest priority matching rule, performas the action associated with it, and increments the counter\nThe main pushers of this technology were:\nSwitch chipset vendors had already started to allow programmers to control some forwarding behaviors Allowed other companies to build their own switches without making a data plane Enabling OpenFlow was easy to deploy based on a simple firmware upgrade The main *pullers of this technology were:\nOpenFlow was meeting the need of conducting large scale experimentation on network architectures OpenFlow was useful in data-center networks that had a need to manage network traffic Companies started investing more in programmers for cotnrol programs and less on proprietary hardware, allowing smaller players to get in the game OpenFlow’s Key Effects:\nGeneralized network device and functions Provided a vision of a network operating system Distributed state management techniques Separating the Data Plane and the Control Plane SDN is different from the traditional networking approaaches because it separates the control and data plane.\nThe reasons for this separations are:\nIndependent evolution and development Routing and forwarding are tied to a single piece of hardware, meaning the only easy time to upgrade, is when you do the whole thing. By separating them, routing can grow while forwarding stays the same, and vice versa. Coupling makes things difficult. Control from high-level software program Using software to compute forwarding tables means higher order programs can control router behavior. Not being attached to the forwarding plane makes this simpler. It’s best for both planes that they go their separate ways :)\nThis then enables:\nData Centers, large data centers with oodles of compute, but using that compute can become even more difficult if you’re rigidly attached to the forwarding hardware Routing, separating the two allows more complex routing Enterprise networks. SDN can imporve sescurity of networks by protecting from things like DDoS by simply dropping traffic at strategic locations Research networks. You can colocate research and production networks, allowing for experimentation on live traffic without interfering with said live traffic Traditional Router: SDN approach: SDN Architecture The main components af an SDN network are:\nSDN controlled network elements - The infrastructure layer is responsible for the forwarding of traffic in a network based on rules from the SDN control plane SDN controller - Logically centralized entity that acts as the interface between network element and network control applications Network control applications - Programs that manage the underlying network by observing network elements through the SDN controller Four defining features The four defining features of SDN architecture are\nFlow-based forwarding Separation of data plane and control plane Netowrk control functions A programmable network Flow-based forwarding The rules for forwarding packets can be computed based on any number of header values from various layers. This differes from the prior approach in which only the destination IP address determined the forwarding of a packet. OpenFlow allowed up to 11 header field values to be used\nSeparation of data plane and control plane SDN controlled switches only operate on the data plane executing rules in the flow tables, created and managed by entirely separate servers\nNetwork control functions The SDN control plane usually runs on multiple servers for increased performance and availability. It also consists of two componetns\nController Network applications The controller maintains up to date network state info and provides it to network control applications. This is used by the applications to monitor and control network devices\nA programmable network Since you have the network-control applications which act as the “brain” of the SDN control plane you can do things like network management, traffic engineering, security, automation, etc. Something like determining the end-to-end path between sources and destinations in the network using Dijkstra wink wink.\nSDN Controller Architecture The SDN controller is a part of the SDN control plane. It acts as an interface between the network elements and the network-control applications.\nSDN Controller Layers Communication Layer - Communicating between the controller and network elements Network-wide state-management layer - Stores information of network-state Interface to the network-control application - communicating between controller and applications Communication Layer This layer has a protocol which the SDN controller and the network controlled elements communicate. This protocol is used so that network devices can send things like new device joining, heartbeat indicators, etc. The communication between SDN controller and the controlled devices is the “southbound” interface. OpenFlow does this.\nNetwork-wide state-management layer This is pretty self-explanatory, everything that has to do with the network state that is managed by the controller. State of hosts, links, switches and copies of flow tables of various switches. This is what is used by the control plane to configure flow tables.\nInterface to the network-control application This layer is the “northbound” interface and how the SDN controller interacts with network-control applications. Network control applications read/write network state, flow tables, etc in the state-management layer. The SDN controller can also notify applications of changes in state as well.\nGenerally these SDN controllers are implemented in a distributed fashion in order to achieve fault tolerance, high availability and efficiency.\nLesson 8 - Software Defined Networking (Part 2) Again, CDN is a more independently layered approach to Routing\nSDN Advantages compared to Traditional Shared Abstractions. Middlebox services (or network functionalities) can be programmed easily since the abstractions provided by the control platform and network programming langauges can be shared Consistency of same network information. All network apps have the same global view leading to more consistent policy decisions while reussing control plane modules Locality of functionality placement. Previously middlebox locations were strategic decisions and often big constraints. With SDN middleboxes can be whereever Simpler Integration. It’s easier to integrate to SDN things than traditional proprietary boxes SDN Landscape Again SDN can be viewed as layers:\n(a) is plane-oriented view, (b) is the SDN layers, (c) is a system design perspective.\nSDN Architecture Infrastructure Instead of needing routers with switching and control plane, physical networking equipment only needs to do simple forwarding. All logic comes from a centralized control system.\nSouthbound Interfaces Communications between control and forwarding elements (switches) is on the southbound interface. These APIs are tightly coupled with the forwarding elements. The most popular implementation is OpenFlow.\nNetwork Virtualization A complete virtualization of a network needs to support arbitrary network topoligies and addressing scheemes, similar to the computing layer. VLAN, NAT and MLPS can provide this full virtualization but this is a box-by-box basis configuration and there is no unifying abstraction to do this in a global manner. So this is one thing that takes a long time still.\nNetwork Operating Systems These operating systems abstract away many low level things like distribution among routing elements, allowing developers to focus on more complex applications. Examples are OpenDayLight, OpenContrail, etc\nNorthbound Interfaces The Northbound interface is how the controller and the network applications talk. There is no set standard for this interface, but one key difference is it’s usually purely software to software communication, unlike the southbound interface. Popular examples are Floodlight, Trema, NOX, ettc.\nLanguage-based virtualization Allowing network devices to be interacted with via many ways at different levels of abstraction. Takes away device communication complexity without compromising security.\nNetwork programming langauges By having high level programming laguages in SDNs it gives more abstractions to make development more modular, things more reusable and do away with device specific low-level configurations.\nNetwork applications The functionalities implementing control plane logic and translates to commands in the data plane. There is avery wide range of options for these applications, doing things like routing, load balancing, security enforcement, and more.\nSDN Infrastructure Layer SDN infrastructure contains routers, switches, and appliance hardware.\nThe physical devices have no embedded intelligence, as it’s delegated to the central control system, the Network Operating System (NOS). These are built on open-souce interfaces to encourage improvements and growth to the networking sphere.\nA data plane devices forwards packets, a controller is a software stack running on commodity hardware. The most widely used data plane device is a model derived from OpenFlow. There’s a pipeline of flow tables where each entry should have a matching rule, actions to be executed on matching packets, counters keeping statistics of matching packets.\nIn OpenFlow device\nPacket arrives Lookup starts, either matches with rule or misses Resolve forward to outgoing port encapsulate and send to controller drop packet send to normal processing pipeline send to next flow table SDN Southbound interrfaces Sounthbound interfaces are the APIs separting the control plane and the data plane. Since switch hardware takes time to design and engineer, this has settled on a standard protoocol of OpenFlow.\nThe OpenFlow protocol supports three info sources:\nEvent based messages sent by forwarding devices to the controller when there is a link or port change Flow statistics generated by forwarding devices and collected by controller Packetss sent by forwarding devices when they don’t know what to do with them The controller and network operating system uses this flow of information to make decisions and maintain states/maps/flow charts.\nSDN Controllers - Centralized vs Distributed The core controllerr functions are:\nTopology Statistics Notifications Device Mangement Shortest Path forwarding Security mechanisms Centralized controllers A single entity manages all forwarding devices in the network. This has a single point of failure and can have a hard time scaling. Some enterprise class networks and data centers use archietctures that allow this and use giant mult-threaded designs alllowing for large amounts of throughput even on a single server.\nDistributed controllers Distributed controlling can scale to meet practically and requirement, because it’s built in to the design to scale as needed. It can be a centralized cluster of nodes, or a physically distributed set of elements. If a provider has multiple data centers, they might even do a hybrid where each center has a cluster, but they talk physically in a physically distributed manner.\nOpen Network Operating System This is an example of a distributed SDN control platform.\nONOS has several instances running in a cluster. The network state is shared across these instances by maintaining a global view. The view is made with network topology and state information.\nForwarding and policy decisions come from the view, OpenFlow managers recieve changes, and switches are programmed.\nTitan is a graph database and Cassandra a distributed key-value store work together to create the view. They interact with this using the Blueprints Graph API.\nThe ONOS archictecture can scale out and offers fault tolerance. In ONOS there is a master controller for a group of switches, and the propagation of state changes is handled solely by the master instance of that switch. This is distributed by adding more instances, reducing number of switches to contoller instances.\nFault tolerance is achieved by handling failures via election, where if the master controller of a switch fails, the rest of the ONOS instances it is connected to fomr on consensu on who the new master should be for each of the switches that were failed.\n",
  "wordCount" : "12471",
  "inLanguage": "en",
  "image":"https://nathanemb.github.io/codetrails/osi_model_7_layers.png","datePublished": "2025-05-24T20:48:59-04:00",
  "dateModified": "2025-05-24T20:48:59-04:00",
  "author":{
    "@type": "Person",
    "name": "Nathan Embaugh"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Nathan Embaugh | codetrails",
    "logo": {
      "@type": "ImageObject",
      "url": "https://nathanemb.github.io/codetrails/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://nathanemb.github.io/codetrails/" accesskey="h" title="Nathan Embaugh | codetrails (Alt + H)">Nathan Embaugh | codetrails</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://nathanemb.github.io/codetrails/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://nathanemb.github.io/codetrails/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://nathanemb.github.io/codetrails/">Home</a>&nbsp;»&nbsp;<a href="https://nathanemb.github.io/codetrails/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      CS6250 - Computer Networks - Notes
    </h1>
    <div class="post-meta"><span title='2025-05-24 20:48:59 -0400 EDT'>May 24, 2025</span>&nbsp;·&nbsp;59 min&nbsp;·&nbsp;Nathan Embaugh&nbsp;|&nbsp;<a href="https://github.com/NathanEmb/codetrails/issues/new/choose" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> 
<figure class="entry-cover">
            <img loading="eager"
                srcset='https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_a75976601a15ce17.png 360w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_eef6607b514803c3.png 480w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_3532c72e7119b318.png 720w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_3771e8c5c8ca8464.png 1080w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_e79f2da8efd67dc.png 1500w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers.png 5667w'
                src="https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers.png"
                sizes="(min-width: 768px) 720px, 100vw"
                width="5667" height="2834"
                alt="The OSI model.">
        <figcaption>The theoretical OSI model.</figcaption>
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#lesson-1---introduction-history-and-internet-architecture" aria-label="Lesson 1 - Introduction, History, and Internet Architecture">Lesson 1 - Introduction, History, and Internet Architecture</a><ul>
                        
                <li>
                    <a href="#history-of-the-internet" aria-label="History of the internet">History of the internet</a></li>
                <li>
                    <a href="#internet-architecture" aria-label="Internet Architecture">Internet Architecture</a><ul>
                        
                <li>
                    <a href="#application-layer" aria-label="Application Layer">Application Layer</a></li>
                <li>
                    <a href="#the-presentation-layer" aria-label="The Presentation Layer">The Presentation Layer</a></li>
                <li>
                    <a href="#the-session-layer" aria-label="The Session Layer">The Session Layer</a></li>
                <li>
                    <a href="#the-transport-layer" aria-label="The Transport Layer">The Transport Layer</a></li>
                <li>
                    <a href="#the-network-layer" aria-label="The Network Layer">The Network Layer</a></li>
                <li>
                    <a href="#the-data-link-layer" aria-label="The Data Link Layer">The Data Link Layer</a></li>
                <li>
                    <a href="#the-physical-layer" aria-label="The Physical Layer">The Physical Layer</a></li></ul>
                </li>
                <li>
                    <a href="#encapsulation" aria-label="Encapsulation">Encapsulation</a></li>
                <li>
                    <a href="#the-end-to-end-e2e-principle" aria-label="The End to End (e2e) Principle">The End to End (e2e) Principle</a><ul>
                        
                <li>
                    <a href="#violations-of-e2e" aria-label="Violations of e2e">Violations of e2e</a></li></ul>
                </li>
                <li>
                    <a href="#the-hourglass-shape-of-the-internet" aria-label="The Hourglass Shape of the Internet">The Hourglass Shape of the Internet</a></li>
                <li>
                    <a href="#interconnecting-hosts-and-networks" aria-label="Interconnecting Hosts and Networks">Interconnecting Hosts and Networks</a><ul>
                        
                <li>
                    <a href="#repeaters-and-hubs" aria-label="Repeaters and Hubs">Repeaters and Hubs</a></li>
                <li>
                    <a href="#bridges-and-layer-2-switches" aria-label="Bridges and Layer-2 Switches">Bridges and Layer-2 Switches</a></li>
                <li>
                    <a href="#routers-and-layer-3-switches" aria-label="Routers and Layer-3 Switches">Routers and Layer-3 Switches</a></li></ul>
                </li>
                <li>
                    <a href="#learning-bridges" aria-label="Learning Bridges">Learning Bridges</a><ul>
                        
                <li>
                    <a href="#the-looping-problem" aria-label="The Looping Problem">The Looping Problem</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#lesson-2---the-transport-layer-tcp" aria-label="Lesson 2 - The Transport Layer (TCP)">Lesson 2 - The Transport Layer (TCP)</a><ul>
                        
                <li>
                    <a href="#transport-layer-intro" aria-label="Transport Layer intro">Transport Layer intro</a></li>
                <li>
                    <a href="#multiplexing" aria-label="Multiplexing">Multiplexing</a></li>
                <li>
                    <a href="#connectionless-multiplexing" aria-label="Connectionless Multiplexing">Connectionless Multiplexing</a></li>
                <li>
                    <a href="#connection-oriented-multiplexing" aria-label="Connection Oriented Multiplexing">Connection Oriented Multiplexing</a></li>
                <li>
                    <a href="#a-word-on-udp" aria-label="A word on UDP">A word on UDP</a></li>
                <li>
                    <a href="#tcp" aria-label="TCP">TCP</a><ul>
                        
                <li>
                    <a href="#three-way-handshake" aria-label="Three way handshake">Three way handshake</a></li>
                <li>
                    <a href="#connection-tear-down" aria-label="Connection tear down">Connection tear down</a></li></ul>
                </li>
                <li>
                    <a href="#reliable-transmission-tcp" aria-label="Reliable Transmission (TCP)">Reliable Transmission (TCP)</a></li>
                <li>
                    <a href="#transmission-control-tcp" aria-label="Transmission Control (TCP)">Transmission Control (TCP)</a><ul>
                        
                <li>
                    <a href="#flow-control" aria-label="Flow Control">Flow Control</a></li>
                <li>
                    <a href="#congestion-control" aria-label="Congestion Control">Congestion Control</a><ul>
                        
                <li>
                    <a href="#network-assisted" aria-label="Network Assisted">Network Assisted</a></li>
                <li>
                    <a href="#end-to-end" aria-label="End to End">End to End</a></li></ul>
                </li>
                <li>
                    <a href="#tcp-throughput" aria-label="TCP Throughput">TCP Throughput</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#lesson-3---intradomain-routing-the-network-layer" aria-label="Lesson 3 - Intradomain Routing (The Network Layer)">Lesson 3 - Intradomain Routing (The Network Layer)</a><ul>
                        
                <li>
                    <a href="#routing" aria-label="Routing">Routing</a><ul>
                        
                <li>
                    <a href="#link-state-routing" aria-label="Link State Routing">Link State Routing</a></li>
                <li>
                    <a href="#distance-vector-routing" aria-label="Distance Vector Routing">Distance Vector Routing</a><ul>
                        
                <li>
                    <a href="#a-simple-example" aria-label="A simple example">A simple example</a></li>
                <li>
                    <a href="#pitfalls-of-dv" aria-label="Pitfalls of DV">Pitfalls of DV</a></li></ul>
                </li>
                <li>
                    <a href="#routing-information-protocol-rip" aria-label="Routing Information Protocol (RIP)">Routing Information Protocol (RIP)</a></li>
                <li>
                    <a href="#open-shortest-path-first" aria-label="Open Shortest Path First">Open Shortest Path First</a></li></ul>
                </li>
                <li>
                    <a href="#hot-potato-routing" aria-label="Hot Potato Routing">Hot Potato Routing</a></li></ul>
                </li>
                <li>
                    <a href="#lesson-4---interdomain-routing-and-as-relationships" aria-label="Lesson 4 - Interdomain Routing and AS Relationships">Lesson 4 - Interdomain Routing and AS Relationships</a><ul>
                        
                <li>
                    <a href="#the-internet" aria-label="The Internet">The Internet</a></li>
                <li>
                    <a href="#as-ecosystem" aria-label="AS Ecosystem">AS Ecosystem</a></li>
                <li>
                    <a href="#internet-business" aria-label="Internet Business">Internet Business</a><ul>
                        
                <li>
                    <a href="#exporting-routes" aria-label="Exporting Routes">Exporting Routes</a></li>
                <li>
                    <a href="#importing-routes" aria-label="Importing Routes">Importing Routes</a></li></ul>
                </li>
                <li>
                    <a href="#border-gateway-protocol-bgp" aria-label="Border Gateway Protocol (BGP)">Border Gateway Protocol (BGP)</a><ul>
                        
                <li>
                    <a href="#bgp-design-goals" aria-label="BGP Design Goals">BGP Design Goals</a></li>
                <li>
                    <a href="#bgp-basics" aria-label="BGP Basics">BGP Basics</a></li>
                <li>
                    <a href="#ibgp-vs-ebgp" aria-label="iBGP vs eBGP">iBGP vs eBGP</a></li>
                <li>
                    <a href="#bgp-router-process" aria-label="BGP Router Process">BGP Router Process</a></li>
                <li>
                    <a href="#bgp-issues" aria-label="BGP Issues">BGP Issues</a></li></ul>
                </li>
                <li>
                    <a href="#peering-at-ixps" aria-label="Peering at IXPs">Peering at IXPs</a><ul>
                        
                <li>
                    <a href="#route-servers" aria-label="Route Servers">Route Servers</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#lesson-5-and-6---router-design-and-algorithms" aria-label="Lesson 5 and 6 - Router Design and Algorithms">Lesson 5 and 6 - Router Design and Algorithms</a><ul>
                        
                <li>
                    <a href="#router-components" aria-label="Router Components">Router Components</a><ul>
                        
                <li>
                    <a href="#forwarding-switching-function" aria-label="Forwarding (Switching) function">Forwarding (Switching) function</a></li>
                <li>
                    <a href="#control-plane-function" aria-label="Control Plane function">Control Plane function</a></li></ul>
                </li>
                <li>
                    <a href="#router-architecture" aria-label="Router Architecture">Router Architecture</a></li>
                <li>
                    <a href="#switching-fabric" aria-label="Switching Fabric">Switching Fabric</a><ul>
                        
                <li>
                    <a href="#switching-via-memory" aria-label="Switching via memory">Switching via memory</a></li>
                <li>
                    <a href="#switching-via-bus" aria-label="Switching via bus">Switching via bus</a></li>
                <li>
                    <a href="#switching-via-interconnection-network" aria-label="Switching via interconnection network">Switching via interconnection network</a></li></ul>
                </li>
                <li>
                    <a href="#router-challenges" aria-label="Router Challenges">Router Challenges</a><ul>
                        
                <li>
                    <a href="#common-bottlenecks" aria-label="Common bottlenecks">Common bottlenecks</a></li></ul>
                </li>
                <li>
                    <a href="#prefix-matching" aria-label="Prefix matching">Prefix matching</a><ul>
                        
                <li>
                    <a href="#unibit-tries" aria-label="Unibit Tries">Unibit Tries</a></li>
                <li>
                    <a href="#multibit-tries" aria-label="Multibit Tries">Multibit Tries</a><ul>
                        
                <li>
                    <a href="#prefix-expansion" aria-label="Prefix expansion">Prefix expansion</a></li></ul>
                </li>
                <li>
                    <a href="#fixed-stride-example" aria-label="Fixed Stride Example">Fixed Stride Example</a></li>
                <li>
                    <a href="#variable-stride-length" aria-label="Variable Stride Length">Variable Stride Length</a></li></ul>
                </li>
                <li>
                    <a href="#packet-classification" aria-label="Packet Classification">Packet Classification</a><ul>
                        
                <li>
                    <a href="#simple-classifiers" aria-label="Simple Classifiers">Simple Classifiers</a></li>
                <li>
                    <a href="#fast-searching---using-set-pruning-tries" aria-label="Fast Searching - Using Set Pruning Tries">Fast Searching - Using Set Pruning Tries</a></li>
                <li>
                    <a href="#reducing-memory-using-backtracking" aria-label="Reducing Memory Using Backtracking">Reducing Memory Using Backtracking</a></li>
                <li>
                    <a href="#grid-of-tries" aria-label="Grid of Tries">Grid of Tries</a></li></ul>
                </li>
                <li>
                    <a href="#scheduling" aria-label="Scheduling">Scheduling</a><ul>
                        
                <li>
                    <a href="#take-a-ticket-algorithm" aria-label="Take a Ticket Algorithm">Take a Ticket Algorithm</a></li>
                <li>
                    <a href="#avoiding-head-of-line-with-take-a-ticket" aria-label="Avoiding Head of Line with Take a Ticket">Avoiding Head of Line with Take a Ticket</a></li>
                <li>
                    <a href="#output-queuing" aria-label="Output Queuing">Output Queuing</a></li>
                <li>
                    <a href="#parallel-iterative-matching" aria-label="Parallel Iterative Matching">Parallel Iterative Matching</a></li>
                <li>
                    <a href="#scheduling-intro" aria-label="Scheduling Intro">Scheduling Intro</a><ul>
                        
                <li>
                    <a href="#fifo-with-tail-drop" aria-label="FIFO with tail drop">FIFO with tail drop</a></li>
                <li>
                    <a href="#quality-of-service" aria-label="Quality of Service">Quality of Service</a><ul>
                        
                <li>
                    <a href="#router-support-for-congestion" aria-label="Router support for congestion">Router support for congestion</a></li>
                <li>
                    <a href="#providing-qos-guarantees-to-flows" aria-label="Providing QoS guarantees to flows">Providing QoS guarantees to flows</a></li>
                <li>
                    <a href="#fair-sharing-of-links-among-competing-flows" aria-label="Fair sharing of links among competing flows">Fair sharing of links among competing flows</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#bit-by-bit-round-robin" aria-label="Bit by Bit Round Robin">Bit by Bit Round Robin</a></li>
                <li>
                    <a href="#deficit-round-robin" aria-label="Deficit Round Robin">Deficit Round Robin</a></li>
                <li>
                    <a href="#token-bucket" aria-label="Token Bucket">Token Bucket</a></li>
                <li>
                    <a href="#leaky-bucket-token-policing" aria-label="Leaky Bucket (Token Policing)">Leaky Bucket (Token Policing)</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#lesson-7---software-defined-networking" aria-label="Lesson 7 - Software Defined Networking">Lesson 7 - Software Defined Networking</a><ul>
                        
                <li>
                    <a href="#why-did-sdn-arise" aria-label="Why did SDN arise?">Why did SDN arise?</a><ul>
                        
                <li>
                    <a href="#diversity-of-equipment" aria-label="Diversity of Equipment">Diversity of Equipment</a></li>
                <li>
                    <a href="#proprietary-technologies" aria-label="Proprietary Technologies">Proprietary Technologies</a></li></ul>
                </li>
                <li>
                    <a href="#history-of-sdns" aria-label="History of SDNs">History of SDNs</a><ul>
                        
                <li>
                    <a href="#active-networks" aria-label="Active Networks">Active Networks</a></li>
                <li>
                    <a href="#control-and-data-plane-separation" aria-label="Control and data plane separation">Control and data plane separation</a></li>
                <li>
                    <a href="#openflow-api-and-network-operating-systems" aria-label="OpenFlow API and network operating systems">OpenFlow API and network operating systems</a></li></ul>
                </li>
                <li>
                    <a href="#separating-the-data-plane-and-the-control-plane" aria-label="Separating the Data Plane and the Control Plane">Separating the Data Plane and the Control Plane</a></li>
                <li>
                    <a href="#sdn-architecture" aria-label="SDN Architecture">SDN Architecture</a><ul>
                        
                <li>
                    <a href="#four-defining-features" aria-label="Four defining features">Four defining features</a><ul>
                        
                <li>
                    <a href="#flow-based-forwarding" aria-label="Flow-based forwarding">Flow-based forwarding</a></li></ul>
                </li>
                <li>
                    <a href="#separation-of-data-plane-and-control-plane" aria-label="Separation of data plane and control plane">Separation of data plane and control plane</a></li>
                <li>
                    <a href="#network-control-functions" aria-label="Network control functions">Network control functions</a></li>
                <li>
                    <a href="#a-programmable-network" aria-label="A programmable network">A programmable network</a></li></ul>
                </li>
                <li>
                    <a href="#sdn-controller-architecture" aria-label="SDN Controller Architecture">SDN Controller Architecture</a><ul>
                        
                <li>
                    <a href="#sdn-controller-layers" aria-label="SDN Controller Layers">SDN Controller Layers</a><ul>
                        
                <li>
                    <a href="#communication-layer" aria-label="Communication Layer">Communication Layer</a></li>
                <li>
                    <a href="#network-wide-state-management-layer" aria-label="Network-wide state-management layer">Network-wide state-management layer</a></li>
                <li>
                    <a href="#interface-to-the-network-control-application" aria-label="Interface to the network-control application">Interface to the network-control application</a></li></ul>
                </li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#lesson-8---software-defined-networking-part-2" aria-label="Lesson 8 - Software Defined Networking (Part 2)">Lesson 8 - Software Defined Networking (Part 2)</a><ul>
                        
                <li>
                    <a href="#sdn-advantages-compared-to-traditional" aria-label="SDN Advantages compared to Traditional">SDN Advantages compared to Traditional</a></li>
                <li>
                    <a href="#sdn-landscape" aria-label="SDN Landscape">SDN Landscape</a></li>
                <li>
                    <a href="#sdn-architecture-1" aria-label="SDN Architecture">SDN Architecture</a><ul>
                        
                <li>
                    <a href="#infrastructure" aria-label="Infrastructure">Infrastructure</a></li>
                <li>
                    <a href="#southbound-interfaces" aria-label="Southbound Interfaces">Southbound Interfaces</a></li>
                <li>
                    <a href="#network-virtualization" aria-label="Network Virtualization">Network Virtualization</a></li>
                <li>
                    <a href="#network-operating-systems" aria-label="Network Operating Systems">Network Operating Systems</a></li>
                <li>
                    <a href="#northbound-interfaces" aria-label="Northbound Interfaces">Northbound Interfaces</a></li>
                <li>
                    <a href="#language-based-virtualization" aria-label="Language-based virtualization">Language-based virtualization</a></li>
                <li>
                    <a href="#network-programming-langauges" aria-label="Network programming langauges">Network programming langauges</a></li>
                <li>
                    <a href="#network-applications" aria-label="Network applications">Network applications</a></li></ul>
                </li>
                <li>
                    <a href="#sdn-infrastructure-layer" aria-label="SDN Infrastructure Layer">SDN Infrastructure Layer</a></li>
                <li>
                    <a href="#sdn-southbound-interrfaces" aria-label="SDN Southbound interrfaces">SDN Southbound interrfaces</a></li>
                <li>
                    <a href="#sdn-controllers---centralized-vs-distributed" aria-label="SDN Controllers - Centralized vs Distributed">SDN Controllers - Centralized vs Distributed</a><ul>
                        
                <li>
                    <a href="#centralized-controllers" aria-label="Centralized controllers">Centralized controllers</a></li>
                <li>
                    <a href="#distributed-controllers" aria-label="Distributed controllers">Distributed controllers</a></li>
                <li>
                    <a href="#open-network-operating-system" aria-label="Open Network Operating System">Open Network Operating System</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="lesson-1---introduction-history-and-internet-architecture">Lesson 1 - Introduction, History, and Internet Architecture<a hidden class="anchor" aria-hidden="true" href="#lesson-1---introduction-history-and-internet-architecture">#</a></h2>
<h3 id="history-of-the-internet">History of the internet<a hidden class="anchor" aria-hidden="true" href="#history-of-the-internet">#</a></h3>
<p>The internet began as many things in tech did, from DARPA.</p>
<p>Specifically:</p>
<ol>
<li>J.C.R. Licklider proposed the &ldquo;Galactic Network&rdquo; (1962)
<ul>
<li>Attached a computer in Stanford to a computer at MIT, thus beginning computers talking to each other</li>
</ul>
</li>
<li>The ARPANET (1969)
<ul>
<li>UCSB, UCLA, Stanford, and U of Utah interlink</li>
</ul>
</li>
<li>Network Control Protocol (NCP), an initial ARPANET host-to-host protocol (1970)
<ul>
<li>The first protocol was designed to handle increasing number of computers, first app built on this was email</li>
</ul>
</li>
<li>Inter-networking and TCP/IP (1973)
<ul>
<li>NCP became TCP/IP, IP for addressing and forwarding packets, TCP for flow control and recovery from lost packets</li>
</ul>
</li>
<li>The Domain Name System (DNS) (1983) and the World Wide Web (WWW) (1990)
<ul>
<li>As the internet exploded with content and endpoints, they needed a way to turn domains into IP addresses. In walks DNS.</li>
</ul>
</li>
</ol>
<h3 id="internet-architecture">Internet Architecture<a hidden class="anchor" aria-hidden="true" href="#internet-architecture">#</a></h3>
<p>The internet was built in layers. Each layer is supposed to have its own job, and not rely on any of the layers above or below it.</p>
<p>Think of a person as a bit of data, then watch them fly from one airport to another and you get the idea.</p>
<p><img alt="Internet as a flight path diagram" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%2011.09.35%20AM.png"></p>
<p>So there is an originally designed theoretical layer named the OSI model, which had 7 layers, and then the layers that were actually implemented, known as the Internet Protocol Stack.</p>
<p><img alt="OSI Model vs actual Internet Model" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Network%20Layers.jpg"></p>
<p>These layers are not as perfect as we would hope, specifically sometimes they do rely on the other layers or they both have methods of solving the same problem like error recovery.</p>
<p>Notice that the Session and Presentation layers disappear in the Internet Protocol Stack, those are handled in the <em>ports</em> of each network device. The logic that is accomplished in those layers still happens, just all in one place.</p>
<h4 id="application-layer">Application Layer<a hidden class="anchor" aria-hidden="true" href="#application-layer">#</a></h4>
<p>The data here is a <strong>message</strong>.</p>
<p>This is the layer we all interact with all the time.</p>
<ul>
<li>HTTP (web)</li>
<li>SMTP (e-mail)</li>
<li>FTP (transfers files between two end hosts)</li>
<li>DNS (translates domain names to IP addresses)</li>
</ul>
<p>Takes the content that we want to ship around, and does all the encoding and decoding needed to actually USE it.</p>
<h4 id="the-presentation-layer">The Presentation Layer<a hidden class="anchor" aria-hidden="true" href="#the-presentation-layer">#</a></h4>
<p>The presentation layer plays the intermediate role of formatting the information that it receives from the layer below and delivering it to the application layer. For example, some functionalities of this layer are formatting a video stream or translating integers from big endian to little endian format.</p>
<h4 id="the-session-layer">The Session Layer<a hidden class="anchor" aria-hidden="true" href="#the-session-layer">#</a></h4>
<p>The session layer is responsible for the mechanism that manages the different transport streams that belong to the same session between end-user application processes. For example, in the case of a teleconference application, it is responsible to tie together the audio stream and the video stream.</p>
<h4 id="the-transport-layer">The Transport Layer<a hidden class="anchor" aria-hidden="true" href="#the-transport-layer">#</a></h4>
<p>The data here is a <strong>segment</strong>.</p>
<p>End to End communication between hosts.</p>
<ul>
<li>Transmission Control Protocol (TCP)</li>
<li>User Datagram Protocol (UDP)</li>
</ul>
<p>TCP is better <em>connection</em>-oriented services, guarantees delivery, manages flow control, and controls congestion. This is the USPS, slow but reliable (except TCP doesn&rsquo;t lose mail like the USPS).</p>
<p>UDP is fast and guarantees <em>nothing</em>. Receivers and Senders using UDP must be able to handle segments getting dropped, delayed, or not making it entirely. But they should be faster when everything is working compared to TCP.</p>
<h4 id="the-network-layer">The Network Layer<a hidden class="anchor" aria-hidden="true" href="#the-network-layer">#</a></h4>
<p>The data here is a <strong>datagram</strong>.</p>
<p>This is where IP comes into play. This layer is responsible for connecting one computer to another, via the IP address that everyone has.</p>
<h4 id="the-data-link-layer">The Data Link Layer<a hidden class="anchor" aria-hidden="true" href="#the-data-link-layer">#</a></h4>
<p>The data here is a <strong>frame</strong>.</p>
<p>This layer is responsible for moving the frames from one node (host or router/switch) to the next node. This uses things like:</p>
<ol>
<li>Ethernet</li>
<li>Point-to-point Protocol (PPP)</li>
<li>Wi-Fi</li>
</ol>
<h4 id="the-physical-layer">The Physical Layer<a hidden class="anchor" aria-hidden="true" href="#the-physical-layer">#</a></h4>
<p>The actual hardware translation. Translating electricity into bits based on ethernet, coax, fiber, etc.</p>
<h3 id="encapsulation">Encapsulation<a hidden class="anchor" aria-hidden="true" href="#encapsulation">#</a></h3>
<p>These layers work on the idea of encapsulation and de-encapsulation. So encapsulation is to take a chunk of data, package it up, add a header to it and pass it on. Then de-encapsulation is using the headers to decode each chunk of data, until all you&rsquo;re left with is the data/message.</p>
<p><img alt="encapsulation vs de-encapsulation" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/0_tDSGidTRt7KrG6BR.webp"></p>
<p>This method is what allows people to build upon the existing infrastructure of the internet, but still make new things.</p>
<h3 id="the-end-to-end-e2e-principle">The End to End (e2e) Principle<a hidden class="anchor" aria-hidden="true" href="#the-end-to-end-e2e-principle">#</a></h3>
<p>The e2e principle shaped the internet as we know it today.</p>
<p>Essentially the principle is that 99% of the complexity should be at the ends of the communications. This allows the underlying infrastructure to be simple, but expandable, and allows people working at the different ends to iterate and create new things quickly.</p>
<p>If they had to change the underlying architecture every time they wanted to change anything it would bring development speed to a crawl.</p>
<p>Beneficial excerpt from the lecture:</p>
<p>Many people argue that the e2e principle allowed the internet to grow rapidly because evolving innovation took place at the network edge, in the form of numerous applications and a plethora of services, rather than in the middle of the network, which could be hard to modify later.</p>
<blockquote>
<p>What were the designers’ original goals that led to the e2e principle?</p>
<blockquote>
<p>Moving functions and services closer to the applications that use them increases the flexibility and the autonomy of the application designer to offer these services to the needs of the specific application.</p></blockquote></blockquote>
<blockquote>
<p>Thus, the higher-level protocol layers are more specific to an application. Whereas the lower-level protocol layers are free to organize the lower-level network resources to achieve application design goals more efficiently and independently of the specific application.</p></blockquote>
<h4 id="violations-of-e2e">Violations of e2e<a hidden class="anchor" aria-hidden="true" href="#violations-of-e2e">#</a></h4>
<p>All rules are meant to be broken.</p>
<p>Firewalls, NAT boxes, and traffic filters all break the e2e principle, and usually for good reason.</p>
<p>NAT routers provide a way to make up for the fact that there aren&rsquo;t that many IP addresses available in IPv4. Instead of EVERY device having its own worldwide public IP address, you give your home 1 IP address, and then every device behind that has its own local address.</p>
<p>This means that whenever a message is sent to your PC it goes:</p>
<p>Web &gt; Router (Public IP)&gt; End Device (local IP)</p>
<p>The router is breaking some rules of e2e, because it is intervening and inspecting data.</p>
<p>This is the notes&rsquo; reasoning for why:</p>
<blockquote>
<p>Why do NAT boxes violate the e2e principle?
The hosts behind NAT boxes are not globally addressable or routable. As a result, it is not possible for other hosts on the public Internet to initiate connections to these devices. So, if we have a host behind a NAT and a host on the public Internet, they cannot communicate by default without the intervention of a NAT box.
Some workarounds allow hosts to initiate connections to hosts that exist behind NATs. For example, Session Traversal Utilities for NAT, or STUN, is a tool that enables hosts to discover NATs and the public IP address and port number that the NAT has allocated for the applications for which the host wants to communicate. Also, UDP hole punching establishes bidirectional UDP connections between hosts behind NATs.</p></blockquote>
<h3 id="the-hourglass-shape-of-the-internet">The Hourglass Shape of the Internet<a hidden class="anchor" aria-hidden="true" href="#the-hourglass-shape-of-the-internet">#</a></h3>
<p>The internet is curvy.</p>
<p>No really, there&rsquo;s a ton on each end of it, but the middle is pretty narrow. Specifically, TCP, UDP, IP are really the backbone of literally everything. See below:</p>
<p><img alt="hourglass internet" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L1-1%20Evolutionary%20Architecture%20Model.jpg"></p>
<p>All roads lead to IP, and TCP/UDP. Researchers have actually done a lot of work to see why this is. They called it the evolutionary architecture model. They did a bunch of in depth quantifications of why/what the internet is and how they got there and drew some interesting conclusions.</p>
<p>In an ideal world where we could do it all over they came up with the following:</p>
<blockquote>
<p>Finally, in terms of future and entirely new Internet architectures, the EvoArch model predicts that even if these brand-new architectures do not have the shape of an hourglass initially, they will probably do so as they evolve, which will lead to new ossified protocols. The model suggests that one way to proactively avoid these ossification effects that we now experience with TCP/IP is for a network architect to design the functionality of each layer so that the waist is wider, consisting of several protocols that offer largely non-overlapping but general services, so that they do not compete with each other.</p></blockquote>
<h3 id="interconnecting-hosts-and-networks">Interconnecting Hosts and Networks<a hidden class="anchor" aria-hidden="true" href="#interconnecting-hosts-and-networks">#</a></h3>
<p>Talking about how to theoretically communicate between computers is important, but hardware actually makes the physical connections.</p>
<p>Those are:</p>
<h4 id="repeaters-and-hubs">Repeaters and Hubs<a hidden class="anchor" aria-hidden="true" href="#repeaters-and-hubs">#</a></h4>
<p>They operate on the physical layer (L1) as they receive and forward digital signals to connect different Ethernet segments. They provide connectivity between hosts that are directly connected (in the same network). The advantage is that they are simple and inexpensive devices, and they can be arranged in a hierarchy. Unfortunately, hosts that are connected through these devices belong to the same collision domain, meaning that they compete for access to the same link.</p>
<h4 id="bridges-and-layer-2-switches">Bridges and Layer-2 Switches<a hidden class="anchor" aria-hidden="true" href="#bridges-and-layer-2-switches">#</a></h4>
<p>These devices can enable communication between hosts that are not directly connected. They operate on the data link layer (L2) based on MAC addresses. They receive packets and forward them to the appropriate destination. A limitation is the finite bandwidth of the outputs. If the arrival rate of the traffic is higher than the capacity of the outputs, then packets are temporarily stored in buffers. But if the buffer space gets full, then this can lead to packet drops.</p>
<h4 id="routers-and-layer-3-switches">Routers and Layer-3 Switches<a hidden class="anchor" aria-hidden="true" href="#routers-and-layer-3-switches">#</a></h4>
<p>These are devices that operate on the network layer (L3).</p>
<h3 id="learning-bridges">Learning Bridges<a hidden class="anchor" aria-hidden="true" href="#learning-bridges">#</a></h3>
<p>A bridge is a piece of hardware that manages the connection between many devices, connected to the same piece of hardware.</p>
<p><img alt="learning bridge" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L1-4%20Illustration%20of%20a%20Learning%20Bridge.jpg"></p>
<p>The bridge is able to understand what devices are on port 1, what devices are on port 2, and so on. This is like a home network switch. You can connect many devices to it, and it handles knowing where the data needs to end up.</p>
<h4 id="the-looping-problem">The Looping Problem<a hidden class="anchor" aria-hidden="true" href="#the-looping-problem">#</a></h4>
<p>The problem with these bridges, is that you can create a loop.</p>
<p>if A connects to B which connects to C which connects to A, you&rsquo;ve created a loop. This can result in never ending looping!</p>
<p>This is handled by running a spanning tree algorithm. The goal of the spanning tree algorithm is to identify which ports when used will eliminate any endless looping.</p>
<p>This works by operating in rounds, and then by removing bridges from the network until you only have one path to every node. This is accomplished by running in rounds the following process:</p>
<ol>
<li>Every node sends:
<ul>
<li>Sender Node ID</li>
<li>Root ID as perceived by sender</li>
<li>Distance from root node</li>
</ul>
</li>
<li>Each node selects the best configuration in order of
<ul>
<li>If root of the one configuration has a smaller ID</li>
<li>If roots have equal IDs choose one with smaller distance to the root</li>
<li>If they have the same distance, choose configuration with smallest sender ID</li>
</ul>
</li>
<li>A node stops sending configuration messages over a link (port) when it receives a configuration message from a neighbor that is:
<ul>
<li>either closer to the root</li>
<li>has the same distance from the root, but it has a smaller ID.</li>
</ul>
</li>
</ol>
<p>We can see this process completed in the following images:</p>
<p><img alt="pre-tree-span" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%2011.36.30%20AM.png"></p>
<p>Then after tree spanning:</p>
<p><img alt="post-tree-spanning" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%2011.38.09%20AM.png"></p>
<h2 id="lesson-2---the-transport-layer-tcp">Lesson 2 - The Transport Layer (TCP)<a hidden class="anchor" aria-hidden="true" href="#lesson-2---the-transport-layer-tcp">#</a></h2>
<p>This lesson is going to talk about the actual protocol responsible for transporting data from one location to another, TCP. The logical connection between two hosts is done in the transport layer.</p>
<p>The transport layer receives a message from the application layer and appends its own header on to it. This is known as a segment. The segment is then sent to the Network layer where it happily bounces through all the routers, bridges, and switches that might be on its path.</p>
<h3 id="transport-layer-intro">Transport Layer intro<a hidden class="anchor" aria-hidden="true" href="#transport-layer-intro">#</a></h3>
<p>Why do we need a transport layer? Why not just send messages directly from the application layer to the network layer? Because the network layer guarantees <strong>nothing</strong>. The transport layer guarantees delivery, and data integrity in a way that wouldn&rsquo;t have been done otherwise.</p>
<p>As mentioned previously there are two main transport layer protocols User Datagram Protocol (UDP) and Transmission Control Protocol (TCP).</p>
<p>UDP just tries to quickly send data, and doesn&rsquo;t do much else. As such it provides no guarantees and puts the responsibility on the application layer to do things like verify integrity and handle dropped messages.</p>
<p>TCP on the other hand does have these extra bells and whistles built in and thus it is much more reliable, if not a tad slower than UDP.</p>
<h3 id="multiplexing">Multiplexing<a hidden class="anchor" aria-hidden="true" href="#multiplexing">#</a></h3>
<p>Multiplexing is the ability for many hosts to use the same network simultaneously. Consider two computers browsing the internet at the same time, or better yet, a computer that is simultaneously browsing the internet and streaming music, it has two incoming data sources, and used in two different ways.</p>
<p>We need to be able to handle this complexity. The Transport layer uses ports to do this. Each application gets one port, and listens only to that port.</p>
<p>There is <strong>Connectionless</strong> and <strong>Connection Oriented</strong> multiplexing. One based on a constant connection, and one is not.</p>
<p>We have names for each direction of this multiplexing operation.</p>
<p>Demultiplexing - Delivering data to the appropriate socket.</p>
<p>Multiplexing - Taking data from all the sockets and putting it into the network layer.</p>
<h3 id="connectionless-multiplexing">Connectionless Multiplexing<a hidden class="anchor" aria-hidden="true" href="#connectionless-multiplexing">#</a></h3>
<p>Connectionless multiplexing is the simpler case. The transport layer has a segment which has the content, a source and source port, and a destination and a destination port. It receives the data from the source port, and makes its best effort at delivering to the destination port.</p>
<p><img alt="Connectionless Multiplexing" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%209.34.42%20PM.png"></p>
<p>If the destination receives it, great, the network layer will route it to the correct port, and then the message will have been successfully delivered.</p>
<p>These are UDP sockets. It&rsquo;s very direct, with no oversight as to what actually happens to the message.</p>
<h3 id="connection-oriented-multiplexing">Connection Oriented Multiplexing<a hidden class="anchor" aria-hidden="true" href="#connection-oriented-multiplexing">#</a></h3>
<p>Connection Oriented multiplexing brings in a lot more complexity.</p>
<p><img alt="Connection Oriented Multiplexing" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%209.36.30%20PM.png"></p>
<p>TCP requires going through a TCP server. The TCP server has a listener process that waits for incoming connection requests, and when it gets it handles setting everything up so that the destination is ready to receive the message.</p>
<blockquote>
<p>Note: If a server has many clients contacting it on the same port, it&rsquo;s not an issue because they have unique IP addresses (hopefully) and they can distinguish the difference between the two that way.</p></blockquote>
<h3 id="a-word-on-udp">A word on UDP<a hidden class="anchor" aria-hidden="true" href="#a-word-on-udp">#</a></h3>
<p>UDP lacks reliability of TCP mainly because it doesn&rsquo;t require establishing a connection.</p>
<p>That lack of reliability makes it better for the following reasons:</p>
<ol>
<li>No congestion control - No process watches every packet to make sure it should be sent</li>
<li>No connection management - We don&rsquo;t have to wait for a socket to be opened, so it just sends quickly</li>
</ol>
<p>Both of these result in lower latency transmission, which is good for some things. Things like multiplayer video games, DNS servers, and other networking hosts, all like to use higher speed protocols.</p>
<p>This puts the onus on the developers on each end to ensure quality, and handle if errors occur, but when things are working well, then things are very speedy.</p>
<p><img alt="udp makeup" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L2%20Diagrams-14.png"></p>
<p>The one quality mechanism UDP provides is a checksum, so you can in fact check that the data that&rsquo;s sent is what it was supposed to be. It creates a checksum by adding together the bits of the source port, destination port and the length of the packet. It then performs a ones complement. That is the checksum.</p>
<p>The receiver takes the source port, destination port, length of packet, and the checksum and adds them all together. Because the checksum is the ones complement, when they are added together it should end up as all ones.</p>
<h3 id="tcp">TCP<a hidden class="anchor" aria-hidden="true" href="#tcp">#</a></h3>
<h4 id="three-way-handshake">Three way handshake<a hidden class="anchor" aria-hidden="true" href="#three-way-handshake">#</a></h4>
<pre><code>Step 1: The TCP client sends a special segment (containing no data) with the SYN bit set to 1. The client also generates an initial sequence number (client_isn) and includes it in this special TCP SYN segment.
</code></pre>
<p>Step 2: The server, upon receiving this packet, allocates the required resources for the connection and sends back the special &ldquo;connection-granted&rdquo; segment which we call SYNACK segment. This packet has the SYN bit set to 1, the acknowledgement field of the TCP segment header set to client_isn+1, and a randomly chosen initial sequence number (server_isn) for the server.</p>
<p>Step 3: When the client receives the SYNACK segment, it also allocates buffer and resources for the connection and sends an acknowledgment with SYN bit set to 0.</p>
<p><img alt="three-way-handshake" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/2%20TCP%20Three-Way%20Handshake.jpg"></p>
<h4 id="connection-tear-down">Connection tear down<a hidden class="anchor" aria-hidden="true" href="#connection-tear-down">#</a></h4>
<p>Connection Teardown</p>
<p>Step 1: When the client wants to end the connection, it sends a segment with FIN bit set to 1 to the server.</p>
<p>Step 2: The server acknowledges that it has received the connection closing request and is now working on closing the connection.</p>
<p>Step 3: The server then sends a segment with FIN bit set to 1, indicating that connection is closed.</p>
<p>Step 4: The client sends an ACK for it to the server. It also waits for some time to resend this acknowledgment in case the first ACK segment is lost.</p>
<p><img alt="teardown" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%209.47.18%20PM.png"></p>
<h3 id="reliable-transmission-tcp">Reliable Transmission (TCP)<a hidden class="anchor" aria-hidden="true" href="#reliable-transmission-tcp">#</a></h3>
<p>TCP guarantees all packets delivered in order. This is a very helpful reliability for developers to build on.</p>
<p>To do this the sender must know what the receiver successfully got. This is accomplished via ARQ (Automatic Repeat Request). If a sender doesn&rsquo;t get a message that ARQ1 was received in a certain timeframe, then it will re-send it.</p>
<p><strong>Stop and Wait ARQ</strong></p>
<p>Guess how long it should take, if you don&rsquo;t get a response, send it again. This can work but is tricky. If you send too much you&rsquo;re retransmitting for no reason, and wait too long your connection is slow.</p>
<p>TCP uses <strong>Selective ACK</strong> which basically waits for the receiver to say hey I didn&rsquo;t get this packet yet, and if it reaches a certain threshold like 3, then it will quickly resend that particular packet. This allows most of the time to be spent actively sending data, and the ability to recover from dropped packets.</p>
<p>This does require the ability to buffer packets until you have everything you need in order.</p>
<h3 id="transmission-control-tcp">Transmission Control (TCP)<a hidden class="anchor" aria-hidden="true" href="#transmission-control-tcp">#</a></h3>
<p>Deciding how much of a link bandwidth to use is a bit complicated. If you send too much for the receiver that could be an issue, or maybe the network can&rsquo;t handle it, or any other amount of things that could go wrong.</p>
<p>So TCP implements a couple things to help that.</p>
<h4 id="flow-control">Flow Control<a hidden class="anchor" aria-hidden="true" href="#flow-control">#</a></h4>
<p>Flow control is where TCP tries to identify the receiver&rsquo;s buffer that it is receiving data with, and tries to match the sender window size to that. Every ACK message includes a <code>rwnd</code> value which says how much buffer space is available.</p>
<p>The sender uses this value to ensure it never sends more bytes than is available in the receiver buffer.</p>
<p>If this value hits zero it would stop, but TCP instead sends packets of 1 byte until it gets a response with a <code>rwnd</code> greater than zero.</p>
<h4 id="congestion-control">Congestion Control<a hidden class="anchor" aria-hidden="true" href="#congestion-control">#</a></h4>
<p>Congestion control is making sure we don&rsquo;t overload any of the links on the way from one host to another.</p>
<p>Good congestion control is:</p>
<ul>
<li>Efficient - use most of the network</li>
<li>Fair - everyone gets equal amounts</li>
<li>Low delay - Low delay is good for things that need to have small lag like video conferences</li>
<li>Fast convergence - everyone gets their bandwidth quickly</li>
</ul>
<h5 id="network-assisted">Network Assisted<a hidden class="anchor" aria-hidden="true" href="#network-assisted">#</a></h5>
<p>Network assisted congestion control relies on pieces of the network sending feedback about what&rsquo;s happening. This could fail when the network is heavily congested though, kind of rendering it useless.</p>
<h5 id="end-to-end">End to End<a hidden class="anchor" aria-hidden="true" href="#end-to-end">#</a></h5>
<p>End to end congestion control gets nothing from the network and instead infers congestion from the hosts. This supports the general principle of making the complexity be at the ends of the networks.</p>
<p>This is mostly done via packet delay (how long did it take to get here) and packet loss (how many times do I need to resend). With these two things you have a rough understanding of network performance at any given moment.</p>
<p>It employs a congestion window, a number indicating roughly how much space is left in the network. This increases until congestion is detected, and then the window is made smaller to reduce congestion.</p>
<p>Ultimately the max size of a TCP packet is the minimum of the receiver buffer and the congestion window.</p>
<p>There are many different methods of increasing congestion window size:</p>
<ul>
<li>Additive</li>
<li>Multiplicative</li>
<li>TCP Reno</li>
<li>AIMD</li>
</ul>
<p>Many of these employ &ldquo;Slow start&rdquo; where they start at a low-ish speed and ramp up. This protects from overwhelming the network right at the start. With timeouts or dropped connections being common you can see why this would be useful.</p>
<p>TCP isn&rsquo;t always fair, but using some of these congestion methods will do a pretty good job of it.</p>
<h4 id="tcp-throughput">TCP Throughput<a hidden class="anchor" aria-hidden="true" href="#tcp-throughput">#</a></h4>
<p>TCP Throughput looks like a sawtooth because of these congestion control mechanisms.</p>
<p>It gets up to the limit, then drops off, then gets up to the limit then drops off.</p>
<p><img alt="throughput" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%2010.17.59%20PM.png"></p>
<h2 id="lesson-3---intradomain-routing-the-network-layer">Lesson 3 - Intradomain Routing (The Network Layer)<a hidden class="anchor" aria-hidden="true" href="#lesson-3---intradomain-routing-the-network-layer">#</a></h2>
<p>This session focuses on the act of routing on the network layer in a single domain. Ideally we understand what it takes for two hosts to share data by the end of this.</p>
<p>We&rsquo;ll talk about:</p>
<ul>
<li>Intradomain Routing Algorithms
<ul>
<li>Link state</li>
<li>Distance vector</li>
</ul>
</li>
<li>Intradomain Protocols
<ul>
<li>Open Shortest Path First (OSPF)</li>
<li>Routing Information Protocol (RIP)</li>
</ul>
</li>
</ul>
<h3 id="routing">Routing<a hidden class="anchor" aria-hidden="true" href="#routing">#</a></h3>
<p>Given two hosts that share the same default router (first-hop router) we know that one host will send a packet to the default router, but what happens next?</p>
<p>In a network with many routers, whenever a router receives a packet, it must consult the forwarding table it maintains, and send the packet to the next router in line. This is referred to as forwarding and is not necessarily the same as routing.</p>
<p>Routing is the act of determining the best path to be traveled from one location to another. Intradomain routing is what we will focus on and it is what happens when both hosts are in the same administrative domain.</p>
<p>Interior Gateway Protocols (IGP) are what handle this type of routing. The two major types we&rsquo;ll cover are  link-state and distance-vector routing algorithms. They are graph theory algorithms with edges and nodes.</p>
<h4 id="link-state-routing">Link State Routing<a hidden class="anchor" aria-hidden="true" href="#link-state-routing">#</a></h4>
<p>Surprise, Dijkstra&rsquo;s algorithm is here again.</p>
<p>In link state, all link costs are known and the network topology is also fully known.</p>
<p>From the lecture directly.</p>
<blockquote>
<p>Let’s introduce some basic terminology. By u, we represent our source node. By v, we represent every other node in the network. By D(v), we represent the cost of the current least cost path from u to v.  By p(v), we represent the previous node along the current least cost path from u to v. By c(u,v), we represent the cost from u to directly attached neighbor v. By N&rsquo;, we represent the subset of nodes along the current least-cost path from u to v.</p></blockquote>
<p><img alt="pseudocode for link-state algo" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L3_1%20Link%20State%20Algorithm.jpg"></p>
<p>Basically we initialize with either:</p>
<ul>
<li>Known cost because it&rsquo;s a link directly connected to the node we&rsquo;re initializing</li>
<li>Infinity cost, because we know it will be less than that but we have something to compare against</li>
</ul>
<p>Then we continue looping through the network, looking for a path with lower costs than our current cost, until we don&rsquo;t find one. This is a fun application of Dijkstra&rsquo;s algorithm, where each router essentially computes Dijkstra&rsquo;s algorithm from itself to all other routers in the network.</p>
<p>This is a pretty costly algorithm at O(n^2) complexity. It also requires that you know everything about the network which is probably why this is intradomain and not interdomain.</p>
<h4 id="distance-vector-routing">Distance Vector Routing<a hidden class="anchor" aria-hidden="true" href="#distance-vector-routing">#</a></h4>
<p>The DV algorithm is iterative, asynchronous, and distributed.</p>
<p>DV is based on the Bellman Ford algorithm. Every node maintains a distance vector to all of the other nodes, and it occasionally shares that information. When a node receives a new distance vector they use it to update their own vector.</p>
<p>The Bellman Ford (BF) equation is the heart of each update: <code>Dx(y) = minv{c(x,v) + Dv(y)}</code></p>
<p><img alt="BF illustration" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/BF-updated.png"></p>
<p>See the pseudocode below:</p>
<p><img alt="DV pseudocode" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%205.36.51%20PM.png"></p>
<p>So essentially, continuously the nodes maintain a list of costs for routes to certain nodes, and these costs are updated whenever nodes send their costs. So instead of every node needing to know every cost, it allows the nodes to only know and focus on the costs of its immediate neighbors, and then relies on other nodes sending its current list of costs occasionally.</p>
<p>This is different from Link State routing because it is distributed, but they are all still computing the most efficient path through the tree.</p>
<h5 id="a-simple-example">A simple example<a hidden class="anchor" aria-hidden="true" href="#a-simple-example">#</a></h5>
<p><a href="Screen%20Shot%202020-01-17%20at%205.40.22%20PM.png">initialization</a></p>
<p><img alt="second iteration" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%205.42.05%20PM.png"></p>
<p><img alt="third iteration" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%206.56.28%20PM.png"></p>
<h5 id="pitfalls-of-dv">Pitfalls of DV<a hidden class="anchor" aria-hidden="true" href="#pitfalls-of-dv">#</a></h5>
<p>What if the link cost changes? In some cases this is handled quickly, and in other cases it can lead to a &ldquo;count-to-infinity&rdquo; problem.</p>
<p><strong>Say a link cost decreases:</strong></p>
<p><img alt="link decrease" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%206.59.26%20PM-1.png"></p>
<ol>
<li>At time t0, y detects that cost to x has changed from 4 to 1, so it updates its distance vector and sends it to its neighbors.</li>
<li>At time t1, z receives the update from y. Now z thinks it can reach x through y with a cost of 2, so it sends its new distance vector to its neighbors.</li>
<li>At time t2, y receives the update from z. Y does not change its distance vector, so it does not send any update.</li>
</ol>
<p>The update is fully propagated pretty quickly.</p>
<p><strong>Say a link cost increases:</strong></p>
<p><img alt="link increase" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.00.44%20PM.png"></p>
<ol>
<li>At t0, y detects that the cost has changed, and now it will update its distance vector thinking that it can still reach x through z with a total cost of 5+1=6.</li>
<li>At t1, we have a routing loop where z thinks it can reach x through y, and y thinks it can reach x through z. This will cause the packets to be bouncing back and forth between y and z until their tables change.</li>
<li>Nodes z and y keep updating each other about their new cost to reach x. For example, y computes its new cost to be 6 and then informs z. Then z computes its new cost to be 7, and then informs y, and so on.</li>
</ol>
<p>The key here is that Node Z, is saying Hey I can definitely reach X, and the cost as Z knows it, is 5. So Node Y says sweet, if I go through Node Z, it&rsquo;s the cost of our link (1) + the cost of Z &gt; X, but the cost of Z &gt; X isn&rsquo;t actually 5 anymore, it&rsquo;s 50.</p>
<p>So they have to iterate until the cost is greater than 50, at which point it will use the real path.</p>
<p>The reason that we can&rsquo;t directly say, &ldquo;hey no the link cost increased by a ton your table is wrong&rdquo; is because we don&rsquo;t know the structure of the network. All we know is X &gt; Y costs a certain value, with no understanding of which links do that.</p>
<p>So instead we have to keep iterating through until the costs are actually updated. This can create a lot of packet bouncing.</p>
<p>This is solved by something called <em>poison reverse</em> where a node says a cost is infinity if it isn&rsquo;t the cheapest path to a certain node. This only works for 2 nodes.</p>
<h4 id="routing-information-protocol-rip">Routing Information Protocol (RIP)<a hidden class="anchor" aria-hidden="true" href="#routing-information-protocol-rip">#</a></h4>
<p>RIP is based on Distance Vectors, but instead of maintaining vectors of distances, they instead maintain entire routing tables with one row for each subnet.</p>
<h4 id="open-shortest-path-first">Open Shortest Path First<a hidden class="anchor" aria-hidden="true" href="#open-shortest-path-first">#</a></h4>
<p>OSPF is a routing protocol that uses link-state to find the best path between source and destination routers. It was created after RIP by ISPs with extra things like authentication messages, multiple same-cost paths, and support for hierarchical routing within a single domain.</p>
<p>OSPF will have one AS (Autonomous System) as the backbone, and routes to other OSPF AS on the network. To go from one Area to another, they must move through the backbone router.</p>
<p>There&rsquo;s a lot more in the notes but tbh they&rsquo;re pretty complicated! It seems that these routers in the send Link State advertisements which communicates the routers local topology. This results in a complete network map, that updates when the network updates.</p>
<p>These LSAs are processed as so:</p>
<p><img alt="How the router processes" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-19%20at%207.18.54%20PM-2.png"></p>
<h3 id="hot-potato-routing">Hot Potato Routing<a hidden class="anchor" aria-hidden="true" href="#hot-potato-routing">#</a></h3>
<p>Sometimes you have to leave your local network, and enter into interdomain routing.</p>
<p>To do this usually you have to find an egress point and the process of finding that egress point is an intradomain routing problem.</p>
<p>Generally hot potato routing is referring to finding the closest/least costly egress point in a given network. The hot potato part of it is that there are many egress points and which one is chosen is not always clear. This routing method of finding the shortest path does make things consistent instead of sometimes going to egress A and sometimes going to egress B.</p>
<h2 id="lesson-4---interdomain-routing-and-as-relationships">Lesson 4 - Interdomain Routing and AS Relationships<a hidden class="anchor" aria-hidden="true" href="#lesson-4---interdomain-routing-and-as-relationships">#</a></h2>
<p><a href="#lesson-3---intradomain-routing-the-network-layer">Lesson 3</a> focused on intradomain routing, but what about when we need to leave our domain?</p>
<p>The internet is an ecosystem of thousands if not millions of networks operated independently, but still connected to each other. This lesson we&rsquo;ll learn about BGP.</p>
<h3 id="the-internet">The Internet<a hidden class="anchor" aria-hidden="true" href="#the-internet">#</a></h3>
<p><img alt="Internet Ecosystem" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.09.27%20PM.png"></p>
<p>The internet started very hierarchical but has been flattening as more IXPs and CDNs have been added.</p>
<p>Each of the types of infrastructure above can be an Autonomous System (AS) which is a group of routers who are under the same authority. I think like, my house technically is an AS that I manage, but not sure about that.</p>
<p>Routing between AS&rsquo;s relies on Border Gateway Protocol (BGP) to exchange information with each other.</p>
<h3 id="as-ecosystem">AS Ecosystem<a hidden class="anchor" aria-hidden="true" href="#as-ecosystem">#</a></h3>
<p>There&rsquo;s two main interactions between AS&rsquo;s.</p>
<ul>
<li>Provider-Customer - Like me paying my ISP for internet</li>
<li>Peer - One ISP routing to another ISP because they need their network to get to location x. This requires traffic levels to be pretty similar so that one party isn&rsquo;t gaining more than the other.</li>
</ul>
<p><img alt="isp map" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L4%20Diagram%20Recreations%20Updated%20Ben-1.png"></p>
<p>See how green cloud ISP can&rsquo;t peer with orange cloud ISPs, because it&rsquo;s too large. But all the orange cloud ISPs are peer relationships because they&rsquo;re similarly sized.</p>
<p>Providers can charge fixed rate or based on usage, totally up to them.</p>
<h3 id="internet-business">Internet Business<a hidden class="anchor" aria-hidden="true" href="#internet-business">#</a></h3>
<p>Importing and Exporting routes is the heart of BGP. Deciding which import/exports to operate and make available is a technical and business decision.</p>
<h4 id="exporting-routes">Exporting Routes<a hidden class="anchor" aria-hidden="true" href="#exporting-routes">#</a></h4>
<p>Export routes come from:</p>
<ul>
<li>Routes from customers</li>
<li>Routes from providers</li>
<li>Routes from peers</li>
</ul>
<p>Which of these are chosen to advertise to other AS&rsquo;s is a business decision.</p>
<h4 id="importing-routes">Importing Routes<a hidden class="anchor" aria-hidden="true" href="#importing-routes">#</a></h4>
<p>Again, they&rsquo;re picky based on which routes are going to bring the most value to the business.</p>
<p>Usually it&rsquo;s this order:</p>
<ol>
<li>An AS wants to ensure that routes toward its customers do not traverse other ASes, unnecessarily generating costs.</li>
<li>An AS uses routes learned from peers since these are usually &ldquo;free&rdquo; (under the peering agreement).</li>
<li>An AS resorts to importing routes learned from providers only when necessary for connectivity since these will add to costs.</li>
</ol>
<h3 id="border-gateway-protocol-bgp">Border Gateway Protocol (BGP)<a hidden class="anchor" aria-hidden="true" href="#border-gateway-protocol-bgp">#</a></h3>
<h4 id="bgp-design-goals">BGP Design Goals<a hidden class="anchor" aria-hidden="true" href="#bgp-design-goals">#</a></h4>
<ul>
<li>Scalability - The internet will never stop growing, try to handle it</li>
<li>Express routing policies (ERP) - Allows ASes to make routing decisions and do it privately</li>
<li>Allow cooperation among ASes - Allows ASes to make their own decision and let business drive the connections</li>
<li>Security - This was added on as it was found to be necessary</li>
</ul>
<h4 id="bgp-basics">BGP Basics<a hidden class="anchor" aria-hidden="true" href="#bgp-basics">#</a></h4>
<p><strong>BGP Peers</strong> send messages over <strong>BGP Sessions</strong> over a semi-permanent TCP port connection. A session is initiated from one router to another with an OPEN message which is then followed by sharing routing tables.</p>
<p>eBGP is an external BGP session, between two ASes. iBGP is an internal BGP session, in a singular AS.</p>
<p><img alt="eBGP and iBGP" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.28.06%20PM.png"></p>
<p>Once the session is started they use:</p>
<ul>
<li>UPDATE - if any updates are made to the Route table, share it</li>
<li>KEEPALIVE - Keeps session going, no changes</li>
</ul>
<p>BGP relies on prefix reachability, a list of IP addresses that prefix all the destinations. This is how the export and import routes are communicated.</p>
<p>Other parameters:</p>
<p><strong>Path Attributes</strong> are also shared with other providers with parameters like:</p>
<ul>
<li>ASPATH - Contains Autonomous System Number and helps choose between multiple routes and stops loops</li>
<li>NEXT HOP - Provides the next router&rsquo;s IP address so that other routers can store in their forwarding table the best path</li>
</ul>
<h4 id="ibgp-vs-ebgp">iBGP vs eBGP<a hidden class="anchor" aria-hidden="true" href="#ibgp-vs-ebgp">#</a></h4>
<p>iBGP is meant for sharing paths of how to get out of an AS, it&rsquo;s not an IGP that gives intradomain networking, but instead a way of telling nodes inside of AS how they can communicate with external ASes.</p>
<p>eBGP is the method of communicating between ASes the available external routes.</p>
<p><img alt="ebgp vs abgp" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L4%20Diagram%20Recreations%20Updated%20Ben-3.png"></p>
<h4 id="bgp-router-process">BGP Router Process<a hidden class="anchor" aria-hidden="true" href="#bgp-router-process">#</a></h4>
<p><img alt="bgp routing" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.48.26%20PM.png"></p>
<p>When a router receives a new list of policies it takes them all in, and then has a decision making process to determine the best routes for it to use.</p>
<p>The operator of this router can determine what is important to them (usually cost related) and make decisions based on that. Here&rsquo;s an example decision process.</p>
<p><img alt="BGP router decision chart" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.44.30%20PM.png"></p>
<p>Important decision makers are:</p>
<p>LocalPref - Decided by operating AS, things like choose the cheaper route (customers first, then peers, etc)
MED - Determined by the neighboring AS, determine which link they would prefer you to use</p>
<h4 id="bgp-issues">BGP Issues<a hidden class="anchor" aria-hidden="true" href="#bgp-issues">#</a></h4>
<p>Two main things:</p>
<ul>
<li>Misconfiguration - Improper configuration can bring networks down for a lot of reasons
<ul>
<li>Can be reduced by limiting size of tables and number of changes</li>
</ul>
</li>
<li>Scalability - Large routing tables are problematic.</li>
</ul>
<p>A lot of work went into reducing routing table sizes. They will do things like use default routing, route aggregation, and something called <strong>flap damping</strong>. Flap damping is a technique that limits the number of updates to a given prefix over time. If it goes over a certain limit, it will silence that prefix&rsquo;s updates until a set time has passed.</p>
<p>This is configurable by domain, allowing you to choose when and where you will accept a lot of updates and when you won&rsquo;t.</p>
<h3 id="peering-at-ixps">Peering at IXPs<a hidden class="anchor" aria-hidden="true" href="#peering-at-ixps">#</a></h3>
<p>ASes peer with each other, where do they do that? One place is an Internet Exchange Point (IXP). They are purpose built infrastructure to facilitate peering.</p>
<p>Internet Exchange Points (IXPs) are critical physical infrastructures where Autonomous Systems (ASes) can directly interconnect and exchange traffic. These facilities are typically housed in secure, well-powered data centers and consist of robust switch fabrics to ensure reliability and fault tolerance. ASes participating in IXPs must have a public ASN, a BGP-capable router, and agree to the IXP’s terms. Once connected, ASes can publicly peer and exchange traffic settlement-free, paying only for connection and port usage, not traffic volume. This makes IXPs more cost-effective and efficient than traditional third-party traffic routing.</p>
<p>IXPs have grown in popularity due to their ability to handle massive volumes of traffic and play a crucial role in improving network performance and reducing costs by keeping local traffic local. They also offer defensive benefits, such as DDoS mitigation, since they observe a large portion of Internet traffic and can help stop malicious activity before it reaches the intended target. Furthermore, IXPs provide a rich environment for research and innovation, particularly in areas like security and Software Defined Networking (SDN), and are evolving into hubs of technology development beyond just traffic exchange.</p>
<p>In addition to public and private peering services, IXPs offer a wide range of features such as route servers, SLAs, remote peering via resellers, mobile network peering, and DDoS blackholing. Some IXPs also provide free value-added services like DNS root servers and time distribution. These offerings, along with the ability to form fast and scalable peering agreements, have made IXPs essential infrastructure for global Internet connectivity, performance, and resilience.</p>
<h4 id="route-servers">Route Servers<a hidden class="anchor" aria-hidden="true" href="#route-servers">#</a></h4>
<p>IXPs use route servers to handle the large number of ASes that they service.</p>
<p>In summary, a Route Server (RS) does the following:</p>
<ul>
<li>It collects and shares routing information from its peers or participants of the IXP that connect to the RS.</li>
<li>It executes its own BGP decision process and re-advertises the resulting information (e.g., best route selection) to all RS&rsquo;s peer routers.</li>
</ul>
<p>It&rsquo;s basically offloading all the configuration work from the AS to the IXP operator. It&rsquo;s what allows people like me to buy a domain and get reliable routing from anywhere in the world to it.</p>
<h2 id="lesson-5-and-6---router-design-and-algorithms">Lesson 5 and 6 - Router Design and Algorithms<a hidden class="anchor" aria-hidden="true" href="#lesson-5-and-6---router-design-and-algorithms">#</a></h2>
<p>Routers are what do the heavy lifting for actually moving data from one point to another. The prior lessons established many pieces and parts of that puzzle.</p>
<p>In short, a router needs to be able to receive an incoming packet on an input link, read its destination, and then send it to the correct output link. Simple in theory, difficult in practice, and more importantly, at scale. Then add on top of just forwarding requirements things like security requirements, quality of service, and other more advanced things, the job becomes difficult.</p>
<h3 id="router-components">Router Components<a hidden class="anchor" aria-hidden="true" href="#router-components">#</a></h3>
<p><strong>The main job of a router is to implement the forwarding plane functions and the control plane functions.</strong></p>
<h4 id="forwarding-switching-function">Forwarding (Switching) function<a hidden class="anchor" aria-hidden="true" href="#forwarding-switching-function">#</a></h4>
<p>The action of transferring a packet from an incoming link, to an outbound link. This should be very fast, on the scale of a few nanoseconds. I believe this is what a nice simple 5 port network switch is, and that&rsquo;s all it is.</p>
<p><img alt="what&rsquo;s in a router" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-2.png"></p>
<p><img alt="what&rsquo;s in a router zoomed" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-3.png"></p>
<p><strong>Input Ports</strong></p>
<p>Input ports do the following:</p>
<ol>
<li>Physically terminate the link</li>
<li>Processes datalink (decapsulating)</li>
<li>Performs lookup function, consulting forwarding table to determine where it should go</li>
</ol>
<p><strong>Switching Fabric</strong>*</p>
<p>This actually moves the packet from the input port, to the output port, using the results from the input port that tells where the packet needs to go.</p>
<p>Three types of switching fabrics:</p>
<ul>
<li>Memory</li>
<li>Bus</li>
<li>Crossbar</li>
</ul>
<p><strong>Output ports</strong></p>
<p>All this does is receive the data from the switching fabric and send it. Specifically:</p>
<ol>
<li>Queue the packets for transfer</li>
<li>Encapsulate the packets</li>
<li>Send them over the physical output port</li>
</ol>
<p><img alt="output port" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-4-1.png"></p>
<h4 id="control-plane-function">Control Plane function<a hidden class="anchor" aria-hidden="true" href="#control-plane-function">#</a></h4>
<p>The control plane refers to:</p>
<ul>
<li>Implementing routing protocols (like the ones from earlier sessions)</li>
<li>Maintaining routing tables</li>
<li>Computing the forwarding table</li>
</ul>
<p>All of these functions are written software in the routing processor, or in the case of an SDN, could be implemented by a remote router.</p>
<p><img alt="alt text" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-5.png"></p>
<h3 id="router-architecture">Router Architecture<a hidden class="anchor" aria-hidden="true" href="#router-architecture">#</a></h3>
<p>Model of a router:</p>
<p><img alt="router architecture overview" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.00.52%20PM.png"></p>
<p>Using the image as a guide we can walk through the path that common tasks take. First we lookup the destination of an incoming packet.</p>
<ol>
<li>Lookup
<ol>
<li>Packet arrives at input link</li>
<li>Lookup output link in forwarding table (Forwarding Information Base FIB)</li>
<li>Resolve any ambiguities
<ul>
<li>Longest Prefix matching</li>
<li>Packet classification</li>
</ul>
</li>
</ol>
</li>
<li>Switching
<ul>
<li>After lookup is completed the packet is switched, from input link to output link. Modern routers use crossbar switches for this task.</li>
<li><em>Some complications occur when many inputs want to send to the same output</em></li>
</ul>
</li>
<li>Queuing
<ul>
<li>
<p>Using various queuing logics, if an output port is congested, each packet enters the queue to wait its turn to use the hardware.</p>
</li>
<li>
<p>Types of queues used:</p>
<ul>
<li>First In First Out (FIFO)</li>
<li>Weighted Fair Queuing</li>
</ul>
</li>
</ul>
</li>
<li>Header Validation and Checksum
<ul>
<li>Check version number, validate checksum, decrement ttl</li>
</ul>
</li>
<li>Route processing
<ul>
<li>Build route using protocols like RIP, OSPF, and BGP</li>
</ul>
</li>
<li>Protocol Processing (Including:)
<ul>
<li>Simple Network Management Protocol (SNMP) - Counters for remote inspection</li>
<li>TCP/UDP for remote communication</li>
<li>Internet Control Message Protocol (ICMP) for sending error messages (eg: TTL is exceeded)</li>
</ul>
</li>
</ol>
<h3 id="switching-fabric">Switching Fabric<a hidden class="anchor" aria-hidden="true" href="#switching-fabric">#</a></h3>
<p>The switching fabric is where most of the logic is implemented in a router, forwarding packets from source to destination.</p>
<p>There are several ways to accomplish this.</p>
<h4 id="switching-via-memory">Switching via memory<a hidden class="anchor" aria-hidden="true" href="#switching-via-memory">#</a></h4>
<p>Physical I/O ports operate as I/O devices in an operating system.</p>
<ol>
<li>Input port receives packet</li>
<li>Send interrupt to routing processor</li>
<li>Packet written to memory</li>
<li>Processor looks at header to get destination address</li>
<li>Lookup output port from forwarding table</li>
<li>Copy from memory into output ports buffer</li>
</ol>
<p><img alt="switching via memory diagram" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.08.02%20PM-1.png"></p>
<h4 id="switching-via-bus">Switching via bus<a hidden class="anchor" aria-hidden="true" href="#switching-via-bus">#</a></h4>
<p>Bus based switching doesn&rsquo;t require a processor.</p>
<ol>
<li>Input port receives packet</li>
<li>Input port marks which destination port it should be for with an internal header</li>
<li>Send it to the bus where all output ports receive the packet
<ul>
<li>Only the port it&rsquo;s supposed to go to accepts it</li>
</ul>
</li>
</ol>
<p>This design is limited by the speed of the bus as only one packet can traverse it at a time.</p>
<p><img alt="switching via bus diagram" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.09.47%20PM.png"></p>
<h4 id="switching-via-interconnection-network">Switching via interconnection network<a hidden class="anchor" aria-hidden="true" href="#switching-via-interconnection-network">#</a></h4>
<p>A crossbar switch is an interconnection network that connects N inputs to N outputs using 2N buses.</p>
<p><img alt="crossbar network diagram" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Crossbar%20Network.png"></p>
<p>This allows many packets at once to traverse the switching fabric, as long as they have different input and output ports. This is done by giving the switching fabric control of the buses, and closing the connections to make the links only when there is a packet that needs to make that journey.</p>
<h3 id="router-challenges">Router Challenges<a hidden class="anchor" aria-hidden="true" href="#router-challenges">#</a></h3>
<p>There are a couple fundamental challenges to overcome for routers at scale.</p>
<ol>
<li>Bandwidth and Internet population scaling
<ul>
<li>Rapidly increasing number of devices (endpoints)</li>
<li>Rapidly increasing volume of data</li>
<li>New types of links like optical links (fiber) which increase transfer but increase complexity</li>
</ul>
</li>
<li>Services at high speeds</li>
</ol>
<h4 id="common-bottlenecks">Common bottlenecks<a hidden class="anchor" aria-hidden="true" href="#common-bottlenecks">#</a></h4>
<p><img alt="common bottlenecks table" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.15.27%20PM.png"></p>
<p>A little bit more detail:</p>
<p><strong>Longest prefix matching</strong> - Due to the ever increasing number of devices on the internet, it&rsquo;s impossible to hold a table for <em>all</em> of them. So instead devices are grouped into prefixes. But then you need good algorithms to deal with the prefixes.</p>
<p><strong>Service differentiation</strong> - If you want to be able to provide priority to some packets and not to others, you need more complex logic to handle that. At scale.</p>
<p><strong>Switching Limitations</strong> - At high speeds, the hardware can become a problem, causing bottlenecks at the I/O ports or even on the switching hardware.</p>
<p><strong>Bottlenecks about services</strong> - Providing a reliable, fast, secure service that is <strong>guaranteed</strong> is difficult. Entire companies are built around doing this so that others don&rsquo;t have to.</p>
<h3 id="prefix-matching">Prefix matching<a hidden class="anchor" aria-hidden="true" href="#prefix-matching">#</a></h3>
<p>Prefixing is a way to group endpoints together to make lookup tables less large.</p>
<p><strong>Prefix Notation:</strong></p>
<p>There are several ways to notate prefixes.</p>
<ol>
<li>Dot decimal
<ul>
<li>16 bit (132.234) becomes binary of 1000010011101010</li>
</ul>
</li>
<li>Slash notation
<ul>
<li>A/L, A=Address, L=Length</li>
<li>132.234.0.0/16</li>
</ul>
</li>
<li>Masking
<ul>
<li>123.234.0.0/16 is written as 123.234.0.0 with a mask 255.255.0.0</li>
<li>The mask 255.255.0.0 denotes that only the first 16 bits are important.</li>
</ul>
</li>
</ol>
<p>This prefixing helped, because we were running out of IP addresses, quickly. But it introduced the issue of <em>longest matching prefix lookup</em>.</p>
<p>The main router performance metric is how quickly it can do a full lookup. There are four common problem areas:</p>
<ol>
<li>A large amount of traffic is concurrent flows of short duration, making caching not very useful.</li>
<li>Lookup speed is important, the most costly part of that is accessing memory</li>
<li>An unstable routing protocol may result in more updates to the table and slower updates, adding milliseconds of time to the table update time.</li>
<li>Cost vs performance, really expensive memory is fast, cheaper memory is slower
<ul>
<li>how to decide which is which likely depends on application</li>
</ul>
</li>
</ol>
<p><img alt="common issues" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-7.png"></p>
<h4 id="unibit-tries">Unibit Tries<a hidden class="anchor" aria-hidden="true" href="#unibit-tries">#</a></h4>
<p>Given this prefix db:</p>
<p><img alt="unibit db" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20Diagram%20Recreations%20Ben%20updated-1.png"></p>
<p>Results in this trie:</p>
<p><img alt="unibit trie" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20Diagram%20Recreations%20Ben%20updated-2.png"></p>
<p>These are the steps we follow to perform a prefix match:</p>
<ol>
<li>We begin the search for a longest prefix match by tracing the trie path.</li>
<li>We continue the search until we fail (no match or an empty pointer)</li>
<li>When our search fails, the last known successful prefix traced in the path is our match and our returned value.</li>
</ol>
<p>Two notes:</p>
<ol>
<li>
<p>If a prefix is a substring of another prefix, the smaller string is stored in the path to the longer (more specific prefix). For example, P4 = 1<em>is a substring of P2 = 111</em>, and thus P4 is stored inside a node towards the path to P2.</p>
</li>
<li>
<p>One-way branches. There may be nodes that only contain one pointer. For example, let’s consider the prefix P3 = 11001. After we match 110 we will be expecting to match 01. But in our prefix database, we don’t have any prefixes that share more than the first 3 bits with P3. So if we had such nodes represented in our trie, we would have nodes with only one pointer. The nodes with only one pointer each are called one-way branches. For efficiency, we compress these one-way branches to a single text string with 2 bits (shown as node P9).</p>
</li>
</ol>
<h4 id="multibit-tries">Multibit Tries<a hidden class="anchor" aria-hidden="true" href="#multibit-tries">#</a></h4>
<p>Unibit tries are very efficient but it requires a large amount of memory accesses to achieve. For highspeed links it is not plausible to access memory that many times. Instead we use strides. A stride is the number of bits to check at each step.</p>
<p>So an alternative to unibit tries are the multibit tries. A multibit trie is a trie where each node has 2k  children, where k is the stride. Next, we will see that we can have two flavors of multibit tries: fixed-length stride tries and variable-length stride tries.</p>
<h5 id="prefix-expansion">Prefix expansion<a hidden class="anchor" aria-hidden="true" href="#prefix-expansion">#</a></h5>
<p>One quick problem you may run into with multibit, is if you have a stride length of 2, you could miss prefixes like 101* so this is handled via expansion:</p>
<p><img alt="prefix expansion table" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-9.png"></p>
<h4 id="fixed-stride-example">Fixed Stride Example<a hidden class="anchor" aria-hidden="true" href="#fixed-stride-example">#</a></h4>
<p>Using a fixed stride length of three, let&rsquo;s do an example. Using the same database as the prior example.</p>
<p>Some key points to note here:</p>
<ol>
<li>Every element in a trie represents two pieces of information: a pointer and a prefix value.</li>
<li>The prefix search moves ahead with the preset length in n-bits (3 in this case)</li>
<li>When the path is traced by a pointer, we remember the last matched prefix (if any).</li>
<li>Our search ends when an empty pointer is met. At that time, we return the last matched prefix as our final prefix match.</li>
</ol>
<p><img alt="routing image fixed stride length" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-8%20Fixed%20Stride.jpg"></p>
<h4 id="variable-stride-length">Variable Stride Length<a hidden class="anchor" aria-hidden="true" href="#variable-stride-length">#</a></h4>
<p>Variable Stride length allows us to save memory and still get all of the addresses.</p>
<p><img alt="variable example image" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-9%20Variable%20Stride.jpg"></p>
<p>Some key points about variable stride:</p>
<ol>
<li>Every node can have a different number of bits to be explored.</li>
<li>The optimizations to the stride length for each node are all done to save trie memory and the least memory accesses.</li>
<li>An optimum variable stride is selected by using dynamic programming</li>
</ol>
<h3 id="packet-classification">Packet Classification<a hidden class="anchor" aria-hidden="true" href="#packet-classification">#</a></h3>
<p>We&rsquo;ve talked aout prefix matching and how it attempts to solve the issue of an ever growing internet with many devices and many ip addresses.</p>
<p>What it doesn&rsquo;t do is provide advanced features like paying attention to source addresses, tcp flags, etc.</p>
<p>Packet classification tackles those challenges.</p>
<p>Common examples:</p>
<ol>
<li>Firewalls - Routers implement firewalls to filter inbound and outbound traffic based on a pre-determined set of policies.</li>
<li>Resource Reservation Protocols - To reserve bandwidth between a source and destination</li>
<li>Routing based on traffic type - If a certain type of traffic is more time sensitive, move it to the front of the queue</li>
</ol>
<p><img alt="example advanced routing" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.20.46%20PM.png"></p>
<h4 id="simple-classifiers">Simple Classifiers<a hidden class="anchor" aria-hidden="true" href="#simple-classifiers">#</a></h4>
<ul>
<li>Linear Search - Perform a search through a rules database for every packet, works fine for simple rules, struggles at large amounts of rules</li>
<li>Caching - Caching is usefule but has issues
<ul>
<li>Even an 80-90% cache rate still results in many searches</li>
<li>A 90% cache rate still has ~0.1 milliseconds of search, which is pretty slow in this context</li>
</ul>
</li>
<li>Passing Labels - Setup &ldquo;Label Switched Paths&rdquo; between sites,
<ul>
<li>Multiprotocol Label Switching (MPLS) and DiffServ use this</li>
<li>MPLS: router A does classification, and then all intermediate routers just read it and use it, instead of doing their own classification</li>
<li>DiffServ: Applies special markers at the edges to mark a packet for special quality-of-service</li>
</ul>
</li>
</ul>
<h4 id="fast-searching---using-set-pruning-tries">Fast Searching - Using Set Pruning Tries<a hidden class="anchor" aria-hidden="true" href="#fast-searching---using-set-pruning-tries">#</a></h4>
<p>Assume a two dimensional rule that only cares about source and destination IPs.</p>
<p><img alt="two dimensional rule table" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-11%20Example%20with%207%20Destination%20Source%20Rules.jpg"></p>
<p>We can build a trie (similar to earlier in this section), where each leaf node is another trie</p>
<p><img alt="trie graph" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-12%20Packet%20Classification.jpg"></p>
<blockquote>
<p>By S1, we denote the source prefix of rule R1, S2 of rule R2, etc. Thus for every destination prefix D in the destination trie, we &ldquo;prune&rdquo; the set of rules to those compatible with D.
We first match the destination IP address in a packet in the destination trie. Then we traverse the corresponding source trie to find the longest prefix match for the source IP. The algorithm keeps track of the lowest-cost matching rule. Finally, the algorithm concludes with the least-cost rule.
Challenge: The problem that we need to solve now is which source prefixes to store at the sources tries? For example, let&rsquo;s consider the destination D = 00*. Both rules R4 and R5 have D as the destination prefix. So the source tries for D will need to include the source prefixes 1* and 11*.
But if we restrict to 1* and 11*, this is not sufficient. Because the prefix 0*, also matches 00*,  and it is found in rules R1, R2, R3, R7. So we will need to include all the corresponding source prefixes.
Moving forward, the problem with the set pruning tries is memory explosion. Because a source prefix can occur in multiple destination tries.</p></blockquote>
<h4 id="reducing-memory-using-backtracking">Reducing Memory Using Backtracking<a hidden class="anchor" aria-hidden="true" href="#reducing-memory-using-backtracking">#</a></h4>
<p>Set pruning has a high cost in memory to reduce time. So we can trade memory for time and try to solve this problem.</p>
<p>From the lecture:</p>
<blockquote>
<p>The set pruning approach has a high cost in memory to reduce time.
The opposite approach is to pay in time to reduce memory.
Let&rsquo;s assume a destination prefix D. The backtracking approach has each destination prefix D point to a source trie that stores the rules whose destination field is exactly D. The search algorithm then performs a &ldquo;backtracking&rdquo; search on the source tries associated with all ancestors of D.
So first, the algorithm goes through the destination trie and finds the longest destination prefix D matching the header. Then it works its way back up the destination trie and searches the source trie associated with every ancestor prefix of D that points to a nonempty source trie.
Since each rule is stored exactly once, the memory requirements are lower than the previous scheme. But, the lookup cost for backtracking is worse than for set-pruning tries.</p></blockquote>
<h4 id="grid-of-tries">Grid of Tries<a hidden class="anchor" aria-hidden="true" href="#grid-of-tries">#</a></h4>
<p>We&rsquo;ve tried Backtracking (high time lower memory), and set pruning (memory explosion). Both fail for their own reasons.</p>
<p>Grid of tries approach takes backtracking and reduces wasted time by precomputing. When backtracking if there is a failure point in the source trie, we have a &ldquo;switch pointer&rdquo; which takes you directly to the next possible source trie containing a matching rule.</p>
<p><img alt="trie network" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.24.35%20PM.png"></p>
<p>At places where there may be a failure to get to a matching rule, we can go directly to the next most likely place to find a rule, with precomputed switch pointers.</p>
<p><img alt="trie network with switch pointers" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.25.59%20PM.png"></p>
<h3 id="scheduling">Scheduling<a hidden class="anchor" aria-hidden="true" href="#scheduling">#</a></h3>
<p>Now we talk about scheduling. Given a N-by-N crossbar switch with N input lines, N output lines, and N2 crosspoint we need to ensure that each input link is only connected to one output link at any given time <em>and</em> we want to maximize throughput by having the as many parallel routes open at one time as possible.</p>
<h4 id="take-a-ticket-algorithm">Take a Ticket Algorithm<a hidden class="anchor" aria-hidden="true" href="#take-a-ticket-algorithm">#</a></h4>
<p>Every output link has a queue, when an input link would like to use that queue it gets a ticket, and waits until it is called to send its packet and the route is opened.</p>
<p>Round 1:</p>
<p><img alt="take a ticket graph" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6%20take_a_ticket_1.png"></p>
<p>Round 2:</p>
<p><img alt="take a ticket round 2" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6%20take_a_ticket_2.png"></p>
<p>Round 3:
<img alt="take a ticket round 3" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6%20take_a_ticket_3.jpg"></p>
<p>and here is an overview of how this all plays out:</p>
<p><img alt="overview of take a ticket" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.33.12%20PM.png"></p>
<p>One thing to note here is that all of the other messages that are going to other nodes are blocked by the fact that they all wanted to go to output 1 first. This is &ldquo;Head of line&rdquo; blocking caused by take a ticket.</p>
<h4 id="avoiding-head-of-line-with-take-a-ticket">Avoiding Head of Line with Take a Ticket<a hidden class="anchor" aria-hidden="true" href="#avoiding-head-of-line-with-take-a-ticket">#</a></h4>
<h4 id="output-queuing">Output Queuing<a hidden class="anchor" aria-hidden="true" href="#output-queuing">#</a></h4>
<p>Given an N-by-N crossbar switch can we try to send to an output link without queuing? Then it would only need to block packets which are headed for the same destination. To do this the fabric must run N times faster than the input links.</p>
<p>A practical approach to this is the knockout scheme. It breaks up packets into fixed sizes k (which is smaller than N). Then if the fabric needs to only run k times as fast as an input link instead of N.</p>
<p>In some cases this can be broken and there are primitive switching rules to handle this.</p>
<ul>
<li>k = 1 and N = 2. Randomly pick the output that is chosen. The switching element, in this case, is called a concentrator.</li>
<li>k = 1 and N &gt; 2. One output is chosen out of N possible outputs. We can use the same strategy of multiple 2-by-2 concentrators in this case.</li>
<li>k needs to be chosen out of N possible cells, with k and N arbitrary values. We create k knockout trees to calculate the first k winners.</li>
</ul>
<p>The drawback of this approach is it is complex to implement.</p>
<h4 id="parallel-iterative-matching">Parallel Iterative Matching<a hidden class="anchor" aria-hidden="true" href="#parallel-iterative-matching">#</a></h4>
<p>This approach still allows queuing but in a way that avoids head-of-line blocking. It starts with taking each incoming link&rsquo;s queue and breaking it into virtual queues for each output link.</p>
<p><img alt="iterative queue 1" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.41.14%20PM.png"></p>
<p><img alt="interative queue 2" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.42.38%20PM.png"></p>
<p><img alt="iterative queue 3" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.43.46%20PM.png"></p>
<p>If an input receives multiple grants, it randomly picks between the two. This allows more packets to attempt to go through more quickly at the same time, and is more efficient than take-a-ticket.</p>
<h4 id="scheduling-intro">Scheduling Intro<a hidden class="anchor" aria-hidden="true" href="#scheduling-intro">#</a></h4>
<p>Busy routers rely on scheduling for routing updates, management queries, and data packets. Since linkspeeds are climbing over 40 gigabit, this needs to be done <strong>very</strong> quickly.</p>
<h5 id="fifo-with-tail-drop">FIFO with tail drop<a hidden class="anchor" aria-hidden="true" href="#fifo-with-tail-drop">#</a></h5>
<p>This is a simple first in first out queue, but if the queue is larger than its limit, the packets at the &ldquo;tail&rdquo; are dropped off.</p>
<h5 id="quality-of-service">Quality of Service<a hidden class="anchor" aria-hidden="true" href="#quality-of-service">#</a></h5>
<p>The FIFO approach has pretty bad quality of service with not guaranteed delivery due to dropping packets in the tail.</p>
<p>This is bad for the following reasons:</p>
<h6 id="router-support-for-congestion">Router support for congestion<a hidden class="anchor" aria-hidden="true" href="#router-support-for-congestion">#</a></h6>
<p>Congestion in the internet is increasingly possible as the usage has increased faster than the link speeds. While most traffic is based on TCP (which has its own ways to handle congestion), additional router support can improve the throughput of sources by helping handle congestion.</p>
<h6 id="providing-qos-guarantees-to-flows">Providing QoS guarantees to flows<a hidden class="anchor" aria-hidden="true" href="#providing-qos-guarantees-to-flows">#</a></h6>
<p>During periods of backup, these packets tend to flood the buffers at an output link. If we use FIFO with tail drop, this blocks other flows, resulting in important connections on the clients’ end freezing. This provides a sub-optimal experience to the user, indicating a change is necessary!</p>
<h6 id="fair-sharing-of-links-among-competing-flows">Fair sharing of links among competing flows<a hidden class="anchor" aria-hidden="true" href="#fair-sharing-of-links-among-competing-flows">#</a></h6>
<p>One way to enable fair sharing is to guarantee certain bandwidths to a flow. Another way is to guarantee the delay through a router for a flow. This is noticeably important for video flows – without a bound on delays, live video streaming will not work well.</p>
<h4 id="bit-by-bit-round-robin">Bit by Bit Round Robin<a hidden class="anchor" aria-hidden="true" href="#bit-by-bit-round-robin">#</a></h4>
<p>FIFO might drop packets. So we can use round robin to fix that. Pure round robin struggles though if one link has different packet sizes than the other, which might result in one link getting better service than the other.</p>
<p>Bit by Bit fixes this. The idea is that even though we can&rsquo;t split packets up bit by bit, we can kind of do it virtually to help inform scheduling decisions. Using a lot of fancy math we can determine the round in which a packet finishes sending.</p>
<p>The Bit by Bit round robin then works by sending the packet which has the smallest finishing round number. Consider the following example:</p>
<p><img alt="round robin bit by bit queue" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-13.png"></p>
<p>F is their finishing number, in their respective queues.</p>
<p><img alt="round robin bit by  bit rnd 2" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-14.png"></p>
<p>We can see F=1002 is sent first, because it had the earliers round finishing number. It was the &ldquo;most starved&rdquo; packet during the prior scheduling round.</p>
<p><img alt="rnd 3" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-15.png"></p>
<p><img alt="rnd 4" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-16.png"></p>
<p>This is fair, but introduces new complexities. Specifically maintaining a priority queue becomes very expensive, and takes a long time, which isn&rsquo;t feasible at gigabit speeds.</p>
<h4 id="deficit-round-robin">Deficit Round Robin<a hidden class="anchor" aria-hidden="true" href="#deficit-round-robin">#</a></h4>
<p>Round robin guaranteed delay and bandwidth fairness, but many applications only care aobut bandwidth fairness. So a simple constant-time round robin could get that done much more simply.</p>
<blockquote>
<p>We assign a quantum size, Qi, and a deficit counter, Di, for each flow. The quantum size determines the share of bandwidth allocated to that flow. For each turn of round-robin, the algorithm will serve as many packets in the flow i with size less than (Qi + Di). If packets remain in the queue, it will store the remaining bandwidth in Di for the next run. However, if all packets in the queue are serviced in that turn, it will clear Di to 0 for the next turn.</p></blockquote>
<p>Consider the following:</p>
<p><img alt="deficit 1" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-14%20Deficit%20Round%20robin.jpg"></p>
<p><img alt="deficit 2" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-15%20Deficit%20Round%20robin%202.jpg"></p>
<blockquote>
<p>In this router, there are four flows – F1, F2, F3, and F4. The quantum size for all flows is 500. Initially, the deficit counters for all flows are set to 0. Initially, the round-robin pointer points to the first flow. The first packet of size 200 will be sent through. However, the funds are insufficient to send the second packet of size 750. Thus, a deficit of 300 will remain in D1. For F2, the first packet of size 500 will be sent, leaving D2 empty.
Similarly, the first packets of F3 and F4 will be sent with D3 = 400 and D4 = 320 after the first iteration. For the second iteration, the D1+ Q1 = 800, meaning there are sufficient funds to send the second and third packets through. Since there are no remaining packets, D1 will be set to 0 instead of 30 (the actual remaining amount).</p></blockquote>
<h4 id="token-bucket">Token Bucket<a hidden class="anchor" aria-hidden="true" href="#token-bucket">#</a></h4>
<p>Sometimes we want to limit flows of certain data types without having to put them into another queue.</p>
<p>Token bucket shaping can accomplish this through things like limiting burstiness of flow by limiting the average rate, and limiting the burst maximum size allowed.</p>
<p><img alt="token bucket flow" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.48.08%20PM.png"></p>
<p>If a packet comes and needs to hit the bucket, the bucket has to have enough available tokens, otherwise it fails. That&rsquo;s how you limit burst.</p>
<p>The problem with this is only one queue per flow. If a flow has a full token bucket it may block other flows. Token policing solves this.</p>
<h4 id="leaky-bucket-token-policing">Leaky Bucket (Token Policing)<a hidden class="anchor" aria-hidden="true" href="#leaky-bucket-token-policing">#</a></h4>
<p>Policing and shaping both help limit the output of a link but in different ways.</p>
<p><img alt="policing vs shaping" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-18%20Leaky%20Bucket.jpg"></p>
<ul>
<li>Policer: When the traffic rate reaches the maximum configured rate, excess traffic is dropped, or the packet&rsquo;s setting or &ldquo;marking&rdquo; is changed. The output rate appears as a saw-toothed wave.</li>
<li>Shaper: A shaper typically retains excess packets in a queue or a buffer, and this excess is scheduled for later transmission. The result is that excess traffic is delayed instead of dropped. Thus, the flow is shaped or smoothed when the data rate is higher than the configured rate. Traffic shaping and policing can work in tandem.</li>
</ul>
<p>Leaky bucket refers to the Token Bucket implementation with a constant output rate. If a packet were to make a bucket overflow it is discarded, but the same time things aren&rsquo;t sent in burst, but at a constant &ldquo;leak&rdquo; rate.</p>
<p><img alt="leaky bucket" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-19Leaky%20bucket%202.jpg"></p>
<h2 id="lesson-7---software-defined-networking">Lesson 7 - Software Defined Networking<a hidden class="anchor" aria-hidden="true" href="#lesson-7---software-defined-networking">#</a></h2>
<p>Software Defined Networking (SDN) was borne of the need to separate the control plane from the data plane.</p>
<h3 id="why-did-sdn-arise">Why did SDN arise?<a hidden class="anchor" aria-hidden="true" href="#why-did-sdn-arise">#</a></h3>
<p>There was a need to make computer networks more programmable, because there is a diversity of equipment  on every network, and many proprietary technologies.</p>
<h4 id="diversity-of-equipment">Diversity of Equipment<a hidden class="anchor" aria-hidden="true" href="#diversity-of-equipment">#</a></h4>
<p>Routers, switches, firewalls, network address translators, server load balancers, intrusion detection systems, oh my! These are just some of the types of devices that get put on a network.</p>
<p>Even with a centralized network controller, there are so many different protocols and interfaces that need support, it creates quite a lot of work to support it.</p>
<h4 id="proprietary-technologies">Proprietary Technologies<a hidden class="anchor" aria-hidden="true" href="#proprietary-technologies">#</a></h4>
<p>Switches and routers often ran proprietary software. Likely done to encourage people to buy all of a certain brand, but in instances where that&rsquo;s not feasible for one reason or another then something has to deal with those differences.</p>
<p>SDN looks to fix all of these issues with ✨software✨. It does this by separating tasks. Specifically separating the control plane and the data plane.</p>
<h3 id="history-of-sdns">History of SDNs<a hidden class="anchor" aria-hidden="true" href="#history-of-sdns">#</a></h3>
<p>The history of SDN can be divided into three phases:</p>
<ol>
<li>Active networks</li>
<li>Control and data plane separation</li>
<li>OpenFlow API and network operating systems</li>
</ol>
<h4 id="active-networks">Active Networks<a hidden class="anchor" aria-hidden="true" href="#active-networks">#</a></h4>
<p>From the mid 1990s until the early 2000s the internet of course exploded. This required new porotocols which were to be created by the Internet Engineering Task Force (IETF). This process sucked and then other things sprung up to fill the holes.</p>
<p>It led to the growth of active networks which used wanted a programming interface which exposed many resources and allowed customization of functionalities for subsets of packets passing through the network. This was opposite to the belief that a simple network core was important to internet success.</p>
<p>There were two prevalent programming models in active networking with the difference being where code is executed:</p>
<ol>
<li>Capsule Model - carried in band pockets</li>
<li>Programmable router/switch model - established out of band mechanisms</li>
</ol>
<p>The main <strong>pushers</strong> of active networks was</p>
<ul>
<li>Reduction in computation cost, enables more processing</li>
<li>Advancement in programming languages, enabled things that were previously not possible, of if they were possible, were unsafe</li>
<li>Advances in rapid code compliation and formal methods</li>
<li>Funding from DARPA (DARPA just keeps showing up)</li>
</ul>
<p>The main <strong>pullers</strong> of active networks was:</p>
<ul>
<li>Network service providers were frustrated with long timelines to deploy new network services</li>
<li>Third parties wanting to get more control on an individual level</li>
<li>Unified control over middleboxes</li>
</ul>
<p>These pulls are similar pulls to the current pulls for SDN.</p>
<p>Active networks made three major contributions to CDNs:</p>
<ul>
<li>Programmable functions in the network to lower the barrier to innovation
<ul>
<li>Active networks were one of the first to use the idea of programmable networks to overcome the slow speed of innovation in computer networks.</li>
<li>Lots of focus was on programming the control plane, but active networks tried to add some to the data plane</li>
<li>This is similar to OpenFlow and other SDN ideas that are being used</li>
</ul>
</li>
<li>Network virtualization, the ability to demultiplex software programs based on packet headers
<ul>
<li>Active networking produced a framework that described a platform that would support experimentation, this led to virtualization</li>
</ul>
</li>
<li>Unified Architecture for middlebox orchestration
<ul>
<li>Control over middleboxes was never fully realized in Active networks but some of its research is benefitting network function virtualization</li>
</ul>
</li>
</ul>
<p>Active Networks main reason for <em>not</em> beocming main stream is due to the fact that it was too ambitious. It required people to program in Java, which was not guaranteed, and did not have security as a focus from the beginning, which scared people.</p>
<h4 id="control-and-data-plane-separation">Control and data plane separation<a hidden class="anchor" aria-hidden="true" href="#control-and-data-plane-separation">#</a></h4>
<p>Control and data plane separation was from around 2001 to 2007. Network operators were desperate to have better management tools of their traffic as the network popularity exploded.</p>
<p>It was identified that many of the main issues had to do with the tight coupling of the control and data planes.</p>
<p>The main <strong>pushers</strong> of control and data plane separation were:</p>
<ul>
<li>Higher link speeds in backbone networks</li>
<li>Internet service providers had a difficult time meeting the increased reliability and new services</li>
<li>Servers had substantially more memory and processing resources than things made even 1 or 2 years earlier</li>
<li>Open source routing software lowered the barrier to creating centralized routing controllers</li>
</ul>
<p>These pushes resulted in:</p>
<ul>
<li>Open interface between control and data planes</li>
<li>Logically centralized control of the network</li>
</ul>
<p>It was different from active networking in the following ways:</p>
<ul>
<li>Focused on spurring innovation by and for network administrators</li>
<li>Emphasized programmability in the control domain rather than the data domain</li>
<li>Worked towards network-wide visibility and control rather than device level</li>
</ul>
<p>The main <strong>pullers</strong> of control and data plane separation were:</p>
<ul>
<li>Selecting between network paths based on current traffic load</li>
<li>Minimizing disruptions during planned routing changes</li>
<li>Redirecting/dropping suspected attack traffic (firewall)</li>
<li>Allow customers more control over traffic flow</li>
<li>Offering value add services for virtual private network customers</li>
</ul>
<p>Most of this work was completed within an ISP, with not much cross ISP interfacing. There were a couple concepts which were taken into SDN design:</p>
<ol>
<li>Logically centralized control using an open interface</li>
<li>Distributed state management</li>
</ol>
<p>People thought this was a bad idea because what if the controller failed. In addition to this people were nervous about distributed network maps instead of the routers knowing the whole picture.</p>
<h4 id="openflow-api-and-network-operating-systems">OpenFlow API and network operating systems<a hidden class="anchor" aria-hidden="true" href="#openflow-api-and-network-operating-systems">#</a></h4>
<p>This took place during 2007 to 2010.</p>
<p>The OpenFlow API was borne fromm an interest in the idea of network experimentation at scale. It balanced fully programmable networks with real world deployments.</p>
<p>It was built on existing hardware but enabled more functions that prior controllers. This dependency was based on hardware flexibility, but it enabled immediate deployment.</p>
<p>OpenFlow switches follow this:</p>
<ul>
<li>Each switch contains a table of packet-handling rules</li>
<li>Each rule has a pattern, list of actions, set of counters, and priority</li>
</ul>
<p>Once a packet is recieved it determines the highest priority matching rule, performas the action associated with it, and increments the counter</p>
<p>The main <strong>pushers</strong> of this technology were:</p>
<ul>
<li>Switch chipset vendors had already started to allow programmers to control some forwarding behaviors</li>
<li>Allowed other companies to build their own switches without making a data plane</li>
<li>Enabling OpenFlow was easy to deploy based on a simple firmware upgrade</li>
</ul>
<p>The main *<em>pullers</em> of this technology were:</p>
<ul>
<li>OpenFlow was meeting the need of conducting large scale experimentation on network architectures</li>
<li>OpenFlow was useful in data-center networks that had a need to manage network traffic</li>
<li>Companies started investing more in programmers for cotnrol programs and less on proprietary hardware, allowing smaller players to get in the game</li>
</ul>
<p>OpenFlow&rsquo;s Key Effects:</p>
<ul>
<li>Generalized network device and functions</li>
<li>Provided a vision of a network operating system</li>
<li>Distributed state management techniques</li>
</ul>
<h3 id="separating-the-data-plane-and-the-control-plane">Separating the Data Plane and the Control Plane<a hidden class="anchor" aria-hidden="true" href="#separating-the-data-plane-and-the-control-plane">#</a></h3>
<p>SDN is different from the traditional networking approaaches because it separates the control and data plane.</p>
<p>The reasons for this separations are:</p>
<ul>
<li>Independent evolution and development
<ul>
<li>Routing <strong>and</strong> forwarding are tied to a single piece of hardware, meaning the only easy time to upgrade, is when you do the whole thing. By separating them, routing can grow while forwarding stays the same, and vice versa. Coupling makes things difficult.</li>
</ul>
</li>
<li>Control from high-level software program
<ul>
<li>Using software to compute forwarding tables means higher order programs can control router behavior. Not being attached to the forwarding plane makes this simpler.</li>
</ul>
</li>
</ul>
<p>It&rsquo;s best for both planes that they go their separate ways :)</p>
<p>This then enables:</p>
<ol>
<li>Data Centers, large data centers with oodles of compute, but using that compute can become even more difficult if you&rsquo;re rigidly attached to the forwarding hardware</li>
<li>Routing, separating the two allows more complex routing</li>
<li>Enterprise networks. SDN can imporve sescurity of networks by protecting from things like DDoS by simply dropping traffic at strategic locations</li>
<li>Research networks. You can colocate research and production networks, allowing for experimentation on live traffic without interfering with said live traffic</li>
</ol>
<p>Traditional Router:
<img alt="traditional router" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-20%20at%205.05.39%20PM.png"></p>
<p>SDN approach:
<img alt="sdn routing approach" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-20%20at%205.07.41%20PM.png"></p>
<h3 id="sdn-architecture">SDN Architecture<a hidden class="anchor" aria-hidden="true" href="#sdn-architecture">#</a></h3>
<p>The main components af an SDN network are:</p>
<ul>
<li>SDN controlled network elements - The infrastructure layer is responsible for the forwarding of traffic in a network based on rules from the SDN control plane</li>
<li>SDN controller - Logically centralized entity that acts as the interface between network element and network control applications</li>
<li>Network control applications - Programs that manage the underlying network by observing network elements through the SDN controller</li>
</ul>
<p><img alt="SDN architecture" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-20%20at%205.11.16%20PM.png"></p>
<h4 id="four-defining-features">Four defining features<a hidden class="anchor" aria-hidden="true" href="#four-defining-features">#</a></h4>
<p>The four defining features of SDN architecture are</p>
<ul>
<li>Flow-based forwarding</li>
<li>Separation of data plane and control plane</li>
<li>Netowrk control functions</li>
<li>A programmable network</li>
</ul>
<h5 id="flow-based-forwarding">Flow-based forwarding<a hidden class="anchor" aria-hidden="true" href="#flow-based-forwarding">#</a></h5>
<p>The rules for forwarding packets can be computed based on any number of header values from various layers. This differes from the prior approach in which only the destination IP address determined the forwarding of a packet. OpenFlow allowed up to 11 header field values to be used</p>
<h4 id="separation-of-data-plane-and-control-plane">Separation of data plane and control plane<a hidden class="anchor" aria-hidden="true" href="#separation-of-data-plane-and-control-plane">#</a></h4>
<p>SDN controlled switches only operate on the data plane executing rules in the flow tables, created and managed by entirely separate servers</p>
<h4 id="network-control-functions">Network control functions<a hidden class="anchor" aria-hidden="true" href="#network-control-functions">#</a></h4>
<p>The SDN control plane usually runs on multiple servers for increased performance and availability. It also consists of two componetns</p>
<ol>
<li>Controller</li>
<li>Network applications</li>
</ol>
<p>The controller maintains up to date network state info and provides it to network control applications. This is used by the applications to monitor and control network devices</p>
<h4 id="a-programmable-network">A programmable network<a hidden class="anchor" aria-hidden="true" href="#a-programmable-network">#</a></h4>
<p>Since you have the network-control applications which act as the &ldquo;brain&rdquo; of the SDN control plane you can do things like network management, traffic engineering, security, automation, etc. Something like determining the end-to-end path between sources and destinations in the network using Dijkstra wink wink.</p>
<h3 id="sdn-controller-architecture">SDN Controller Architecture<a hidden class="anchor" aria-hidden="true" href="#sdn-controller-architecture">#</a></h3>
<p>The SDN controller is a part of the SDN control plane. It acts as an interface between the network elements and the network-control applications.</p>
<h4 id="sdn-controller-layers">SDN Controller Layers<a hidden class="anchor" aria-hidden="true" href="#sdn-controller-layers">#</a></h4>
<ul>
<li>Communication Layer - Communicating between the controller and network elements</li>
<li>Network-wide state-management layer - Stores information of network-state</li>
<li>Interface to the network-control application - communicating between controller and applications</li>
</ul>
<h5 id="communication-layer">Communication Layer<a hidden class="anchor" aria-hidden="true" href="#communication-layer">#</a></h5>
<p>This layer has a protocol which the SDN controller and the network controlled elements communicate. This protocol is used so that network devices can send things like new device joining, heartbeat indicators, etc. The communication between SDN controller and the controlled devices is the &ldquo;southbound&rdquo; interface. OpenFlow does this.</p>
<p><img alt="communication layer slide" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-20%20at%205.16.13%20PM.png"></p>
<h5 id="network-wide-state-management-layer">Network-wide state-management layer<a hidden class="anchor" aria-hidden="true" href="#network-wide-state-management-layer">#</a></h5>
<p>This is pretty self-explanatory, everything that has to do with the network state that is managed by the controller. State of hosts, links, switches and copies of flow tables of various switches. This is what is used by the control plane to configure flow tables.</p>
<h5 id="interface-to-the-network-control-application">Interface to the network-control application<a hidden class="anchor" aria-hidden="true" href="#interface-to-the-network-control-application">#</a></h5>
<p>This layer is the &ldquo;northbound&rdquo; interface and how the SDN controller interacts with network-control applications. Network control applications read/write network state, flow tables, etc in the state-management layer. The SDN controller can also notify applications of changes in state as well.</p>
<p>Generally these SDN controllers are implemented in a distributed fashion in order to achieve fault tolerance, high availability and efficiency.</p>
<h2 id="lesson-8---software-defined-networking-part-2">Lesson 8 - Software Defined Networking (Part 2)<a hidden class="anchor" aria-hidden="true" href="#lesson-8---software-defined-networking-part-2">#</a></h2>
<p>Again, CDN is a more independently layered approach to Routing</p>
<p><img alt="CDN layers screenshot" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-29%20at%201.00.18%20PM.png"></p>
<h3 id="sdn-advantages-compared-to-traditional">SDN Advantages compared to Traditional<a hidden class="anchor" aria-hidden="true" href="#sdn-advantages-compared-to-traditional">#</a></h3>
<ol>
<li>Shared Abstractions. Middlebox services (or network functionalities) can be programmed easily since the abstractions provided by the control platform and network programming langauges can be shared</li>
<li>Consistency of same network information. All network apps have the same global view leading to more consistent policy decisions while reussing control plane modules</li>
<li>Locality of functionality placement. Previously middlebox locations were strategic decisions and often big constraints. With SDN middleboxes can be whereever</li>
<li>Simpler Integration. It&rsquo;s easier to integrate to SDN things than traditional proprietary boxes</li>
</ol>
<p><img alt="sdn advantages slide" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-29%20at%201.06.37%20PM.png"></p>
<h3 id="sdn-landscape">SDN Landscape<a hidden class="anchor" aria-hidden="true" href="#sdn-landscape">#</a></h3>
<p>Again SDN can be viewed as layers:</p>
<p><img alt="sdn layers" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-29%20at%201.12.27%20PM.png"></p>
<p>(a) is plane-oriented view, (b) is the SDN layers, (c) is a system design perspective.</p>
<h3 id="sdn-architecture-1">SDN Architecture<a hidden class="anchor" aria-hidden="true" href="#sdn-architecture-1">#</a></h3>
<p><img alt="Overview image" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-29%20at%201.10.04%20PM.png"></p>
<h4 id="infrastructure">Infrastructure<a hidden class="anchor" aria-hidden="true" href="#infrastructure">#</a></h4>
<p>Instead of needing routers with switching and control plane, physical networking equipment only needs to do simple forwarding. All logic comes from a centralized control system.</p>
<h4 id="southbound-interfaces">Southbound Interfaces<a hidden class="anchor" aria-hidden="true" href="#southbound-interfaces">#</a></h4>
<p>Communications between control and forwarding elements (switches) is on the southbound interface. These APIs are tightly coupled with the forwarding elements. The most popular implementation is OpenFlow.</p>
<h4 id="network-virtualization">Network Virtualization<a hidden class="anchor" aria-hidden="true" href="#network-virtualization">#</a></h4>
<p>A complete virtualization of a network needs to support arbitrary network topoligies and addressing scheemes, similar to the computing layer. VLAN, NAT and MLPS can provide this full virtualization but this is a box-by-box basis configuration and there is no unifying abstraction to do this in a global manner. So this is one thing that takes a long time still.</p>
<h4 id="network-operating-systems">Network Operating Systems<a hidden class="anchor" aria-hidden="true" href="#network-operating-systems">#</a></h4>
<p>These operating systems abstract away many low level things like distribution among routing elements, allowing developers to focus on more complex applications. Examples are OpenDayLight, OpenContrail, etc</p>
<h4 id="northbound-interfaces">Northbound Interfaces<a hidden class="anchor" aria-hidden="true" href="#northbound-interfaces">#</a></h4>
<p>The Northbound interface is how the controller and the network applications talk. There is no set standard for this interface, but one key difference is it&rsquo;s usually purely software to software communication, unlike the southbound interface. Popular examples are Floodlight, Trema, NOX, ettc.</p>
<h4 id="language-based-virtualization">Language-based virtualization<a hidden class="anchor" aria-hidden="true" href="#language-based-virtualization">#</a></h4>
<p>Allowing network devices to be interacted with via many ways at different levels of abstraction. Takes away device communication complexity without compromising security.</p>
<h4 id="network-programming-langauges">Network programming langauges<a hidden class="anchor" aria-hidden="true" href="#network-programming-langauges">#</a></h4>
<p>By having high level programming laguages in SDNs it gives more abstractions to make development more modular, things more reusable and do away with device specific low-level configurations.</p>
<h4 id="network-applications">Network applications<a hidden class="anchor" aria-hidden="true" href="#network-applications">#</a></h4>
<p>The functionalities implementing control plane logic and translates to commands in the data plane. There is avery wide range of options for these applications, doing things like routing, load balancing, security enforcement, and more.</p>
<h3 id="sdn-infrastructure-layer">SDN Infrastructure Layer<a hidden class="anchor" aria-hidden="true" href="#sdn-infrastructure-layer">#</a></h3>
<p>SDN infrastructure contains routers, switches, and appliance hardware.</p>
<p>The physical devices have no embedded intelligence, as it&rsquo;s delegated to the central control system, the Network Operating System (NOS). These are built on open-souce interfaces to encourage improvements and growth to the networking sphere.</p>
<p>A data plane devices forwards packets, a controller is a software stack running  on commodity hardware. The most widely used data plane device is a model derived from OpenFlow. There&rsquo;s a pipeline of flow tables where each entry should have a matching rule, actions to be executed on matching packets, counters keeping statistics of matching packets.</p>
<p>In OpenFlow device</p>
<ol>
<li>Packet arrives</li>
<li>Lookup starts, either matches with rule or misses</li>
<li>Resolve
<ol>
<li>forward to outgoing port</li>
<li>encapsulate and send to controller</li>
<li>drop packet</li>
<li>send to normal processing pipeline</li>
<li>send to next flow table</li>
</ol>
</li>
</ol>
<h3 id="sdn-southbound-interrfaces">SDN Southbound interrfaces<a hidden class="anchor" aria-hidden="true" href="#sdn-southbound-interrfaces">#</a></h3>
<p>Sounthbound interfaces are the APIs separting the <strong>control plane</strong> and the <strong>data plane</strong>. Since switch hardware takes time to design and engineer, this has settled on a standard protoocol of OpenFlow.</p>
<p>The OpenFlow protocol supports three info sources:</p>
<ol>
<li>Event based messages sent by forwarding devices to the controller when there is a link or port change</li>
<li>Flow statistics generated by forwarding devices and collected by controller</li>
<li>Packetss sent by forwarding devices when they don&rsquo;t know what to do with them</li>
</ol>
<p>The controller and network operating system uses this flow of information to make decisions and maintain states/maps/flow charts.</p>
<h3 id="sdn-controllers---centralized-vs-distributed">SDN Controllers - Centralized vs Distributed<a hidden class="anchor" aria-hidden="true" href="#sdn-controllers---centralized-vs-distributed">#</a></h3>
<p>The core controllerr functions are:</p>
<ul>
<li>Topology</li>
<li>Statistics</li>
<li>Notifications</li>
<li>Device Mangement</li>
<li>Shortest Path forwarding</li>
<li>Security mechanisms</li>
</ul>
<h4 id="centralized-controllers">Centralized controllers<a hidden class="anchor" aria-hidden="true" href="#centralized-controllers">#</a></h4>
<p>A single entity manages all forwarding devices in the network. This has a single point of failure and can have a hard time scaling. Some enterprise class networks and data centers use archietctures that allow this and use giant mult-threaded designs alllowing for large amounts of throughput even on a single server.</p>
<h4 id="distributed-controllers">Distributed controllers<a hidden class="anchor" aria-hidden="true" href="#distributed-controllers">#</a></h4>
<p>Distributed controlling can scale to meet practically and requirement, because it&rsquo;s built in to the design to scale as needed. It can be a centralized cluster of nodes, or a physically distributed set of elements. If a provider has multiple data centers, they might even do a hybrid where each center has a cluster, but they talk physically in a physically distributed manner.</p>
<h4 id="open-network-operating-system">Open Network Operating System<a hidden class="anchor" aria-hidden="true" href="#open-network-operating-system">#</a></h4>
<p>This is an example of a distributed SDN control platform.</p>
<p><img alt="ONOS controller" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-29%20at%203.47.37%20PM.png"></p>
<p>ONOS has several instances running in a cluster. The network state is shared across these instances by maintaining a global view. The view is made with network topology and state information.</p>
<p>Forwarding and policy decisions come from the view, OpenFlow managers recieve changes, and switches are programmed.</p>
<p>Titan is a graph database and Cassandra a distributed key-value store work together to create the view. They interact with this using the Blueprints Graph API.</p>
<p>The ONOS archictecture can scale out and offers fault tolerance. In ONOS there is a master controller for a group of switches, and the propagation of state changes is handled solely by the master instance of that switch. This is distributed by adding more instances, reducing number of switches to contoller instances.</p>
<p>Fault tolerance is achieved by handling failures via election, where if the master controller of a switch fails, the rest of the ONOS instances it is connected to fomr on consensu on who the new master should be for each of the switches that were failed.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://nathanemb.github.io/codetrails/tags/school/">School</a></li>
      <li><a href="https://nathanemb.github.io/codetrails/tags/omscs/">OMSCS</a></li>
      <li><a href="https://nathanemb.github.io/codetrails/tags/computer-networks/">Computer Networks</a></li>
      <li><a href="https://nathanemb.github.io/codetrails/tags/notes/">Notes</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://nathanemb.github.io/codetrails/">Nathan Embaugh | codetrails</a></span>

</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
