<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>CS6250 - Computer Networks - Notes | Nathan Embaugh | codetrails</title>
<meta name="keywords" content="school, OMSCS, Computer Networks, notes">
<meta name="description" content="My notes on Computer Networks from GTech&rsquo;s OMSCS.">
<meta name="author" content="Nathan Embaugh">
<link rel="canonical" href="https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/">
<link crossorigin="anonymous" href="/codetrails/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://nathanemb.github.io/codetrails/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://nathanemb.github.io/codetrails/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://nathanemb.github.io/codetrails/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://nathanemb.github.io/codetrails/apple-touch-icon.png">
<link rel="mask-icon" href="https://nathanemb.github.io/codetrails/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-TR2MH8J8BF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TR2MH8J8BF');
        }
      </script><meta property="og:url" content="https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/">
  <meta property="og:site_name" content="Nathan Embaugh | codetrails">
  <meta property="og:title" content="CS6250 - Computer Networks - Notes">
  <meta property="og:description" content="My notes on Computer Networks from GTech’s OMSCS.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-05-24T20:48:59-04:00">
    <meta property="article:modified_time" content="2025-05-24T20:48:59-04:00">
    <meta property="article:tag" content="School">
    <meta property="article:tag" content="OMSCS">
    <meta property="article:tag" content="Computer Networks">
    <meta property="article:tag" content="Notes">
    <meta property="og:image" content="https://nathanemb.github.io/codetrails/osi_model_7_layers.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://nathanemb.github.io/codetrails/osi_model_7_layers.png">
<meta name="twitter:title" content="CS6250 - Computer Networks - Notes">
<meta name="twitter:description" content="My notes on Computer Networks from GTech&rsquo;s OMSCS.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://nathanemb.github.io/codetrails/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "CS6250 - Computer Networks - Notes",
      "item": "https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "CS6250 - Computer Networks - Notes",
  "name": "CS6250 - Computer Networks - Notes",
  "description": "My notes on Computer Networks from GTech\u0026rsquo;s OMSCS.",
  "keywords": [
    "school", "OMSCS", "Computer Networks", "notes"
  ],
  "articleBody": "Lesson 1 - Introduction, History, and Internet Architecture History of the internet The internet began as many things in tech did, from DARPA.\nSpecifically:\nJ.C.R. Licklider proposed the “Galactic Network” (1962) Attached a computer in Stanford to a computer at MIT, thus beginning computers talking to each other The ARPANET (1969) UCSB, UCLA, Stanford, and U of Utah interlink Network Control Protocol (NCP), an initial ARPANET host-to-host protocol (1970) The first protocol was designed to handle increasing number of computers, first app built on this was email Inter-networking and TCP/IP (1973) NCP became TCP/IP, IP for addressing and forwarding packets, TCP for flow control and recovery from lost packets The Domain Name System (DNS) (1983) and the World Wide Web (WWW) (1990) As the internet exploded with content and endpoints, they needed a way to turn domains into IP addresses. In walks DNS. Internet Architecture The internet was built in layers. Each layer is supposed to have its own job, and not rely on any of the layers above or below it.\nThink of a person as a bit of data, then watch them fly from one airport to another and you get the idea.\nSo there is an originally designed theoretical layer named the OSI model, which had 7 layers, and then the layers that were actually implemented, known as the Internet Protocol Stack.\nThese layers are not as perfect as we would hope, specifically sometimes they do rely on the other layers or they both have methods of solving the same problem like error recovery.\nNotice that the Session and Presentation layers disappear in the Internet Protocol Stack, those are handled in the ports of each network device. The logic that is accomplished in those layers still happens, just all in one place.\nApplication Layer The data here is a message.\nThis is the layer we all interact with all the time.\nHTTP (web) SMTP (e-mail) FTP (transfers files between two end hosts) DNS (translates domain names to IP addresses) Takes the content that we want to ship around, and does all the encoding and decoding needed to actually USE it.\nThe Presentation Layer The presentation layer plays the intermediate role of formatting the information that it receives from the layer below and delivering it to the application layer. For example, some functionalities of this layer are formatting a video stream or translating integers from big endian to little endian format.\nThe Session Layer The session layer is responsible for the mechanism that manages the different transport streams that belong to the same session between end-user application processes. For example, in the case of a teleconference application, it is responsible to tie together the audio stream and the video stream.\nThe Transport Layer The data here is a segment.\nEnd to End communication between hosts.\nTransmission Control Protocol (TCP) User Datagram Protocol (UDP) TCP is better connection-oriented services, guarantees delivery, manages flow control, and controls congestion. This is the USPS, slow but reliable (except TCP doesn’t lose mail like the USPS).\nUDP is fast and guarantees nothing. Receivers and Senders using UDP must be able to handle segments getting dropped, delayed, or not making it entirely. But they should be faster when everything is working compared to TCP.\nThe Network Layer The data here is a datagram.\nThis is where IP comes into play. This layer is responsible for connecting one computer to another, via the IP address that everyone has.\nThe Data Link Layer The data here is a frame.\nThis layer is responsible for moving the frames from one node (host or router/switch) to the next node. This uses things like:\nEthernet Point-to-point Protocol (PPP) Wi-Fi The Physical Layer The actual hardware translation. Translating electricity into bits based on ethernet, coax, fiber, etc.\nEncapsulation These layers work on the idea of encapsulation and de-encapsulation. So encapsulation is to take a chunk of data, package it up, add a header to it and pass it on. Then de-encapsulation is using the headers to decode each chunk of data, until all you’re left with is the data/message.\nThis method is what allows people to build upon the existing infrastructure of the internet, but still make new things.\nThe End to End (e2e) Principle The e2e principle shaped the internet as we know it today.\nEssentially the principle is that 99% of the complexity should be at the ends of the communications. This allows the underlying infrastructure to be simple, but expandable, and allows people working at the different ends to iterate and create new things quickly.\nIf they had to change the underlying architecture every time they wanted to change anything it would bring development speed to a crawl.\nBeneficial excerpt from the lecture:\nMany people argue that the e2e principle allowed the internet to grow rapidly because evolving innovation took place at the network edge, in the form of numerous applications and a plethora of services, rather than in the middle of the network, which could be hard to modify later.\nWhat were the designers’ original goals that led to the e2e principle?\nMoving functions and services closer to the applications that use them increases the flexibility and the autonomy of the application designer to offer these services to the needs of the specific application.\nThus, the higher-level protocol layers are more specific to an application. Whereas the lower-level protocol layers are free to organize the lower-level network resources to achieve application design goals more efficiently and independently of the specific application.\nViolations of e2e All rules are meant to be broken.\nFirewalls, NAT boxes, and traffic filters all break the e2e principle, and usually for good reason.\nNAT routers provide a way to make up for the fact that there aren’t that many IP addresses available in IPv4. Instead of EVERY device having its own worldwide public IP address, you give your home 1 IP address, and then every device behind that has its own local address.\nThis means that whenever a message is sent to your PC it goes:\nWeb \u003e Router (Public IP)\u003e End Device (local IP)\nThe router is breaking some rules of e2e, because it is intervening and inspecting data.\nThis is the notes’ reasoning for why:\nWhy do NAT boxes violate the e2e principle? The hosts behind NAT boxes are not globally addressable or routable. As a result, it is not possible for other hosts on the public Internet to initiate connections to these devices. So, if we have a host behind a NAT and a host on the public Internet, they cannot communicate by default without the intervention of a NAT box. Some workarounds allow hosts to initiate connections to hosts that exist behind NATs. For example, Session Traversal Utilities for NAT, or STUN, is a tool that enables hosts to discover NATs and the public IP address and port number that the NAT has allocated for the applications for which the host wants to communicate. Also, UDP hole punching establishes bidirectional UDP connections between hosts behind NATs.\nThe Hourglass Shape of the Internet The internet is curvy.\nNo really, there’s a ton on each end of it, but the middle is pretty narrow. Specifically, TCP, UDP, IP are really the backbone of literally everything. See below:\nAll roads lead to IP, and TCP/UDP. Researchers have actually done a lot of work to see why this is. They called it the evolutionary architecture model. They did a bunch of in depth quantifications of why/what the internet is and how they got there and drew some interesting conclusions.\nIn an ideal world where we could do it all over they came up with the following:\nFinally, in terms of future and entirely new Internet architectures, the EvoArch model predicts that even if these brand-new architectures do not have the shape of an hourglass initially, they will probably do so as they evolve, which will lead to new ossified protocols. The model suggests that one way to proactively avoid these ossification effects that we now experience with TCP/IP is for a network architect to design the functionality of each layer so that the waist is wider, consisting of several protocols that offer largely non-overlapping but general services, so that they do not compete with each other.\nInterconnecting Hosts and Networks Talking about how to theoretically communicate between computers is important, but hardware actually makes the physical connections.\nThose are:\nRepeaters and Hubs They operate on the physical layer (L1) as they receive and forward digital signals to connect different Ethernet segments. They provide connectivity between hosts that are directly connected (in the same network). The advantage is that they are simple and inexpensive devices, and they can be arranged in a hierarchy. Unfortunately, hosts that are connected through these devices belong to the same collision domain, meaning that they compete for access to the same link.\nBridges and Layer-2 Switches These devices can enable communication between hosts that are not directly connected. They operate on the data link layer (L2) based on MAC addresses. They receive packets and forward them to the appropriate destination. A limitation is the finite bandwidth of the outputs. If the arrival rate of the traffic is higher than the capacity of the outputs, then packets are temporarily stored in buffers. But if the buffer space gets full, then this can lead to packet drops.\nRouters and Layer-3 Switches These are devices that operate on the network layer (L3).\nLearning Bridges A bridge is a piece of hardware that manages the connection between many devices, connected to the same piece of hardware.\nThe bridge is able to understand what devices are on port 1, what devices are on port 2, and so on. This is like a home network switch. You can connect many devices to it, and it handles knowing where the data needs to end up.\nThe Looping Problem The problem with these bridges, is that you can create a loop.\nif A connects to B which connects to C which connects to A, you’ve created a loop. This can result in never ending looping!\nThis is handled by running a spanning tree algorithm. The goal of the spanning tree algorithm is to identify which ports when used will eliminate any endless looping.\nThis works by operating in rounds, and then by removing bridges from the network until you only have one path to every node. This is accomplished by running in rounds the following process:\nEvery node sends: Sender Node ID Root ID as perceived by sender Distance from root node Each node selects the best configuration in order of If root of the one configuration has a smaller ID If roots have equal IDs choose one with smaller distance to the root If they have the same distance, choose configuration with smallest sender ID A node stops sending configuration messages over a link (port) when it receives a configuration message from a neighbor that is: either closer to the root has the same distance from the root, but it has a smaller ID. We can see this process completed in the following images:\nThen after tree spanning:\nLesson 2 - The Transport Layer (TCP) This lesson is going to talk about the actual protocol responsible for transporting data from one location to another, TCP. The logical connection between two hosts is done in the transport layer.\nThe transport layer receives a message from the application layer and appends its own header on to it. This is known as a segment. The segment is then sent to the Network layer where it happily bounces through all the routers, bridges, and switches that might be on its path.\nTransport Layer intro Why do we need a transport layer? Why not just send messages directly from the application layer to the network layer? Because the network layer guarantees nothing. The transport layer guarantees delivery, and data integrity in a way that wouldn’t have been done otherwise.\nAs mentioned previously there are two main transport layer protocols User Datagram Protocol (UDP) and Transmission Control Protocol (TCP).\nUDP just tries to quickly send data, and doesn’t do much else. As such it provides no guarantees and puts the responsibility on the application layer to do things like verify integrity and handle dropped messages.\nTCP on the other hand does have these extra bells and whistles built in and thus it is much more reliable, if not a tad slower than UDP.\nMultiplexing Multiplexing is the ability for many hosts to use the same network simultaneously. Consider two computers browsing the internet at the same time, or better yet, a computer that is simultaneously browsing the internet and streaming music, it has two incoming data sources, and used in two different ways.\nWe need to be able to handle this complexity. The Transport layer uses ports to do this. Each application gets one port, and listens only to that port.\nThere is Connectionless and Connection Oriented multiplexing. One based on a constant connection, and one is not.\nWe have names for each direction of this multiplexing operation.\nDemultiplexing - Delivering data to the appropriate socket.\nMultiplexing - Taking data from all the sockets and putting it into the network layer.\nConnectionless Multiplexing Connectionless multiplexing is the simpler case. The transport layer has a segment which has the content, a source and source port, and a destination and a destination port. It receives the data from the source port, and makes its best effort at delivering to the destination port.\nIf the destination receives it, great, the network layer will route it to the correct port, and then the message will have been successfully delivered.\nThese are UDP sockets. It’s very direct, with no oversight as to what actually happens to the message.\nConnection Oriented Multiplexing Connection Oriented multiplexing brings in a lot more complexity.\nTCP requires going through a TCP server. The TCP server has a listener process that waits for incoming connection requests, and when it gets it handles setting everything up so that the destination is ready to receive the message.\nNote: If a server has many clients contacting it on the same port, it’s not an issue because they have unique IP addresses (hopefully) and they can distinguish the difference between the two that way.\nA word on UDP UDP lacks reliability of TCP mainly because it doesn’t require establishing a connection.\nThat lack of reliability makes it better for the following reasons:\nNo congestion control - No process watches every packet to make sure it should be sent No connection management - We don’t have to wait for a socket to be opened, so it just sends quickly Both of these result in lower latency transmission, which is good for some things. Things like multiplayer video games, DNS servers, and other networking hosts, all like to use higher speed protocols.\nThis puts the onus on the developers on each end to ensure quality, and handle if errors occur, but when things are working well, then things are very speedy.\nThe one quality mechanism UDP provides is a checksum, so you can in fact check that the data that’s sent is what it was supposed to be. It creates a checksum by adding together the bits of the source port, destination port and the length of the packet. It then performs a ones complement. That is the checksum.\nThe receiver takes the source port, destination port, length of packet, and the checksum and adds them all together. Because the checksum is the ones complement, when they are added together it should end up as all ones.\nTCP Three way handshake Step 1: The TCP client sends a special segment (containing no data) with the SYN bit set to 1. The client also generates an initial sequence number (client_isn) and includes it in this special TCP SYN segment. Step 2: The server, upon receiving this packet, allocates the required resources for the connection and sends back the special “connection-granted” segment which we call SYNACK segment. This packet has the SYN bit set to 1, the acknowledgement field of the TCP segment header set to client_isn+1, and a randomly chosen initial sequence number (server_isn) for the server.\nStep 3: When the client receives the SYNACK segment, it also allocates buffer and resources for the connection and sends an acknowledgment with SYN bit set to 0.\nConnection tear down Connection Teardown\nStep 1: When the client wants to end the connection, it sends a segment with FIN bit set to 1 to the server.\nStep 2: The server acknowledges that it has received the connection closing request and is now working on closing the connection.\nStep 3: The server then sends a segment with FIN bit set to 1, indicating that connection is closed.\nStep 4: The client sends an ACK for it to the server. It also waits for some time to resend this acknowledgment in case the first ACK segment is lost.\nReliable Transmission (TCP) TCP guarantees all packets delivered in order. This is a very helpful reliability for developers to build on.\nTo do this the sender must know what the receiver successfully got. This is accomplished via ARQ (Automatic Repeat Request). If a sender doesn’t get a message that ARQ1 was received in a certain timeframe, then it will re-send it.\nStop and Wait ARQ\nGuess how long it should take, if you don’t get a response, send it again. This can work but is tricky. If you send too much you’re retransmitting for no reason, and wait too long your connection is slow.\nTCP uses Selective ACK which basically waits for the receiver to say hey I didn’t get this packet yet, and if it reaches a certain threshold like 3, then it will quickly resend that particular packet. This allows most of the time to be spent actively sending data, and the ability to recover from dropped packets.\nThis does require the ability to buffer packets until you have everything you need in order.\nTransmission Control (TCP) Deciding how much of a link bandwidth to use is a bit complicated. If you send too much for the receiver that could be an issue, or maybe the network can’t handle it, or any other amount of things that could go wrong.\nSo TCP implements a couple things to help that.\nFlow Control Flow control is where TCP tries to identify the receiver’s buffer that it is receiving data with, and tries to match the sender window size to that. Every ACK message includes a rwnd value which says how much buffer space is available.\nThe sender uses this value to ensure it never sends more bytes than is available in the receiver buffer.\nIf this value hits zero it would stop, but TCP instead sends packets of 1 byte until it gets a response with a rwnd greater than zero.\nCongestion Control Congestion control is making sure we don’t overload any of the links on the way from one host to another.\nGood congestion control is:\nEfficient - use most of the network Fair - everyone gets equal amounts Low delay - Low delay is good for things that need to have small lag like video conferences Fast convergence - everyone gets their bandwidth quickly Network Assisted Network assisted congestion control relies on pieces of the network sending feedback about what’s happening. This could fail when the network is heavily congested though, kind of rendering it useless.\nEnd to End End to end congestion control gets nothing from the network and instead infers congestion from the hosts. This supports the general principle of making the complexity be at the ends of the networks.\nThis is mostly done via packet delay (how long did it take to get here) and packet loss (how many times do I need to resend). With these two things you have a rough understanding of network performance at any given moment.\nIt employs a congestion window, a number indicating roughly how much space is left in the network. This increases until congestion is detected, and then the window is made smaller to reduce congestion.\nUltimately the max size of a TCP packet is the minimum of the receiver buffer and the congestion window.\nThere are many different methods of increasing congestion window size:\nAdditive Multiplicative TCP Reno AIMD Many of these employ “Slow start” where they start at a low-ish speed and ramp up. This protects from overwhelming the network right at the start. With timeouts or dropped connections being common you can see why this would be useful.\nTCP isn’t always fair, but using some of these congestion methods will do a pretty good job of it.\nTCP Throughput TCP Throughput looks like a sawtooth because of these congestion control mechanisms.\nIt gets up to the limit, then drops off, then gets up to the limit then drops off.\nLesson 3 - Intradomain Routing (The Network Layer) This session focuses on the act of routing on the network layer in a single domain. Ideally we understand what it takes for two hosts to share data by the end of this.\nWe’ll talk about:\nIntradomain Routing Algorithms Link state Distance vector Intradomain Protocols Open Shortest Path First (OSPF) Routing Information Protocol (RIP) Routing Given two hosts that share the same default router (first-hop router) we know that one host will send a packet to the default router, but what happens next?\nIn a network with many routers, whenever a router receives a packet, it must consult the forwarding table it maintains, and send the packet to the next router in line. This is referred to as forwarding and is not necessarily the same as routing.\nRouting is the act of determining the best path to be traveled from one location to another. Intradomain routing is what we will focus on and it is what happens when both hosts are in the same administrative domain.\nInterior Gateway Protocols (IGP) are what handle this type of routing. The two major types we’ll cover are link-state and distance-vector routing algorithms. They are graph theory algorithms with edges and nodes.\nLink State Routing Surprise, Dijkstra’s algorithm is here again.\nIn link state, all link costs are known and the network topology is also fully known.\nFrom the lecture directly.\nLet’s introduce some basic terminology. By u, we represent our source node. By v, we represent every other node in the network. By D(v), we represent the cost of the current least cost path from u to v. By p(v), we represent the previous node along the current least cost path from u to v. By c(u,v), we represent the cost from u to directly attached neighbor v. By N’, we represent the subset of nodes along the current least-cost path from u to v.\nBasically we initialize with either:\nKnown cost because it’s a link directly connected to the node we’re initializing Infinity cost, because we know it will be less than that but we have something to compare against Then we continue looping through the network, looking for a path with lower costs than our current cost, until we don’t find one. This is a fun application of Dijkstra’s algorithm, where each router essentially computes Dijkstra’s algorithm from itself to all other routers in the network.\nThis is a pretty costly algorithm at O(n^2) complexity. It also requires that you know everything about the network which is probably why this is intradomain and not interdomain.\nDistance Vector Routing The DV algorithm is iterative, asynchronous, and distributed.\nDV is based on the Bellman Ford algorithm. Every node maintains a distance vector to all of the other nodes, and it occasionally shares that information. When a node receives a new distance vector they use it to update their own vector.\nThe Bellman Ford (BF) equation is the heart of each update: Dx(y) = minv{c(x,v) + Dv(y)}\nSee the pseudocode below:\nSo essentially, continuously the nodes maintain a list of costs for routes to certain nodes, and these costs are updated whenever nodes send their costs. So instead of every node needing to know every cost, it allows the nodes to only know and focus on the costs of its immediate neighbors, and then relies on other nodes sending its current list of costs occasionally.\nThis is different from Link State routing because it is distributed, but they are all still computing the most efficient path through the tree.\nA simple example initialization\nPitfalls of DV What if the link cost changes? In some cases this is handled quickly, and in other cases it can lead to a “count-to-infinity” problem.\nSay a link cost decreases:\nAt time t0, y detects that cost to x has changed from 4 to 1, so it updates its distance vector and sends it to its neighbors. At time t1, z receives the update from y. Now z thinks it can reach x through y with a cost of 2, so it sends its new distance vector to its neighbors. At time t2, y receives the update from z. Y does not change its distance vector, so it does not send any update. The update is fully propagated pretty quickly.\nSay a link cost increases:\nAt t0, y detects that the cost has changed, and now it will update its distance vector thinking that it can still reach x through z with a total cost of 5+1=6. At t1, we have a routing loop where z thinks it can reach x through y, and y thinks it can reach x through z. This will cause the packets to be bouncing back and forth between y and z until their tables change. Nodes z and y keep updating each other about their new cost to reach x. For example, y computes its new cost to be 6 and then informs z. Then z computes its new cost to be 7, and then informs y, and so on. The key here is that Node Z, is saying Hey I can definitely reach X, and the cost as Z knows it, is 5. So Node Y says sweet, if I go through Node Z, it’s the cost of our link (1) + the cost of Z \u003e X, but the cost of Z \u003e X isn’t actually 5 anymore, it’s 50.\nSo they have to iterate until the cost is greater than 50, at which point it will use the real path.\nThe reason that we can’t directly say, “hey no the link cost increased by a ton your table is wrong” is because we don’t know the structure of the network. All we know is X \u003e Y costs a certain value, with no understanding of which links do that.\nSo instead we have to keep iterating through until the costs are actually updated. This can create a lot of packet bouncing.\nThis is solved by something called poison reverse where a node says a cost is infinity if it isn’t the cheapest path to a certain node. This only works for 2 nodes.\nRouting Information Protocol (RIP) RIP is based on Distance Vectors, but instead of maintaining vectors of distances, they instead maintain entire routing tables with one row for each subnet.\nOpen Shortest Path First OSPF is a routing protocol that uses link-state to find the best path between source and destination routers. It was created after RIP by ISPs with extra things like authentication messages, multiple same-cost paths, and support for hierarchical routing within a single domain.\nOSPF will have one AS (Autonomous System) as the backbone, and routes to other OSPF AS on the network. To go from one Area to another, they must move through the backbone router.\nThere’s a lot more in the notes but tbh they’re pretty complicated! It seems that these routers in the send Link State advertisements which communicates the routers local topology. This results in a complete network map, that updates when the network updates.\nThese LSAs are processed as so:\nHot Potato Routing Sometimes you have to leave your local network, and enter into interdomain routing.\nTo do this usually you have to find an egress point and the process of finding that egress point is an intradomain routing problem.\nGenerally hot potato routing is referring to finding the closest/least costly egress point in a given network. The hot potato part of it is that there are many egress points and which one is chosen is not always clear. This routing method of finding the shortest path does make things consistent instead of sometimes going to egress A and sometimes going to egress B.\nLesson 4 - Interdomain Routing and AS Relationships Lesson 3 focused on intradomain routing, but what about when we need to leave our domain?\nThe internet is an ecosystem of thousands if not millions of networks operated independently, but still connected to each other. This lesson we’ll learn about BGP.\nThe Internet The internet started very hierarchical but has been flattening as more IXPs and CDNs have been added.\nEach of the types of infrastructure above can be an Autonomous System (AS) which is a group of routers who are under the same authority. I think like, my house technically is an AS that I manage, but not sure about that.\nRouting between AS’s relies on Border Gateway Protocol (BGP) to exchange information with each other.\nAS Ecosystem There’s two main interactions between AS’s.\nProvider-Customer - Like me paying my ISP for internet Peer - One ISP routing to another ISP because they need their network to get to location x. This requires traffic levels to be pretty similar so that one party isn’t gaining more than the other. See how green cloud ISP can’t peer with orange cloud ISPs, because it’s too large. But all the orange cloud ISPs are peer relationships because they’re similarly sized.\nProviders can charge fixed rate or based on usage, totally up to them.\nInternet Business Importing and Exporting routes is the heart of BGP. Deciding which import/exports to operate and make available is a technical and business decision.\nExporting Routes Export routes come from:\nRoutes from customers Routes from providers Routes from peers Which of these are chosen to advertise to other AS’s is a business decision.\nImporting Routes Again, they’re picky based on which routes are going to bring the most value to the business.\nUsually it’s this order:\nAn AS wants to ensure that routes toward its customers do not traverse other ASes, unnecessarily generating costs. An AS uses routes learned from peers since these are usually “free” (under the peering agreement). An AS resorts to importing routes learned from providers only when necessary for connectivity since these will add to costs. Border Gateway Protocol (BGP) BGP Design Goals Scalability - The internet will never stop growing, try to handle it Express routing policies (ERP) - Allows ASes to make routing decisions and do it privately Allow cooperation among ASes - Allows ASes to make their own decision and let business drive the connections Security - This was added on as it was found to be necessary BGP Basics BGP Peers send messages over BGP Sessions over a semi-permanent TCP port connection. A session is initiated from one router to another with an OPEN message which is then followed by sharing routing tables.\neBGP is an external BGP session, between two ASes. iBGP is an internal BGP session, in a singular AS.\nOnce the session is started they use:\nUPDATE - if any updates are made to the Route table, share it KEEPALIVE - Keeps session going, no changes BGP relies on prefix reachability, a list of IP addresses that prefix all the destinations. This is how the export and import routes are communicated.\nOther parameters:\nPath Attributes are also shared with other providers with parameters like:\nASPATH - Contains Autonomous System Number and helps choose between multiple routes and stops loops NEXT HOP - Provides the next router’s IP address so that other routers can store in their forwarding table the best path iBGP vs eBGP iBGP is meant for sharing paths of how to get out of an AS, it’s not an IGP that gives intradomain networking, but instead a way of telling nodes inside of AS how they can communicate with external ASes.\neBGP is the method of communicating between ASes the available external routes.\nBGP Router Process When a router receives a new list of policies it takes them all in, and then has a decision making process to determine the best routes for it to use.\nThe operator of this router can determine what is important to them (usually cost related) and make decisions based on that. Here’s an example decision process.\nImportant decision makers are:\nLocalPref - Decided by operating AS, things like choose the cheaper route (customers first, then peers, etc) MED - Determined by the neighboring AS, determine which link they would prefer you to use\nBGP Issues Two main things:\nMisconfiguration - Improper configuration can bring networks down for a lot of reasons Can be reduced by limiting size of tables and number of changes Scalability - Large routing tables are problematic. A lot of work went into reducing routing table sizes. They will do things like use default routing, route aggregation, and something called flap damping. Flap damping is a technique that limits the number of updates to a given prefix over time. If it goes over a certain limit, it will silence that prefix’s updates until a set time has passed.\nThis is configurable by domain, allowing you to choose when and where you will accept a lot of updates and when you won’t.\nPeering at IXPs ASes peer with each other, where do they do that? One place is an Internet Exchange Point (IXP). They are purpose built infrastructure to facilitate peering.\nInternet Exchange Points (IXPs) are critical physical infrastructures where Autonomous Systems (ASes) can directly interconnect and exchange traffic. These facilities are typically housed in secure, well-powered data centers and consist of robust switch fabrics to ensure reliability and fault tolerance. ASes participating in IXPs must have a public ASN, a BGP-capable router, and agree to the IXP’s terms. Once connected, ASes can publicly peer and exchange traffic settlement-free, paying only for connection and port usage, not traffic volume. This makes IXPs more cost-effective and efficient than traditional third-party traffic routing.\nIXPs have grown in popularity due to their ability to handle massive volumes of traffic and play a crucial role in improving network performance and reducing costs by keeping local traffic local. They also offer defensive benefits, such as DDoS mitigation, since they observe a large portion of Internet traffic and can help stop malicious activity before it reaches the intended target. Furthermore, IXPs provide a rich environment for research and innovation, particularly in areas like security and Software Defined Networking (SDN), and are evolving into hubs of technology development beyond just traffic exchange.\nIn addition to public and private peering services, IXPs offer a wide range of features such as route servers, SLAs, remote peering via resellers, mobile network peering, and DDoS blackholing. Some IXPs also provide free value-added services like DNS root servers and time distribution. These offerings, along with the ability to form fast and scalable peering agreements, have made IXPs essential infrastructure for global Internet connectivity, performance, and resilience.\nRoute Servers IXPs use route servers to handle the large number of ASes that they service.\nIn summary, a Route Server (RS) does the following:\nIt collects and shares routing information from its peers or participants of the IXP that connect to the RS. It executes its own BGP decision process and re-advertises the resulting information (e.g., best route selection) to all RS’s peer routers. It’s basically offloading all the configuration work from the AS to the IXP operator. It’s what allows people like me to buy a domain and get reliable routing from anywhere in the world to it.\nLesson 5 and 6 - Router Design and Algorithms Routers are what do the heavy lifting for actually moving data from one point to another. The prior lessons established many pieces and parts of that puzzle.\nIn short, a router needs to be able to receive an incoming packet on an input link, read its destination, and then send it to the correct output link. Simple in theory, difficult in practice, and more importantly, at scale. Then add on top of just forwarding requirements things like security requirements, quality of service, and other more advanced things, the job becomes difficult.\nRouter Components The main job of a router is to implement the forwarding plane functions and the control plane functions.\nForwarding (Switching) function The action of transferring a packet from an incoming link, to an outbound link. This should be very fast, on the scale of a few nanoseconds. I believe this is what a nice simple 5 port network switch is, and that’s all it is.\nInput Ports\nInput ports do the following:\nPhysically terminate the link Processes datalink (decapsulating) Performs lookup function, consulting forwarding table to determine where it should go Switching Fabric*\nThis actually moves the packet from the input port, to the output port, using the results from the input port that tells where the packet needs to go.\nThree types of switching fabrics:\nMemory Bus Crossbar Output ports\nAll this does is receive the data from the switching fabric and send it. Specifically:\nQueue the packets for transfer Encapsulate the packets Send them over the physical output port Control Plane function The control plane refers to:\nImplementing routing protocols (like the ones from earlier sessions) Maintaining routing tables Computing the forwarding table All of these functions are written software in the routing processor, or in the case of an SDN, could be implemented by a remote router.\nRouter Architecture Model of a router:\nUsing the image as a guide we can walk through the path that common tasks take. First we lookup the destination of an incoming packet.\nLookup Packet arrives at input link Lookup output link in forwarding table (Forwarding Information Base FIB) Resolve any ambiguities Longest Prefix matching Packet classification Switching After lookup is completed the packet is switched, from input link to output link. Modern routers use crossbar switches for this task. Some complications occur when many inputs want to send to the same output Queuing Using various queuing logics, if an output port is congested, each packet enters the queue to wait its turn to use the hardware.\nTypes of queues used:\nFirst In First Out (FIFO) Weighted Fair Queuing Header Validation and Checksum Check version number, validate checksum, decrement ttl Route processing Build route using protocols like RIP, OSPF, and BGP Protocol Processing (Including:) Simple Network Management Protocol (SNMP) - Counters for remote inspection TCP/UDP for remote communication Internet Control Message Protocol (ICMP) for sending error messages (eg: TTL is exceeded) Switching Fabric The switching fabric is where most of the logic is implemented in a router, forwarding packets from source to destination.\nThere are several ways to accomplish this.\nSwitching via memory Physical I/O ports operate as I/O devices in an operating system.\nInput port receives packet Send interrupt to routing processor Packet written to memory Processor looks at header to get destination address Lookup output port from forwarding table Copy from memory into output ports buffer Switching via bus Bus based switching doesn’t require a processor.\nInput port receives packet Input port marks which destination port it should be for with an internal header Send it to the bus where all output ports receive the packet Only the port it’s supposed to go to accepts it This design is limited by the speed of the bus as only one packet can traverse it at a time.\nSwitching via interconnection network A crossbar switch is an interconnection network that connects N inputs to N outputs using 2N buses.\nThis allows many packets at once to traverse the switching fabric, as long as they have different input and output ports. This is done by giving the switching fabric control of the buses, and closing the connections to make the links only when there is a packet that needs to make that journey.\nRouter Challenges There are a couple fundamental challenges to overcome for routers at scale.\nBandwidth and Internet population scaling Rapidly increasing number of devices (endpoints) Rapidly increasing volume of data New types of links like optical links (fiber) which increase transfer but increase complexity Services at high speeds Common bottlenecks A little bit more detail:\nLongest prefix matching - Due to the ever increasing number of devices on the internet, it’s impossible to hold a table for all of them. So instead devices are grouped into prefixes. But then you need good algorithms to deal with the prefixes.\nService differentiation - If you want to be able to provide priority to some packets and not to others, you need more complex logic to handle that. At scale.\nSwitching Limitations - At high speeds, the hardware can become a problem, causing bottlenecks at the I/O ports or even on the switching hardware.\nBottlenecks about services - Providing a reliable, fast, secure service that is guaranteed is difficult. Entire companies are built around doing this so that others don’t have to.\nPrefix matching Prefixing is a way to group endpoints together to make lookup tables less large.\nPrefix Notation:\nThere are several ways to notate prefixes.\nDot decimal 16 bit (132.234) becomes binary of 1000010011101010 Slash notation A/L, A=Address, L=Length 132.238.0.0/16 Masking 123.234.0.0/16 is written as 123.234.0.0 with a mask 255.255.0.0 The mask 255.255.0.0 denotes that only the first 16 bits are important. This prefixing helped, because we were running out of IP addresses, quickly. But it introduced the issue of longest matching prefix lookup.\nThe main router performance metric is how quickly it can do a full lookup. There are four common problem areas:\nA large amount of traffic is concurrent flows of short duration, making caching not very useful. Lookup speed is important, the most costly part of that is accessing memory An unstable routing protocol may result in more updates to the table and slower updates, adding milliseconds of time to the table update time. Cost vs performance, really expensive memory is fast, cheaper memory is slower how to decide which is which likely depends on application Unibit Tries Given this prefix db:\nResults in this trie:\nThese are the steps we follow to perform a prefix match:\nWe begin the search for a longest prefix match by tracing the trie path. We continue the search until we fail (no match or an empty pointer) When our search fails, the last known successful prefix traced in the path is our match and our returned value. Two notes:\nIf a prefix is a substring of another prefix, the smaller string is stored in the path to the longer (more specific prefix). For example, P4 = 1is a substring of P2 = 111, and thus P4 is stored inside a node towards the path to P2.\nOne-way branches. There may be nodes that only contain one pointer. For example, let’s consider the prefix P3 = 11001. After we match 110 we will be expecting to match 01. But in our prefix database, we don’t have any prefixes that share more than the first 3 bits with P3. So if we had such nodes represented in our trie, we would have nodes with only one pointer. The nodes with only one pointer each are called one-way branches. For efficiency, we compress these one-way branches to a single text string with 2 bits (shown as node P9).\nMultibit Tries Unibit tries are very efficient but it requires a large amount of memory accesses to achieve. For highspeed links it is not plausible to access memory that many times. Instead we use strides. A stride is the number of bits to check at each step.\nSo an alternative to unibit tries are the multibit tries. A multibit trie is a trie where each node has 2k children, where k is the stride. Next, we will see that we can have two flavors of multibit tries: fixed-length stride tries and variable-length stride tries.\nPrefix expansion One quick problem you may run into with multibit, is if you have a stride length of 2, you could miss prefixes like 101* so this is handled via expansion:\nFixed Stride Example Using a fixed stride length of three, let’s do an example. Using the same database as the prior example.\nSome key points to note here:\nEvery element in a trie represents two pieces of information: a pointer and a prefix value. The prefix search moves ahead with the preset length in n-bits (3 in this case) When the path is traced by a pointer, we remember the last matched prefix (if any). Our search ends when an empty pointer is met. At that time, we return the last matched prefix as our final prefix match. Variable Stride Length Variable Stride length allows us to save memory and still get all of the addresses.\nSome key points about variable stride:\nEvery node can have a different number of bits to be explored. The optimizations to the stride length for each node are all done to save trie memory and the least memory accesses. An optimum variable stride is selected by using dynamic programming Packet Classification We’ve talked aout prefix matching and how it attempts to solve the issue of an ever growing internet with many devices and many ip addresses.\nWhat it doesn’t do is provide advanced features like paying attention to source addresses, tcp flags, etc.\nPacket classification tackles those challenges.\nCommon examples:\nFirewalls - Routers implement firewalls to filter inbound and outbound traffic based on a pre-determined set of policies. Resource Reservation Protocols - To reserve bandwidth between a source and destination Routing based on traffic type - If a certain type of traffic is more time sensitive, move it to the front of the queue Simple Classifiers Linear Search - Perform a search through a rules database for every packet, works fine for simple rules, struggles at large amounts of rules Caching - Caching is usefule but has issues Even an 80-90% cache rate still results in many searches A 90% cache rate still has ~0.1 milliseconds of search, which is pretty slow in this context Passing Labels - Setup “Label Switched Paths” between sites, Multiprotocol Label Switching (MPLS) and DiffServ use this MPLS: router A does classification, and then all intermediate routers just read it and use it, instead of doing their own classification DiffServ: Applies special markers at the edges to mark a packet for special quality-of-service Fast Searching - Using Set Pruning Tries Assume a two dimensional rule that only cares about source and destination IPs.\nWe can build a trie (similar to earlier in this section), where each leaf node is another trie\nBy S1, we denote the source prefix of rule R1, S2 of rule R2, etc. Thus for every destination prefix D in the destination trie, we “prune” the set of rules to those compatible with D. We first match the destination IP address in a packet in the destination trie. Then we traverse the corresponding source trie to find the longest prefix match for the source IP. The algorithm keeps track of the lowest-cost matching rule. Finally, the algorithm concludes with the least-cost rule. Challenge: The problem that we need to solve now is which source prefixes to store at the sources tries? For example, let’s consider the destination D = 00*. Both rules R4 and R5 have D as the destination prefix. So the source tries for D will need to include the source prefixes 1* and 11*. But if we restrict to 1* and 11*, this is not sufficient. Because the prefix 0*, also matches 00*, and it is found in rules R1, R2, R3, R7. So we will need to include all the corresponding source prefixes. Moving forward, the problem with the set pruning tries is memory explosion. Because a source prefix can occur in multiple destination tries.\nReducing Memory Using Backtracking Set pruning has a high cost in memory to reduce time. So we can trade memory for time and try to solve this problem.\nFrom the lecture:\nThe set pruning approach has a high cost in memory to reduce time. The opposite approach is to pay in time to reduce memory. Let’s assume a destination prefix D. The backtracking approach has each destination prefix D point to a source trie that stores the rules whose destination field is exactly D. The search algorithm then performs a “backtracking” search on the source tries associated with all ancestors of D. So first, the algorithm goes through the destination trie and finds the longest destination prefix D matching the header. Then it works its way back up the destination trie and searches the source trie associated with every ancestor prefix of D that points to a nonempty source trie. Since each rule is stored exactly once, the memory requirements are lower than the previous scheme. But, the lookup cost for backtracking is worse than for set-pruning tries.\nGrid of Tries We’ve tried Backtracking (high time lower memory), and set pruning (memory explosion). Both fail for their own reasons.\nGrid of tries approach takes backtracking and reduces wasted time by precomputing. When backtracking if there is a failure point in the source trie, we have a “switch pointer” which takes you directly to the next possible source trie containing a matching rule.\nAt places where there may be a failure to get to a matching rule, we can go directly to the next most likely place to find a rule, with precomputed switch pointers.\nScheduling Now we talk about scheduling. Given a N-by-N crossbar switch with N input lines, N output lines, and N2 crosspoint we need to ensure that each input link is only connected to one output link at any given time and we want to maximize throughput by having the as many parallel routes open at one time as possible.\nTake a Ticket Algorithm Every output link has a queue, when an input link would like to use that queue it gets a ticket, and waits until it is called to send its packet and the route is opened.\nRound 1:\nRound 2:\nRound 3: and here is an overview of how this all plays out:\nOne thing to note here is that all of the other messages that are going to other nodes are blocked by the fact that they all wanted to go to output 1 first. This is “Head of line” blocking caused by take a ticket.\nAvoiding Head of Line with Take a Ticket Output Queuing Given an N-by-N crossbar switch can we try to send to an output link without queuing? Then it would only need to block packets which are headed for the same destination. To do this the fabric must run N times faster than the input links.\nA practical approach to this is the knockout scheme. It breaks up packets into fixed sizes k (which is smaller than N). Then if the fabric needs to only run k times as fast as an input link instead of N.\nIn some cases this can be broken and there are primitive switching rules to handle this.\nk = 1 and N = 2. Randomly pick the output that is chosen. The switching element, in this case, is called a concentrator. k = 1 and N \u003e 2. One output is chosen out of N possible outputs. We can use the same strategy of multiple 2-by-2 concentrators in this case. k needs to be chosen out of N possible cells, with k and N arbitrary values. We create k knockout trees to calculate the first k winners. The drawback of this approach is it is complex to implement.\nParallel Iterative Matching This approach still allows queuing but in a way that avoids head-of-line blocking. It starts with taking each incoming link’s queue and breaking it into virtual queues for each output link.\nIf an input receives multiple grants, it randomly picks between the two. This allows more packets to attempt to go through more quickly at the same time, and is more efficient than take-a-ticket.\nScheduling Intro Busy routers rely on scheduling for routing updates, management queries, and data packets. Since linkspeeds are climbing over 40 gigabit, this needs to be done very quickly.\nFIFO with tail drop This is a simple first in first out queue, but if the queue is larger than its limit, the packets at the “tail” are dropped off.\nQuality of Service The FIFO approach has pretty bad quality of service with not guaranteed delivery due to dropping packets in the tail.\nThis is bad for the following reasons:\nRouter support for congestion Congestion in the internet is increasingly possible as the usage has increased faster than the link speeds. While most traffic is based on TCP (which has its own ways to handle congestion), additional router support can improve the throughput of sources by helping handle congestion.\nProviding QoS guarantees to flows During periods of backup, these packets tend to flood the buffers at an output link. If we use FIFO with tail drop, this blocks other flows, resulting in important connections on the clients’ end freezing. This provides a sub-optimal experience to the user, indicating a change is necessary!\nFair sharing of links among competing flows One way to enable fair sharing is to guarantee certain bandwidths to a flow. Another way is to guarantee the delay through a router for a flow. This is noticeably important for video flows – without a bound on delays, live video streaming will not work well.\nBit by Bit Round Robin FIFO might drop packets. So we can use round robin to fix that. Pure round robin struggles though if one link has different packet sizes than the other, which might result in one link getting better service than the other.\nBit by Bit fixes this. The idea is that even though we can’t split packets up bit by bit, we can kind of do it virtually to help inform scheduling decisions. Using a lot of fancy math we can determine the round in which a packet finishes sending.\nThe Bit by Bit round robin then works by sending the packet which has the smallest finishing round number. Consider the following example:\nF is their finishing number, in their respective queues.\nWe can see F=1002 is sent first, because it had the earliers round finishing number. It was the “most starved” packet during the prior scheduling round.\nThis is fair, but introduces new complexities. Specifically maintaining a priority queue becomes very expensive, and takes a long time, which isn’t feasible at gigabit speeds.\nDeficit Round Robin Round robin guaranteed delay and bandwidth fairness, but many applications only care aobut bandwidth fairness. So a simple constant-time round robin could get that done much more simply.\nWe assign a quantum size, Qi, and a deficit counter, Di, for each flow. The quantum size determines the share of bandwidth allocated to that flow. For each turn of round-robin, the algorithm will serve as many packets in the flow i with size less than (Qi + Di). If packets remain in the queue, it will store the remaining bandwidth in Di for the next run. However, if all packets in the queue are serviced in that turn, it will clear Di to 0 for the next turn.\nConsider the following:\nIn this router, there are four flows – F1, F2, F3, and F4. The quantum size for all flows is 500. Initially, the deficit counters for all flows are set to 0. Initially, the round-robin pointer points to the first flow. The first packet of size 200 will be sent through. However, the funds are insufficient to send the second packet of size 750. Thus, a deficit of 300 will remain in D1. For F2, the first packet of size 500 will be sent, leaving D2 empty. Similarly, the first packets of F3 and F4 will be sent with D3 = 400 and D4 = 320 after the first iteration. For the second iteration, the D1+ Q1 = 800, meaning there are sufficient funds to send the second and third packets through. Since there are no remaining packets, D1 will be set to 0 instead of 30 (the actual remaining amount).\nToken Bucket Sometimes we want to limit flows of certain data types without having to put them into another queue.\nToken bucket shaping can accomplish this through things like limiting burstiness of flow by limiting the average rate, and limiting the burst maximum size allowed.\nIf a packet comes and needs to hit the bucket, the bucket has to have enough available tokens, otherwise it fails. That’s how you limit burst.\nThe problem with this is only one queue per flow. If a flow has a full token bucket it may block other flows. Token policing solves this.\nLeaky Bucket (Token Policing) Policing and shaping both help limit the output of a link but in different ways.\nPolicer: When the traffic rate reaches the maximum configured rate, excess traffic is dropped, or the packet’s setting or “marking” is changed. The output rate appears as a saw-toothed wave. Shaper: A shaper typically retains excess packets in a queue or a buffer, and this excess is scheduled for later transmission. The result is that excess traffic is delayed instead of dropped. Thus, the flow is shaped or smoothed when the data rate is higher than the configured rate. Traffic shaping and policing can work in tandem. Leaky bucket refers to the Token Bucket implementation with a constant output rate. If a packet were to make a bucket overflow it is discarded, but the same time things aren’t sent in burst, but at a constant “leak” rate.\n",
  "wordCount" : "9675",
  "inLanguage": "en",
  "image":"https://nathanemb.github.io/codetrails/osi_model_7_layers.png","datePublished": "2025-05-24T20:48:59-04:00",
  "dateModified": "2025-05-24T20:48:59-04:00",
  "author":{
    "@type": "Person",
    "name": "Nathan Embaugh"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Nathan Embaugh | codetrails",
    "logo": {
      "@type": "ImageObject",
      "url": "https://nathanemb.github.io/codetrails/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://nathanemb.github.io/codetrails/" accesskey="h" title="Nathan Embaugh | codetrails (Alt + H)">Nathan Embaugh | codetrails</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://nathanemb.github.io/codetrails/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://nathanemb.github.io/codetrails/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://nathanemb.github.io/codetrails/">Home</a>&nbsp;»&nbsp;<a href="https://nathanemb.github.io/codetrails/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      CS6250 - Computer Networks - Notes
    </h1>
    <div class="post-meta"><span title='2025-05-24 20:48:59 -0400 EDT'>May 24, 2025</span>&nbsp;·&nbsp;46 min&nbsp;·&nbsp;Nathan Embaugh&nbsp;|&nbsp;<a href="https://github.com/NathanEmb/codetrails/issues/new/choose" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> 
<figure class="entry-cover">
            <img loading="eager"
                srcset='https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_a75976601a15ce17.png 360w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_eef6607b514803c3.png 480w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_3532c72e7119b318.png 720w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_3771e8c5c8ca8464.png 1080w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers_hu_e79f2da8efd67dc.png 1500w,https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers.png 5667w'
                src="https://nathanemb.github.io/codetrails/posts/4-computer-networks-notes/osi_model_7_layers.png"
                sizes="(min-width: 768px) 720px, 100vw"
                width="5667" height="2834"
                alt="The OSI model.">
        <figcaption>The theoretical OSI model.</figcaption>
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#lesson-1---introduction-history-and-internet-architecture" aria-label="Lesson 1 - Introduction, History, and Internet Architecture">Lesson 1 - Introduction, History, and Internet Architecture</a><ul>
                        
                <li>
                    <a href="#history-of-the-internet" aria-label="History of the internet">History of the internet</a></li>
                <li>
                    <a href="#internet-architecture" aria-label="Internet Architecture">Internet Architecture</a><ul>
                        
                <li>
                    <a href="#application-layer" aria-label="Application Layer">Application Layer</a></li>
                <li>
                    <a href="#the-presentation-layer" aria-label="The Presentation Layer">The Presentation Layer</a></li>
                <li>
                    <a href="#the-session-layer" aria-label="The Session Layer">The Session Layer</a></li>
                <li>
                    <a href="#the-transport-layer" aria-label="The Transport Layer">The Transport Layer</a></li>
                <li>
                    <a href="#the-network-layer" aria-label="The Network Layer">The Network Layer</a></li>
                <li>
                    <a href="#the-data-link-layer" aria-label="The Data Link Layer">The Data Link Layer</a></li>
                <li>
                    <a href="#the-physical-layer" aria-label="The Physical Layer">The Physical Layer</a></li></ul>
                </li>
                <li>
                    <a href="#encapsulation" aria-label="Encapsulation">Encapsulation</a></li>
                <li>
                    <a href="#the-end-to-end-e2e-principle" aria-label="The End to End (e2e) Principle">The End to End (e2e) Principle</a><ul>
                        
                <li>
                    <a href="#violations-of-e2e" aria-label="Violations of e2e">Violations of e2e</a></li></ul>
                </li>
                <li>
                    <a href="#the-hourglass-shape-of-the-internet" aria-label="The Hourglass Shape of the Internet">The Hourglass Shape of the Internet</a></li>
                <li>
                    <a href="#interconnecting-hosts-and-networks" aria-label="Interconnecting Hosts and Networks">Interconnecting Hosts and Networks</a><ul>
                        
                <li>
                    <a href="#repeaters-and-hubs" aria-label="Repeaters and Hubs">Repeaters and Hubs</a></li>
                <li>
                    <a href="#bridges-and-layer-2-switches" aria-label="Bridges and Layer-2 Switches">Bridges and Layer-2 Switches</a></li>
                <li>
                    <a href="#routers-and-layer-3-switches" aria-label="Routers and Layer-3 Switches">Routers and Layer-3 Switches</a></li></ul>
                </li>
                <li>
                    <a href="#learning-bridges" aria-label="Learning Bridges">Learning Bridges</a><ul>
                        
                <li>
                    <a href="#the-looping-problem" aria-label="The Looping Problem">The Looping Problem</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#lesson-2---the-transport-layer-tcp" aria-label="Lesson 2 - The Transport Layer (TCP)">Lesson 2 - The Transport Layer (TCP)</a><ul>
                        
                <li>
                    <a href="#transport-layer-intro" aria-label="Transport Layer intro">Transport Layer intro</a></li>
                <li>
                    <a href="#multiplexing" aria-label="Multiplexing">Multiplexing</a></li>
                <li>
                    <a href="#connectionless-multiplexing" aria-label="Connectionless Multiplexing">Connectionless Multiplexing</a></li>
                <li>
                    <a href="#connection-oriented-multiplexing" aria-label="Connection Oriented Multiplexing">Connection Oriented Multiplexing</a></li>
                <li>
                    <a href="#a-word-on-udp" aria-label="A word on UDP">A word on UDP</a></li>
                <li>
                    <a href="#tcp" aria-label="TCP">TCP</a><ul>
                        
                <li>
                    <a href="#three-way-handshake" aria-label="Three way handshake">Three way handshake</a></li>
                <li>
                    <a href="#connection-tear-down" aria-label="Connection tear down">Connection tear down</a></li></ul>
                </li>
                <li>
                    <a href="#reliable-transmission-tcp" aria-label="Reliable Transmission (TCP)">Reliable Transmission (TCP)</a></li>
                <li>
                    <a href="#transmission-control-tcp" aria-label="Transmission Control (TCP)">Transmission Control (TCP)</a><ul>
                        
                <li>
                    <a href="#flow-control" aria-label="Flow Control">Flow Control</a></li>
                <li>
                    <a href="#congestion-control" aria-label="Congestion Control">Congestion Control</a><ul>
                        
                <li>
                    <a href="#network-assisted" aria-label="Network Assisted">Network Assisted</a></li>
                <li>
                    <a href="#end-to-end" aria-label="End to End">End to End</a></li></ul>
                </li>
                <li>
                    <a href="#tcp-throughput" aria-label="TCP Throughput">TCP Throughput</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#lesson-3---intradomain-routing-the-network-layer" aria-label="Lesson 3 - Intradomain Routing (The Network Layer)">Lesson 3 - Intradomain Routing (The Network Layer)</a><ul>
                        
                <li>
                    <a href="#routing" aria-label="Routing">Routing</a><ul>
                        
                <li>
                    <a href="#link-state-routing" aria-label="Link State Routing">Link State Routing</a></li>
                <li>
                    <a href="#distance-vector-routing" aria-label="Distance Vector Routing">Distance Vector Routing</a><ul>
                        
                <li>
                    <a href="#a-simple-example" aria-label="A simple example">A simple example</a></li>
                <li>
                    <a href="#pitfalls-of-dv" aria-label="Pitfalls of DV">Pitfalls of DV</a></li></ul>
                </li>
                <li>
                    <a href="#routing-information-protocol-rip" aria-label="Routing Information Protocol (RIP)">Routing Information Protocol (RIP)</a></li>
                <li>
                    <a href="#open-shortest-path-first" aria-label="Open Shortest Path First">Open Shortest Path First</a></li></ul>
                </li>
                <li>
                    <a href="#hot-potato-routing" aria-label="Hot Potato Routing">Hot Potato Routing</a></li></ul>
                </li>
                <li>
                    <a href="#lesson-4---interdomain-routing-and-as-relationships" aria-label="Lesson 4 - Interdomain Routing and AS Relationships">Lesson 4 - Interdomain Routing and AS Relationships</a><ul>
                        
                <li>
                    <a href="#the-internet" aria-label="The Internet">The Internet</a></li>
                <li>
                    <a href="#as-ecosystem" aria-label="AS Ecosystem">AS Ecosystem</a></li>
                <li>
                    <a href="#internet-business" aria-label="Internet Business">Internet Business</a><ul>
                        
                <li>
                    <a href="#exporting-routes" aria-label="Exporting Routes">Exporting Routes</a></li>
                <li>
                    <a href="#importing-routes" aria-label="Importing Routes">Importing Routes</a></li></ul>
                </li>
                <li>
                    <a href="#border-gateway-protocol-bgp" aria-label="Border Gateway Protocol (BGP)">Border Gateway Protocol (BGP)</a><ul>
                        
                <li>
                    <a href="#bgp-design-goals" aria-label="BGP Design Goals">BGP Design Goals</a></li>
                <li>
                    <a href="#bgp-basics" aria-label="BGP Basics">BGP Basics</a></li>
                <li>
                    <a href="#ibgp-vs-ebgp" aria-label="iBGP vs eBGP">iBGP vs eBGP</a></li>
                <li>
                    <a href="#bgp-router-process" aria-label="BGP Router Process">BGP Router Process</a></li>
                <li>
                    <a href="#bgp-issues" aria-label="BGP Issues">BGP Issues</a></li></ul>
                </li>
                <li>
                    <a href="#peering-at-ixps" aria-label="Peering at IXPs">Peering at IXPs</a><ul>
                        
                <li>
                    <a href="#route-servers" aria-label="Route Servers">Route Servers</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#lesson-5-and-6---router-design-and-algorithms" aria-label="Lesson 5 and 6 - Router Design and Algorithms">Lesson 5 and 6 - Router Design and Algorithms</a><ul>
                        
                <li>
                    <a href="#router-components" aria-label="Router Components">Router Components</a><ul>
                        
                <li>
                    <a href="#forwarding-switching-function" aria-label="Forwarding (Switching) function">Forwarding (Switching) function</a></li>
                <li>
                    <a href="#control-plane-function" aria-label="Control Plane function">Control Plane function</a></li></ul>
                </li>
                <li>
                    <a href="#router-architecture" aria-label="Router Architecture">Router Architecture</a></li>
                <li>
                    <a href="#switching-fabric" aria-label="Switching Fabric">Switching Fabric</a><ul>
                        
                <li>
                    <a href="#switching-via-memory" aria-label="Switching via memory">Switching via memory</a></li>
                <li>
                    <a href="#switching-via-bus" aria-label="Switching via bus">Switching via bus</a></li>
                <li>
                    <a href="#switching-via-interconnection-network" aria-label="Switching via interconnection network">Switching via interconnection network</a></li></ul>
                </li>
                <li>
                    <a href="#router-challenges" aria-label="Router Challenges">Router Challenges</a><ul>
                        
                <li>
                    <a href="#common-bottlenecks" aria-label="Common bottlenecks">Common bottlenecks</a></li></ul>
                </li>
                <li>
                    <a href="#prefix-matching" aria-label="Prefix matching">Prefix matching</a><ul>
                        
                <li>
                    <a href="#unibit-tries" aria-label="Unibit Tries">Unibit Tries</a></li>
                <li>
                    <a href="#multibit-tries" aria-label="Multibit Tries">Multibit Tries</a><ul>
                        
                <li>
                    <a href="#prefix-expansion" aria-label="Prefix expansion">Prefix expansion</a></li></ul>
                </li>
                <li>
                    <a href="#fixed-stride-example" aria-label="Fixed Stride Example">Fixed Stride Example</a></li>
                <li>
                    <a href="#variable-stride-length" aria-label="Variable Stride Length">Variable Stride Length</a></li></ul>
                </li>
                <li>
                    <a href="#packet-classification" aria-label="Packet Classification">Packet Classification</a><ul>
                        
                <li>
                    <a href="#simple-classifiers" aria-label="Simple Classifiers">Simple Classifiers</a></li>
                <li>
                    <a href="#fast-searching---using-set-pruning-tries" aria-label="Fast Searching - Using Set Pruning Tries">Fast Searching - Using Set Pruning Tries</a></li>
                <li>
                    <a href="#reducing-memory-using-backtracking" aria-label="Reducing Memory Using Backtracking">Reducing Memory Using Backtracking</a></li>
                <li>
                    <a href="#grid-of-tries" aria-label="Grid of Tries">Grid of Tries</a></li></ul>
                </li>
                <li>
                    <a href="#scheduling" aria-label="Scheduling">Scheduling</a><ul>
                        
                <li>
                    <a href="#take-a-ticket-algorithm" aria-label="Take a Ticket Algorithm">Take a Ticket Algorithm</a></li>
                <li>
                    <a href="#avoiding-head-of-line-with-take-a-ticket" aria-label="Avoiding Head of Line with Take a Ticket">Avoiding Head of Line with Take a Ticket</a></li>
                <li>
                    <a href="#output-queuing" aria-label="Output Queuing">Output Queuing</a></li>
                <li>
                    <a href="#parallel-iterative-matching" aria-label="Parallel Iterative Matching">Parallel Iterative Matching</a></li>
                <li>
                    <a href="#scheduling-intro" aria-label="Scheduling Intro">Scheduling Intro</a><ul>
                        
                <li>
                    <a href="#fifo-with-tail-drop" aria-label="FIFO with tail drop">FIFO with tail drop</a></li>
                <li>
                    <a href="#quality-of-service" aria-label="Quality of Service">Quality of Service</a><ul>
                        
                <li>
                    <a href="#router-support-for-congestion" aria-label="Router support for congestion">Router support for congestion</a></li>
                <li>
                    <a href="#providing-qos-guarantees-to-flows" aria-label="Providing QoS guarantees to flows">Providing QoS guarantees to flows</a></li>
                <li>
                    <a href="#fair-sharing-of-links-among-competing-flows" aria-label="Fair sharing of links among competing flows">Fair sharing of links among competing flows</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#bit-by-bit-round-robin" aria-label="Bit by Bit Round Robin">Bit by Bit Round Robin</a></li>
                <li>
                    <a href="#deficit-round-robin" aria-label="Deficit Round Robin">Deficit Round Robin</a></li>
                <li>
                    <a href="#token-bucket" aria-label="Token Bucket">Token Bucket</a></li>
                <li>
                    <a href="#leaky-bucket-token-policing" aria-label="Leaky Bucket (Token Policing)">Leaky Bucket (Token Policing)</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="lesson-1---introduction-history-and-internet-architecture">Lesson 1 - Introduction, History, and Internet Architecture<a hidden class="anchor" aria-hidden="true" href="#lesson-1---introduction-history-and-internet-architecture">#</a></h2>
<h3 id="history-of-the-internet">History of the internet<a hidden class="anchor" aria-hidden="true" href="#history-of-the-internet">#</a></h3>
<p>The internet began as many things in tech did, from DARPA.</p>
<p>Specifically:</p>
<ol>
<li>J.C.R. Licklider proposed the &ldquo;Galactic Network&rdquo; (1962)
<ul>
<li>Attached a computer in Stanford to a computer at MIT, thus beginning computers talking to each other</li>
</ul>
</li>
<li>The ARPANET (1969)
<ul>
<li>UCSB, UCLA, Stanford, and U of Utah interlink</li>
</ul>
</li>
<li>Network Control Protocol (NCP), an initial ARPANET host-to-host protocol (1970)
<ul>
<li>The first protocol was designed to handle increasing number of computers, first app built on this was email</li>
</ul>
</li>
<li>Inter-networking and TCP/IP (1973)
<ul>
<li>NCP became TCP/IP, IP for addressing and forwarding packets, TCP for flow control and recovery from lost packets</li>
</ul>
</li>
<li>The Domain Name System (DNS) (1983) and the World Wide Web (WWW) (1990)
<ul>
<li>As the internet exploded with content and endpoints, they needed a way to turn domains into IP addresses. In walks DNS.</li>
</ul>
</li>
</ol>
<h3 id="internet-architecture">Internet Architecture<a hidden class="anchor" aria-hidden="true" href="#internet-architecture">#</a></h3>
<p>The internet was built in layers. Each layer is supposed to have its own job, and not rely on any of the layers above or below it.</p>
<p>Think of a person as a bit of data, then watch them fly from one airport to another and you get the idea.</p>
<p><img alt="Internet as a flight path diagram" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%2011.09.35%20AM.png"></p>
<p>So there is an originally designed theoretical layer named the OSI model, which had 7 layers, and then the layers that were actually implemented, known as the Internet Protocol Stack.</p>
<p><img alt="OSI Model vs actual Internet Model" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Network%20Layers.jpg"></p>
<p>These layers are not as perfect as we would hope, specifically sometimes they do rely on the other layers or they both have methods of solving the same problem like error recovery.</p>
<p>Notice that the Session and Presentation layers disappear in the Internet Protocol Stack, those are handled in the <em>ports</em> of each network device. The logic that is accomplished in those layers still happens, just all in one place.</p>
<h4 id="application-layer">Application Layer<a hidden class="anchor" aria-hidden="true" href="#application-layer">#</a></h4>
<p>The data here is a <strong>message</strong>.</p>
<p>This is the layer we all interact with all the time.</p>
<ul>
<li>HTTP (web)</li>
<li>SMTP (e-mail)</li>
<li>FTP (transfers files between two end hosts)</li>
<li>DNS (translates domain names to IP addresses)</li>
</ul>
<p>Takes the content that we want to ship around, and does all the encoding and decoding needed to actually USE it.</p>
<h4 id="the-presentation-layer">The Presentation Layer<a hidden class="anchor" aria-hidden="true" href="#the-presentation-layer">#</a></h4>
<p>The presentation layer plays the intermediate role of formatting the information that it receives from the layer below and delivering it to the application layer. For example, some functionalities of this layer are formatting a video stream or translating integers from big endian to little endian format.</p>
<h4 id="the-session-layer">The Session Layer<a hidden class="anchor" aria-hidden="true" href="#the-session-layer">#</a></h4>
<p>The session layer is responsible for the mechanism that manages the different transport streams that belong to the same session between end-user application processes. For example, in the case of a teleconference application, it is responsible to tie together the audio stream and the video stream.</p>
<h4 id="the-transport-layer">The Transport Layer<a hidden class="anchor" aria-hidden="true" href="#the-transport-layer">#</a></h4>
<p>The data here is a <strong>segment</strong>.</p>
<p>End to End communication between hosts.</p>
<ul>
<li>Transmission Control Protocol (TCP)</li>
<li>User Datagram Protocol (UDP)</li>
</ul>
<p>TCP is better <em>connection</em>-oriented services, guarantees delivery, manages flow control, and controls congestion. This is the USPS, slow but reliable (except TCP doesn&rsquo;t lose mail like the USPS).</p>
<p>UDP is fast and guarantees <em>nothing</em>. Receivers and Senders using UDP must be able to handle segments getting dropped, delayed, or not making it entirely. But they should be faster when everything is working compared to TCP.</p>
<h4 id="the-network-layer">The Network Layer<a hidden class="anchor" aria-hidden="true" href="#the-network-layer">#</a></h4>
<p>The data here is a <strong>datagram</strong>.</p>
<p>This is where IP comes into play. This layer is responsible for connecting one computer to another, via the IP address that everyone has.</p>
<h4 id="the-data-link-layer">The Data Link Layer<a hidden class="anchor" aria-hidden="true" href="#the-data-link-layer">#</a></h4>
<p>The data here is a <strong>frame</strong>.</p>
<p>This layer is responsible for moving the frames from one node (host or router/switch) to the next node. This uses things like:</p>
<ol>
<li>Ethernet</li>
<li>Point-to-point Protocol (PPP)</li>
<li>Wi-Fi</li>
</ol>
<h4 id="the-physical-layer">The Physical Layer<a hidden class="anchor" aria-hidden="true" href="#the-physical-layer">#</a></h4>
<p>The actual hardware translation. Translating electricity into bits based on ethernet, coax, fiber, etc.</p>
<h3 id="encapsulation">Encapsulation<a hidden class="anchor" aria-hidden="true" href="#encapsulation">#</a></h3>
<p>These layers work on the idea of encapsulation and de-encapsulation. So encapsulation is to take a chunk of data, package it up, add a header to it and pass it on. Then de-encapsulation is using the headers to decode each chunk of data, until all you&rsquo;re left with is the data/message.</p>
<p><img alt="encapsulation vs de-encapsulation" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/0_tDSGidTRt7KrG6BR.webp"></p>
<p>This method is what allows people to build upon the existing infrastructure of the internet, but still make new things.</p>
<h3 id="the-end-to-end-e2e-principle">The End to End (e2e) Principle<a hidden class="anchor" aria-hidden="true" href="#the-end-to-end-e2e-principle">#</a></h3>
<p>The e2e principle shaped the internet as we know it today.</p>
<p>Essentially the principle is that 99% of the complexity should be at the ends of the communications. This allows the underlying infrastructure to be simple, but expandable, and allows people working at the different ends to iterate and create new things quickly.</p>
<p>If they had to change the underlying architecture every time they wanted to change anything it would bring development speed to a crawl.</p>
<p>Beneficial excerpt from the lecture:</p>
<p>Many people argue that the e2e principle allowed the internet to grow rapidly because evolving innovation took place at the network edge, in the form of numerous applications and a plethora of services, rather than in the middle of the network, which could be hard to modify later.</p>
<blockquote>
<p>What were the designers’ original goals that led to the e2e principle?</p>
<blockquote>
<p>Moving functions and services closer to the applications that use them increases the flexibility and the autonomy of the application designer to offer these services to the needs of the specific application.</p></blockquote></blockquote>
<blockquote>
<p>Thus, the higher-level protocol layers are more specific to an application. Whereas the lower-level protocol layers are free to organize the lower-level network resources to achieve application design goals more efficiently and independently of the specific application.</p></blockquote>
<h4 id="violations-of-e2e">Violations of e2e<a hidden class="anchor" aria-hidden="true" href="#violations-of-e2e">#</a></h4>
<p>All rules are meant to be broken.</p>
<p>Firewalls, NAT boxes, and traffic filters all break the e2e principle, and usually for good reason.</p>
<p>NAT routers provide a way to make up for the fact that there aren&rsquo;t that many IP addresses available in IPv4. Instead of EVERY device having its own worldwide public IP address, you give your home 1 IP address, and then every device behind that has its own local address.</p>
<p>This means that whenever a message is sent to your PC it goes:</p>
<p>Web &gt; Router (Public IP)&gt; End Device (local IP)</p>
<p>The router is breaking some rules of e2e, because it is intervening and inspecting data.</p>
<p>This is the notes&rsquo; reasoning for why:</p>
<blockquote>
<p>Why do NAT boxes violate the e2e principle?
The hosts behind NAT boxes are not globally addressable or routable. As a result, it is not possible for other hosts on the public Internet to initiate connections to these devices. So, if we have a host behind a NAT and a host on the public Internet, they cannot communicate by default without the intervention of a NAT box.
Some workarounds allow hosts to initiate connections to hosts that exist behind NATs. For example, Session Traversal Utilities for NAT, or STUN, is a tool that enables hosts to discover NATs and the public IP address and port number that the NAT has allocated for the applications for which the host wants to communicate. Also, UDP hole punching establishes bidirectional UDP connections between hosts behind NATs.</p></blockquote>
<h3 id="the-hourglass-shape-of-the-internet">The Hourglass Shape of the Internet<a hidden class="anchor" aria-hidden="true" href="#the-hourglass-shape-of-the-internet">#</a></h3>
<p>The internet is curvy.</p>
<p>No really, there&rsquo;s a ton on each end of it, but the middle is pretty narrow. Specifically, TCP, UDP, IP are really the backbone of literally everything. See below:</p>
<p><img alt="hourglass internet" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L1-1%20Evolutionary%20Architecture%20Model.jpg"></p>
<p>All roads lead to IP, and TCP/UDP. Researchers have actually done a lot of work to see why this is. They called it the evolutionary architecture model. They did a bunch of in depth quantifications of why/what the internet is and how they got there and drew some interesting conclusions.</p>
<p>In an ideal world where we could do it all over they came up with the following:</p>
<blockquote>
<p>Finally, in terms of future and entirely new Internet architectures, the EvoArch model predicts that even if these brand-new architectures do not have the shape of an hourglass initially, they will probably do so as they evolve, which will lead to new ossified protocols. The model suggests that one way to proactively avoid these ossification effects that we now experience with TCP/IP is for a network architect to design the functionality of each layer so that the waist is wider, consisting of several protocols that offer largely non-overlapping but general services, so that they do not compete with each other.</p></blockquote>
<h3 id="interconnecting-hosts-and-networks">Interconnecting Hosts and Networks<a hidden class="anchor" aria-hidden="true" href="#interconnecting-hosts-and-networks">#</a></h3>
<p>Talking about how to theoretically communicate between computers is important, but hardware actually makes the physical connections.</p>
<p>Those are:</p>
<h4 id="repeaters-and-hubs">Repeaters and Hubs<a hidden class="anchor" aria-hidden="true" href="#repeaters-and-hubs">#</a></h4>
<p>They operate on the physical layer (L1) as they receive and forward digital signals to connect different Ethernet segments. They provide connectivity between hosts that are directly connected (in the same network). The advantage is that they are simple and inexpensive devices, and they can be arranged in a hierarchy. Unfortunately, hosts that are connected through these devices belong to the same collision domain, meaning that they compete for access to the same link.</p>
<h4 id="bridges-and-layer-2-switches">Bridges and Layer-2 Switches<a hidden class="anchor" aria-hidden="true" href="#bridges-and-layer-2-switches">#</a></h4>
<p>These devices can enable communication between hosts that are not directly connected. They operate on the data link layer (L2) based on MAC addresses. They receive packets and forward them to the appropriate destination. A limitation is the finite bandwidth of the outputs. If the arrival rate of the traffic is higher than the capacity of the outputs, then packets are temporarily stored in buffers. But if the buffer space gets full, then this can lead to packet drops.</p>
<h4 id="routers-and-layer-3-switches">Routers and Layer-3 Switches<a hidden class="anchor" aria-hidden="true" href="#routers-and-layer-3-switches">#</a></h4>
<p>These are devices that operate on the network layer (L3).</p>
<h3 id="learning-bridges">Learning Bridges<a hidden class="anchor" aria-hidden="true" href="#learning-bridges">#</a></h3>
<p>A bridge is a piece of hardware that manages the connection between many devices, connected to the same piece of hardware.</p>
<p><img alt="learning bridge" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L1-4%20Illustration%20of%20a%20Learning%20Bridge.jpg"></p>
<p>The bridge is able to understand what devices are on port 1, what devices are on port 2, and so on. This is like a home network switch. You can connect many devices to it, and it handles knowing where the data needs to end up.</p>
<h4 id="the-looping-problem">The Looping Problem<a hidden class="anchor" aria-hidden="true" href="#the-looping-problem">#</a></h4>
<p>The problem with these bridges, is that you can create a loop.</p>
<p>if A connects to B which connects to C which connects to A, you&rsquo;ve created a loop. This can result in never ending looping!</p>
<p>This is handled by running a spanning tree algorithm. The goal of the spanning tree algorithm is to identify which ports when used will eliminate any endless looping.</p>
<p>This works by operating in rounds, and then by removing bridges from the network until you only have one path to every node. This is accomplished by running in rounds the following process:</p>
<ol>
<li>Every node sends:
<ul>
<li>Sender Node ID</li>
<li>Root ID as perceived by sender</li>
<li>Distance from root node</li>
</ul>
</li>
<li>Each node selects the best configuration in order of
<ul>
<li>If root of the one configuration has a smaller ID</li>
<li>If roots have equal IDs choose one with smaller distance to the root</li>
<li>If they have the same distance, choose configuration with smallest sender ID</li>
</ul>
</li>
<li>A node stops sending configuration messages over a link (port) when it receives a configuration message from a neighbor that is:
<ul>
<li>either closer to the root</li>
<li>has the same distance from the root, but it has a smaller ID.</li>
</ul>
</li>
</ol>
<p>We can see this process completed in the following images:</p>
<p><img alt="pre-tree-span" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%2011.36.30%20AM.png"></p>
<p>Then after tree spanning:</p>
<p><img alt="post-tree-spanning" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%2011.38.09%20AM.png"></p>
<h2 id="lesson-2---the-transport-layer-tcp">Lesson 2 - The Transport Layer (TCP)<a hidden class="anchor" aria-hidden="true" href="#lesson-2---the-transport-layer-tcp">#</a></h2>
<p>This lesson is going to talk about the actual protocol responsible for transporting data from one location to another, TCP. The logical connection between two hosts is done in the transport layer.</p>
<p>The transport layer receives a message from the application layer and appends its own header on to it. This is known as a segment. The segment is then sent to the Network layer where it happily bounces through all the routers, bridges, and switches that might be on its path.</p>
<h3 id="transport-layer-intro">Transport Layer intro<a hidden class="anchor" aria-hidden="true" href="#transport-layer-intro">#</a></h3>
<p>Why do we need a transport layer? Why not just send messages directly from the application layer to the network layer? Because the network layer guarantees <strong>nothing</strong>. The transport layer guarantees delivery, and data integrity in a way that wouldn&rsquo;t have been done otherwise.</p>
<p>As mentioned previously there are two main transport layer protocols User Datagram Protocol (UDP) and Transmission Control Protocol (TCP).</p>
<p>UDP just tries to quickly send data, and doesn&rsquo;t do much else. As such it provides no guarantees and puts the responsibility on the application layer to do things like verify integrity and handle dropped messages.</p>
<p>TCP on the other hand does have these extra bells and whistles built in and thus it is much more reliable, if not a tad slower than UDP.</p>
<h3 id="multiplexing">Multiplexing<a hidden class="anchor" aria-hidden="true" href="#multiplexing">#</a></h3>
<p>Multiplexing is the ability for many hosts to use the same network simultaneously. Consider two computers browsing the internet at the same time, or better yet, a computer that is simultaneously browsing the internet and streaming music, it has two incoming data sources, and used in two different ways.</p>
<p>We need to be able to handle this complexity. The Transport layer uses ports to do this. Each application gets one port, and listens only to that port.</p>
<p>There is <strong>Connectionless</strong> and <strong>Connection Oriented</strong> multiplexing. One based on a constant connection, and one is not.</p>
<p>We have names for each direction of this multiplexing operation.</p>
<p>Demultiplexing - Delivering data to the appropriate socket.</p>
<p>Multiplexing - Taking data from all the sockets and putting it into the network layer.</p>
<h3 id="connectionless-multiplexing">Connectionless Multiplexing<a hidden class="anchor" aria-hidden="true" href="#connectionless-multiplexing">#</a></h3>
<p>Connectionless multiplexing is the simpler case. The transport layer has a segment which has the content, a source and source port, and a destination and a destination port. It receives the data from the source port, and makes its best effort at delivering to the destination port.</p>
<p><img alt="Connectionless Multiplexing" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%209.34.42%20PM.png"></p>
<p>If the destination receives it, great, the network layer will route it to the correct port, and then the message will have been successfully delivered.</p>
<p>These are UDP sockets. It&rsquo;s very direct, with no oversight as to what actually happens to the message.</p>
<h3 id="connection-oriented-multiplexing">Connection Oriented Multiplexing<a hidden class="anchor" aria-hidden="true" href="#connection-oriented-multiplexing">#</a></h3>
<p>Connection Oriented multiplexing brings in a lot more complexity.</p>
<p><img alt="Connection Oriented Multiplexing" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%209.36.30%20PM.png"></p>
<p>TCP requires going through a TCP server. The TCP server has a listener process that waits for incoming connection requests, and when it gets it handles setting everything up so that the destination is ready to receive the message.</p>
<blockquote>
<p>Note: If a server has many clients contacting it on the same port, it&rsquo;s not an issue because they have unique IP addresses (hopefully) and they can distinguish the difference between the two that way.</p></blockquote>
<h3 id="a-word-on-udp">A word on UDP<a hidden class="anchor" aria-hidden="true" href="#a-word-on-udp">#</a></h3>
<p>UDP lacks reliability of TCP mainly because it doesn&rsquo;t require establishing a connection.</p>
<p>That lack of reliability makes it better for the following reasons:</p>
<ol>
<li>No congestion control - No process watches every packet to make sure it should be sent</li>
<li>No connection management - We don&rsquo;t have to wait for a socket to be opened, so it just sends quickly</li>
</ol>
<p>Both of these result in lower latency transmission, which is good for some things. Things like multiplayer video games, DNS servers, and other networking hosts, all like to use higher speed protocols.</p>
<p>This puts the onus on the developers on each end to ensure quality, and handle if errors occur, but when things are working well, then things are very speedy.</p>
<p><img alt="udp makeup" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L2%20Diagrams-14.png"></p>
<p>The one quality mechanism UDP provides is a checksum, so you can in fact check that the data that&rsquo;s sent is what it was supposed to be. It creates a checksum by adding together the bits of the source port, destination port and the length of the packet. It then performs a ones complement. That is the checksum.</p>
<p>The receiver takes the source port, destination port, length of packet, and the checksum and adds them all together. Because the checksum is the ones complement, when they are added together it should end up as all ones.</p>
<h3 id="tcp">TCP<a hidden class="anchor" aria-hidden="true" href="#tcp">#</a></h3>
<h4 id="three-way-handshake">Three way handshake<a hidden class="anchor" aria-hidden="true" href="#three-way-handshake">#</a></h4>
<pre><code>Step 1: The TCP client sends a special segment (containing no data) with the SYN bit set to 1. The client also generates an initial sequence number (client_isn) and includes it in this special TCP SYN segment.
</code></pre>
<p>Step 2: The server, upon receiving this packet, allocates the required resources for the connection and sends back the special &ldquo;connection-granted&rdquo; segment which we call SYNACK segment. This packet has the SYN bit set to 1, the acknowledgement field of the TCP segment header set to client_isn+1, and a randomly chosen initial sequence number (server_isn) for the server.</p>
<p>Step 3: When the client receives the SYNACK segment, it also allocates buffer and resources for the connection and sends an acknowledgment with SYN bit set to 0.</p>
<p><img alt="three-way-handshake" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/2%20TCP%20Three-Way%20Handshake.jpg"></p>
<h4 id="connection-tear-down">Connection tear down<a hidden class="anchor" aria-hidden="true" href="#connection-tear-down">#</a></h4>
<p>Connection Teardown</p>
<p>Step 1: When the client wants to end the connection, it sends a segment with FIN bit set to 1 to the server.</p>
<p>Step 2: The server acknowledges that it has received the connection closing request and is now working on closing the connection.</p>
<p>Step 3: The server then sends a segment with FIN bit set to 1, indicating that connection is closed.</p>
<p>Step 4: The client sends an ACK for it to the server. It also waits for some time to resend this acknowledgment in case the first ACK segment is lost.</p>
<p><img alt="teardown" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%209.47.18%20PM.png"></p>
<h3 id="reliable-transmission-tcp">Reliable Transmission (TCP)<a hidden class="anchor" aria-hidden="true" href="#reliable-transmission-tcp">#</a></h3>
<p>TCP guarantees all packets delivered in order. This is a very helpful reliability for developers to build on.</p>
<p>To do this the sender must know what the receiver successfully got. This is accomplished via ARQ (Automatic Repeat Request). If a sender doesn&rsquo;t get a message that ARQ1 was received in a certain timeframe, then it will re-send it.</p>
<p><strong>Stop and Wait ARQ</strong></p>
<p>Guess how long it should take, if you don&rsquo;t get a response, send it again. This can work but is tricky. If you send too much you&rsquo;re retransmitting for no reason, and wait too long your connection is slow.</p>
<p>TCP uses <strong>Selective ACK</strong> which basically waits for the receiver to say hey I didn&rsquo;t get this packet yet, and if it reaches a certain threshold like 3, then it will quickly resend that particular packet. This allows most of the time to be spent actively sending data, and the ability to recover from dropped packets.</p>
<p>This does require the ability to buffer packets until you have everything you need in order.</p>
<h3 id="transmission-control-tcp">Transmission Control (TCP)<a hidden class="anchor" aria-hidden="true" href="#transmission-control-tcp">#</a></h3>
<p>Deciding how much of a link bandwidth to use is a bit complicated. If you send too much for the receiver that could be an issue, or maybe the network can&rsquo;t handle it, or any other amount of things that could go wrong.</p>
<p>So TCP implements a couple things to help that.</p>
<h4 id="flow-control">Flow Control<a hidden class="anchor" aria-hidden="true" href="#flow-control">#</a></h4>
<p>Flow control is where TCP tries to identify the receiver&rsquo;s buffer that it is receiving data with, and tries to match the sender window size to that. Every ACK message includes a <code>rwnd</code> value which says how much buffer space is available.</p>
<p>The sender uses this value to ensure it never sends more bytes than is available in the receiver buffer.</p>
<p>If this value hits zero it would stop, but TCP instead sends packets of 1 byte until it gets a response with a <code>rwnd</code> greater than zero.</p>
<h4 id="congestion-control">Congestion Control<a hidden class="anchor" aria-hidden="true" href="#congestion-control">#</a></h4>
<p>Congestion control is making sure we don&rsquo;t overload any of the links on the way from one host to another.</p>
<p>Good congestion control is:</p>
<ul>
<li>Efficient - use most of the network</li>
<li>Fair - everyone gets equal amounts</li>
<li>Low delay - Low delay is good for things that need to have small lag like video conferences</li>
<li>Fast convergence - everyone gets their bandwidth quickly</li>
</ul>
<h5 id="network-assisted">Network Assisted<a hidden class="anchor" aria-hidden="true" href="#network-assisted">#</a></h5>
<p>Network assisted congestion control relies on pieces of the network sending feedback about what&rsquo;s happening. This could fail when the network is heavily congested though, kind of rendering it useless.</p>
<h5 id="end-to-end">End to End<a hidden class="anchor" aria-hidden="true" href="#end-to-end">#</a></h5>
<p>End to end congestion control gets nothing from the network and instead infers congestion from the hosts. This supports the general principle of making the complexity be at the ends of the networks.</p>
<p>This is mostly done via packet delay (how long did it take to get here) and packet loss (how many times do I need to resend). With these two things you have a rough understanding of network performance at any given moment.</p>
<p>It employs a congestion window, a number indicating roughly how much space is left in the network. This increases until congestion is detected, and then the window is made smaller to reduce congestion.</p>
<p>Ultimately the max size of a TCP packet is the minimum of the receiver buffer and the congestion window.</p>
<p>There are many different methods of increasing congestion window size:</p>
<ul>
<li>Additive</li>
<li>Multiplicative</li>
<li>TCP Reno</li>
<li>AIMD</li>
</ul>
<p>Many of these employ &ldquo;Slow start&rdquo; where they start at a low-ish speed and ramp up. This protects from overwhelming the network right at the start. With timeouts or dropped connections being common you can see why this would be useful.</p>
<p>TCP isn&rsquo;t always fair, but using some of these congestion methods will do a pretty good job of it.</p>
<h4 id="tcp-throughput">TCP Throughput<a hidden class="anchor" aria-hidden="true" href="#tcp-throughput">#</a></h4>
<p>TCP Throughput looks like a sawtooth because of these congestion control mechanisms.</p>
<p>It gets up to the limit, then drops off, then gets up to the limit then drops off.</p>
<p><img alt="throughput" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-16%20at%2010.17.59%20PM.png"></p>
<h2 id="lesson-3---intradomain-routing-the-network-layer">Lesson 3 - Intradomain Routing (The Network Layer)<a hidden class="anchor" aria-hidden="true" href="#lesson-3---intradomain-routing-the-network-layer">#</a></h2>
<p>This session focuses on the act of routing on the network layer in a single domain. Ideally we understand what it takes for two hosts to share data by the end of this.</p>
<p>We&rsquo;ll talk about:</p>
<ul>
<li>Intradomain Routing Algorithms
<ul>
<li>Link state</li>
<li>Distance vector</li>
</ul>
</li>
<li>Intradomain Protocols
<ul>
<li>Open Shortest Path First (OSPF)</li>
<li>Routing Information Protocol (RIP)</li>
</ul>
</li>
</ul>
<h3 id="routing">Routing<a hidden class="anchor" aria-hidden="true" href="#routing">#</a></h3>
<p>Given two hosts that share the same default router (first-hop router) we know that one host will send a packet to the default router, but what happens next?</p>
<p>In a network with many routers, whenever a router receives a packet, it must consult the forwarding table it maintains, and send the packet to the next router in line. This is referred to as forwarding and is not necessarily the same as routing.</p>
<p>Routing is the act of determining the best path to be traveled from one location to another. Intradomain routing is what we will focus on and it is what happens when both hosts are in the same administrative domain.</p>
<p>Interior Gateway Protocols (IGP) are what handle this type of routing. The two major types we&rsquo;ll cover are  link-state and distance-vector routing algorithms. They are graph theory algorithms with edges and nodes.</p>
<h4 id="link-state-routing">Link State Routing<a hidden class="anchor" aria-hidden="true" href="#link-state-routing">#</a></h4>
<p>Surprise, Dijkstra&rsquo;s algorithm is here again.</p>
<p>In link state, all link costs are known and the network topology is also fully known.</p>
<p>From the lecture directly.</p>
<blockquote>
<p>Let’s introduce some basic terminology. By u, we represent our source node. By v, we represent every other node in the network. By D(v), we represent the cost of the current least cost path from u to v.  By p(v), we represent the previous node along the current least cost path from u to v. By c(u,v), we represent the cost from u to directly attached neighbor v. By N&rsquo;, we represent the subset of nodes along the current least-cost path from u to v.</p></blockquote>
<p><img alt="pseudocode for link-state algo" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L3_1%20Link%20State%20Algorithm.jpg"></p>
<p>Basically we initialize with either:</p>
<ul>
<li>Known cost because it&rsquo;s a link directly connected to the node we&rsquo;re initializing</li>
<li>Infinity cost, because we know it will be less than that but we have something to compare against</li>
</ul>
<p>Then we continue looping through the network, looking for a path with lower costs than our current cost, until we don&rsquo;t find one. This is a fun application of Dijkstra&rsquo;s algorithm, where each router essentially computes Dijkstra&rsquo;s algorithm from itself to all other routers in the network.</p>
<p>This is a pretty costly algorithm at O(n^2) complexity. It also requires that you know everything about the network which is probably why this is intradomain and not interdomain.</p>
<h4 id="distance-vector-routing">Distance Vector Routing<a hidden class="anchor" aria-hidden="true" href="#distance-vector-routing">#</a></h4>
<p>The DV algorithm is iterative, asynchronous, and distributed.</p>
<p>DV is based on the Bellman Ford algorithm. Every node maintains a distance vector to all of the other nodes, and it occasionally shares that information. When a node receives a new distance vector they use it to update their own vector.</p>
<p>The Bellman Ford (BF) equation is the heart of each update: <code>Dx(y) = minv{c(x,v) + Dv(y)}</code></p>
<p><img alt="BF illustration" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/BF-updated.png"></p>
<p>See the pseudocode below:</p>
<p><img alt="DV pseudocode" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%205.36.51%20PM.png"></p>
<p>So essentially, continuously the nodes maintain a list of costs for routes to certain nodes, and these costs are updated whenever nodes send their costs. So instead of every node needing to know every cost, it allows the nodes to only know and focus on the costs of its immediate neighbors, and then relies on other nodes sending its current list of costs occasionally.</p>
<p>This is different from Link State routing because it is distributed, but they are all still computing the most efficient path through the tree.</p>
<h5 id="a-simple-example">A simple example<a hidden class="anchor" aria-hidden="true" href="#a-simple-example">#</a></h5>
<p><a href="Screen%20Shot%202020-01-17%20at%205.40.22%20PM.png">initialization</a></p>
<p><img alt="second iteration" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%205.42.05%20PM.png"></p>
<p><img alt="third iteration" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%206.56.28%20PM.png"></p>
<h5 id="pitfalls-of-dv">Pitfalls of DV<a hidden class="anchor" aria-hidden="true" href="#pitfalls-of-dv">#</a></h5>
<p>What if the link cost changes? In some cases this is handled quickly, and in other cases it can lead to a &ldquo;count-to-infinity&rdquo; problem.</p>
<p><strong>Say a link cost decreases:</strong></p>
<p><img alt="link decrease" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%206.59.26%20PM-1.png"></p>
<ol>
<li>At time t0, y detects that cost to x has changed from 4 to 1, so it updates its distance vector and sends it to its neighbors.</li>
<li>At time t1, z receives the update from y. Now z thinks it can reach x through y with a cost of 2, so it sends its new distance vector to its neighbors.</li>
<li>At time t2, y receives the update from z. Y does not change its distance vector, so it does not send any update.</li>
</ol>
<p>The update is fully propagated pretty quickly.</p>
<p><strong>Say a link cost increases:</strong></p>
<p><img alt="link increase" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.00.44%20PM.png"></p>
<ol>
<li>At t0, y detects that the cost has changed, and now it will update its distance vector thinking that it can still reach x through z with a total cost of 5+1=6.</li>
<li>At t1, we have a routing loop where z thinks it can reach x through y, and y thinks it can reach x through z. This will cause the packets to be bouncing back and forth between y and z until their tables change.</li>
<li>Nodes z and y keep updating each other about their new cost to reach x. For example, y computes its new cost to be 6 and then informs z. Then z computes its new cost to be 7, and then informs y, and so on.</li>
</ol>
<p>The key here is that Node Z, is saying Hey I can definitely reach X, and the cost as Z knows it, is 5. So Node Y says sweet, if I go through Node Z, it&rsquo;s the cost of our link (1) + the cost of Z &gt; X, but the cost of Z &gt; X isn&rsquo;t actually 5 anymore, it&rsquo;s 50.</p>
<p>So they have to iterate until the cost is greater than 50, at which point it will use the real path.</p>
<p>The reason that we can&rsquo;t directly say, &ldquo;hey no the link cost increased by a ton your table is wrong&rdquo; is because we don&rsquo;t know the structure of the network. All we know is X &gt; Y costs a certain value, with no understanding of which links do that.</p>
<p>So instead we have to keep iterating through until the costs are actually updated. This can create a lot of packet bouncing.</p>
<p>This is solved by something called <em>poison reverse</em> where a node says a cost is infinity if it isn&rsquo;t the cheapest path to a certain node. This only works for 2 nodes.</p>
<h4 id="routing-information-protocol-rip">Routing Information Protocol (RIP)<a hidden class="anchor" aria-hidden="true" href="#routing-information-protocol-rip">#</a></h4>
<p>RIP is based on Distance Vectors, but instead of maintaining vectors of distances, they instead maintain entire routing tables with one row for each subnet.</p>
<h4 id="open-shortest-path-first">Open Shortest Path First<a hidden class="anchor" aria-hidden="true" href="#open-shortest-path-first">#</a></h4>
<p>OSPF is a routing protocol that uses link-state to find the best path between source and destination routers. It was created after RIP by ISPs with extra things like authentication messages, multiple same-cost paths, and support for hierarchical routing within a single domain.</p>
<p>OSPF will have one AS (Autonomous System) as the backbone, and routes to other OSPF AS on the network. To go from one Area to another, they must move through the backbone router.</p>
<p>There&rsquo;s a lot more in the notes but tbh they&rsquo;re pretty complicated! It seems that these routers in the send Link State advertisements which communicates the routers local topology. This results in a complete network map, that updates when the network updates.</p>
<p>These LSAs are processed as so:</p>
<p><img alt="How the router processes" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-19%20at%207.18.54%20PM-2.png"></p>
<h3 id="hot-potato-routing">Hot Potato Routing<a hidden class="anchor" aria-hidden="true" href="#hot-potato-routing">#</a></h3>
<p>Sometimes you have to leave your local network, and enter into interdomain routing.</p>
<p>To do this usually you have to find an egress point and the process of finding that egress point is an intradomain routing problem.</p>
<p>Generally hot potato routing is referring to finding the closest/least costly egress point in a given network. The hot potato part of it is that there are many egress points and which one is chosen is not always clear. This routing method of finding the shortest path does make things consistent instead of sometimes going to egress A and sometimes going to egress B.</p>
<h2 id="lesson-4---interdomain-routing-and-as-relationships">Lesson 4 - Interdomain Routing and AS Relationships<a hidden class="anchor" aria-hidden="true" href="#lesson-4---interdomain-routing-and-as-relationships">#</a></h2>
<p><a href="#lesson-3---intradomain-routing-the-network-layer">Lesson 3</a> focused on intradomain routing, but what about when we need to leave our domain?</p>
<p>The internet is an ecosystem of thousands if not millions of networks operated independently, but still connected to each other. This lesson we&rsquo;ll learn about BGP.</p>
<h3 id="the-internet">The Internet<a hidden class="anchor" aria-hidden="true" href="#the-internet">#</a></h3>
<p><img alt="Internet Ecosystem" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.09.27%20PM.png"></p>
<p>The internet started very hierarchical but has been flattening as more IXPs and CDNs have been added.</p>
<p>Each of the types of infrastructure above can be an Autonomous System (AS) which is a group of routers who are under the same authority. I think like, my house technically is an AS that I manage, but not sure about that.</p>
<p>Routing between AS&rsquo;s relies on Border Gateway Protocol (BGP) to exchange information with each other.</p>
<h3 id="as-ecosystem">AS Ecosystem<a hidden class="anchor" aria-hidden="true" href="#as-ecosystem">#</a></h3>
<p>There&rsquo;s two main interactions between AS&rsquo;s.</p>
<ul>
<li>Provider-Customer - Like me paying my ISP for internet</li>
<li>Peer - One ISP routing to another ISP because they need their network to get to location x. This requires traffic levels to be pretty similar so that one party isn&rsquo;t gaining more than the other.</li>
</ul>
<p><img alt="isp map" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L4%20Diagram%20Recreations%20Updated%20Ben-1.png"></p>
<p>See how green cloud ISP can&rsquo;t peer with orange cloud ISPs, because it&rsquo;s too large. But all the orange cloud ISPs are peer relationships because they&rsquo;re similarly sized.</p>
<p>Providers can charge fixed rate or based on usage, totally up to them.</p>
<h3 id="internet-business">Internet Business<a hidden class="anchor" aria-hidden="true" href="#internet-business">#</a></h3>
<p>Importing and Exporting routes is the heart of BGP. Deciding which import/exports to operate and make available is a technical and business decision.</p>
<h4 id="exporting-routes">Exporting Routes<a hidden class="anchor" aria-hidden="true" href="#exporting-routes">#</a></h4>
<p>Export routes come from:</p>
<ul>
<li>Routes from customers</li>
<li>Routes from providers</li>
<li>Routes from peers</li>
</ul>
<p>Which of these are chosen to advertise to other AS&rsquo;s is a business decision.</p>
<h4 id="importing-routes">Importing Routes<a hidden class="anchor" aria-hidden="true" href="#importing-routes">#</a></h4>
<p>Again, they&rsquo;re picky based on which routes are going to bring the most value to the business.</p>
<p>Usually it&rsquo;s this order:</p>
<ol>
<li>An AS wants to ensure that routes toward its customers do not traverse other ASes, unnecessarily generating costs.</li>
<li>An AS uses routes learned from peers since these are usually &ldquo;free&rdquo; (under the peering agreement).</li>
<li>An AS resorts to importing routes learned from providers only when necessary for connectivity since these will add to costs.</li>
</ol>
<h3 id="border-gateway-protocol-bgp">Border Gateway Protocol (BGP)<a hidden class="anchor" aria-hidden="true" href="#border-gateway-protocol-bgp">#</a></h3>
<h4 id="bgp-design-goals">BGP Design Goals<a hidden class="anchor" aria-hidden="true" href="#bgp-design-goals">#</a></h4>
<ul>
<li>Scalability - The internet will never stop growing, try to handle it</li>
<li>Express routing policies (ERP) - Allows ASes to make routing decisions and do it privately</li>
<li>Allow cooperation among ASes - Allows ASes to make their own decision and let business drive the connections</li>
<li>Security - This was added on as it was found to be necessary</li>
</ul>
<h4 id="bgp-basics">BGP Basics<a hidden class="anchor" aria-hidden="true" href="#bgp-basics">#</a></h4>
<p><strong>BGP Peers</strong> send messages over <strong>BGP Sessions</strong> over a semi-permanent TCP port connection. A session is initiated from one router to another with an OPEN message which is then followed by sharing routing tables.</p>
<p>eBGP is an external BGP session, between two ASes. iBGP is an internal BGP session, in a singular AS.</p>
<p><img alt="eBGP and iBGP" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.28.06%20PM.png"></p>
<p>Once the session is started they use:</p>
<ul>
<li>UPDATE - if any updates are made to the Route table, share it</li>
<li>KEEPALIVE - Keeps session going, no changes</li>
</ul>
<p>BGP relies on prefix reachability, a list of IP addresses that prefix all the destinations. This is how the export and import routes are communicated.</p>
<p>Other parameters:</p>
<p><strong>Path Attributes</strong> are also shared with other providers with parameters like:</p>
<ul>
<li>ASPATH - Contains Autonomous System Number and helps choose between multiple routes and stops loops</li>
<li>NEXT HOP - Provides the next router&rsquo;s IP address so that other routers can store in their forwarding table the best path</li>
</ul>
<h4 id="ibgp-vs-ebgp">iBGP vs eBGP<a hidden class="anchor" aria-hidden="true" href="#ibgp-vs-ebgp">#</a></h4>
<p>iBGP is meant for sharing paths of how to get out of an AS, it&rsquo;s not an IGP that gives intradomain networking, but instead a way of telling nodes inside of AS how they can communicate with external ASes.</p>
<p>eBGP is the method of communicating between ASes the available external routes.</p>
<p><img alt="ebgp vs abgp" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L4%20Diagram%20Recreations%20Updated%20Ben-3.png"></p>
<h4 id="bgp-router-process">BGP Router Process<a hidden class="anchor" aria-hidden="true" href="#bgp-router-process">#</a></h4>
<p><img alt="bgp routing" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.48.26%20PM.png"></p>
<p>When a router receives a new list of policies it takes them all in, and then has a decision making process to determine the best routes for it to use.</p>
<p>The operator of this router can determine what is important to them (usually cost related) and make decisions based on that. Here&rsquo;s an example decision process.</p>
<p><img alt="BGP router decision chart" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-01-17%20at%207.44.30%20PM.png"></p>
<p>Important decision makers are:</p>
<p>LocalPref - Decided by operating AS, things like choose the cheaper route (customers first, then peers, etc)
MED - Determined by the neighboring AS, determine which link they would prefer you to use</p>
<h4 id="bgp-issues">BGP Issues<a hidden class="anchor" aria-hidden="true" href="#bgp-issues">#</a></h4>
<p>Two main things:</p>
<ul>
<li>Misconfiguration - Improper configuration can bring networks down for a lot of reasons
<ul>
<li>Can be reduced by limiting size of tables and number of changes</li>
</ul>
</li>
<li>Scalability - Large routing tables are problematic.</li>
</ul>
<p>A lot of work went into reducing routing table sizes. They will do things like use default routing, route aggregation, and something called <strong>flap damping</strong>. Flap damping is a technique that limits the number of updates to a given prefix over time. If it goes over a certain limit, it will silence that prefix&rsquo;s updates until a set time has passed.</p>
<p>This is configurable by domain, allowing you to choose when and where you will accept a lot of updates and when you won&rsquo;t.</p>
<h3 id="peering-at-ixps">Peering at IXPs<a hidden class="anchor" aria-hidden="true" href="#peering-at-ixps">#</a></h3>
<p>ASes peer with each other, where do they do that? One place is an Internet Exchange Point (IXP). They are purpose built infrastructure to facilitate peering.</p>
<p>Internet Exchange Points (IXPs) are critical physical infrastructures where Autonomous Systems (ASes) can directly interconnect and exchange traffic. These facilities are typically housed in secure, well-powered data centers and consist of robust switch fabrics to ensure reliability and fault tolerance. ASes participating in IXPs must have a public ASN, a BGP-capable router, and agree to the IXP’s terms. Once connected, ASes can publicly peer and exchange traffic settlement-free, paying only for connection and port usage, not traffic volume. This makes IXPs more cost-effective and efficient than traditional third-party traffic routing.</p>
<p>IXPs have grown in popularity due to their ability to handle massive volumes of traffic and play a crucial role in improving network performance and reducing costs by keeping local traffic local. They also offer defensive benefits, such as DDoS mitigation, since they observe a large portion of Internet traffic and can help stop malicious activity before it reaches the intended target. Furthermore, IXPs provide a rich environment for research and innovation, particularly in areas like security and Software Defined Networking (SDN), and are evolving into hubs of technology development beyond just traffic exchange.</p>
<p>In addition to public and private peering services, IXPs offer a wide range of features such as route servers, SLAs, remote peering via resellers, mobile network peering, and DDoS blackholing. Some IXPs also provide free value-added services like DNS root servers and time distribution. These offerings, along with the ability to form fast and scalable peering agreements, have made IXPs essential infrastructure for global Internet connectivity, performance, and resilience.</p>
<h4 id="route-servers">Route Servers<a hidden class="anchor" aria-hidden="true" href="#route-servers">#</a></h4>
<p>IXPs use route servers to handle the large number of ASes that they service.</p>
<p>In summary, a Route Server (RS) does the following:</p>
<ul>
<li>It collects and shares routing information from its peers or participants of the IXP that connect to the RS.</li>
<li>It executes its own BGP decision process and re-advertises the resulting information (e.g., best route selection) to all RS&rsquo;s peer routers.</li>
</ul>
<p>It&rsquo;s basically offloading all the configuration work from the AS to the IXP operator. It&rsquo;s what allows people like me to buy a domain and get reliable routing from anywhere in the world to it.</p>
<h2 id="lesson-5-and-6---router-design-and-algorithms">Lesson 5 and 6 - Router Design and Algorithms<a hidden class="anchor" aria-hidden="true" href="#lesson-5-and-6---router-design-and-algorithms">#</a></h2>
<p>Routers are what do the heavy lifting for actually moving data from one point to another. The prior lessons established many pieces and parts of that puzzle.</p>
<p>In short, a router needs to be able to receive an incoming packet on an input link, read its destination, and then send it to the correct output link. Simple in theory, difficult in practice, and more importantly, at scale. Then add on top of just forwarding requirements things like security requirements, quality of service, and other more advanced things, the job becomes difficult.</p>
<h3 id="router-components">Router Components<a hidden class="anchor" aria-hidden="true" href="#router-components">#</a></h3>
<p><strong>The main job of a router is to implement the forwarding plane functions and the control plane functions.</strong></p>
<h4 id="forwarding-switching-function">Forwarding (Switching) function<a hidden class="anchor" aria-hidden="true" href="#forwarding-switching-function">#</a></h4>
<p>The action of transferring a packet from an incoming link, to an outbound link. This should be very fast, on the scale of a few nanoseconds. I believe this is what a nice simple 5 port network switch is, and that&rsquo;s all it is.</p>
<p><img alt="what&rsquo;s in a router" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-2.png"></p>
<p><img alt="what&rsquo;s in a router zoomed" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-3.png"></p>
<p><strong>Input Ports</strong></p>
<p>Input ports do the following:</p>
<ol>
<li>Physically terminate the link</li>
<li>Processes datalink (decapsulating)</li>
<li>Performs lookup function, consulting forwarding table to determine where it should go</li>
</ol>
<p><strong>Switching Fabric</strong>*</p>
<p>This actually moves the packet from the input port, to the output port, using the results from the input port that tells where the packet needs to go.</p>
<p>Three types of switching fabrics:</p>
<ul>
<li>Memory</li>
<li>Bus</li>
<li>Crossbar</li>
</ul>
<p><strong>Output ports</strong></p>
<p>All this does is receive the data from the switching fabric and send it. Specifically:</p>
<ol>
<li>Queue the packets for transfer</li>
<li>Encapsulate the packets</li>
<li>Send them over the physical output port</li>
</ol>
<p><img alt="output port" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-4-1.png"></p>
<h4 id="control-plane-function">Control Plane function<a hidden class="anchor" aria-hidden="true" href="#control-plane-function">#</a></h4>
<p>The control plane refers to:</p>
<ul>
<li>Implementing routing protocols (like the ones from earlier sessions)</li>
<li>Maintaining routing tables</li>
<li>Computing the forwarding table</li>
</ul>
<p>All of these functions are written software in the routing processor, or in the case of an SDN, could be implemented by a remote router.</p>
<p><img alt="alt text" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-5.png"></p>
<h3 id="router-architecture">Router Architecture<a hidden class="anchor" aria-hidden="true" href="#router-architecture">#</a></h3>
<p>Model of a router:</p>
<p><img alt="router architecture overview" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.00.52%20PM.png"></p>
<p>Using the image as a guide we can walk through the path that common tasks take. First we lookup the destination of an incoming packet.</p>
<ol>
<li>Lookup
<ol>
<li>Packet arrives at input link</li>
<li>Lookup output link in forwarding table (Forwarding Information Base FIB)</li>
<li>Resolve any ambiguities
<ul>
<li>Longest Prefix matching</li>
<li>Packet classification</li>
</ul>
</li>
</ol>
</li>
<li>Switching
<ul>
<li>After lookup is completed the packet is switched, from input link to output link. Modern routers use crossbar switches for this task.</li>
<li><em>Some complications occur when many inputs want to send to the same output</em></li>
</ul>
</li>
<li>Queuing
<ul>
<li>
<p>Using various queuing logics, if an output port is congested, each packet enters the queue to wait its turn to use the hardware.</p>
</li>
<li>
<p>Types of queues used:</p>
<ul>
<li>First In First Out (FIFO)</li>
<li>Weighted Fair Queuing</li>
</ul>
</li>
</ul>
</li>
<li>Header Validation and Checksum
<ul>
<li>Check version number, validate checksum, decrement ttl</li>
</ul>
</li>
<li>Route processing
<ul>
<li>Build route using protocols like RIP, OSPF, and BGP</li>
</ul>
</li>
<li>Protocol Processing (Including:)
<ul>
<li>Simple Network Management Protocol (SNMP) - Counters for remote inspection</li>
<li>TCP/UDP for remote communication</li>
<li>Internet Control Message Protocol (ICMP) for sending error messages (eg: TTL is exceeded)</li>
</ul>
</li>
</ol>
<h3 id="switching-fabric">Switching Fabric<a hidden class="anchor" aria-hidden="true" href="#switching-fabric">#</a></h3>
<p>The switching fabric is where most of the logic is implemented in a router, forwarding packets from source to destination.</p>
<p>There are several ways to accomplish this.</p>
<h4 id="switching-via-memory">Switching via memory<a hidden class="anchor" aria-hidden="true" href="#switching-via-memory">#</a></h4>
<p>Physical I/O ports operate as I/O devices in an operating system.</p>
<ol>
<li>Input port receives packet</li>
<li>Send interrupt to routing processor</li>
<li>Packet written to memory</li>
<li>Processor looks at header to get destination address</li>
<li>Lookup output port from forwarding table</li>
<li>Copy from memory into output ports buffer</li>
</ol>
<p><img alt="switching via memory diagram" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.08.02%20PM-1.png"></p>
<h4 id="switching-via-bus">Switching via bus<a hidden class="anchor" aria-hidden="true" href="#switching-via-bus">#</a></h4>
<p>Bus based switching doesn&rsquo;t require a processor.</p>
<ol>
<li>Input port receives packet</li>
<li>Input port marks which destination port it should be for with an internal header</li>
<li>Send it to the bus where all output ports receive the packet
<ul>
<li>Only the port it&rsquo;s supposed to go to accepts it</li>
</ul>
</li>
</ol>
<p>This design is limited by the speed of the bus as only one packet can traverse it at a time.</p>
<p><img alt="switching via bus diagram" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.09.47%20PM.png"></p>
<h4 id="switching-via-interconnection-network">Switching via interconnection network<a hidden class="anchor" aria-hidden="true" href="#switching-via-interconnection-network">#</a></h4>
<p>A crossbar switch is an interconnection network that connects N inputs to N outputs using 2N buses.</p>
<p><img alt="crossbar network diagram" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Crossbar%20Network.png"></p>
<p>This allows many packets at once to traverse the switching fabric, as long as they have different input and output ports. This is done by giving the switching fabric control of the buses, and closing the connections to make the links only when there is a packet that needs to make that journey.</p>
<h3 id="router-challenges">Router Challenges<a hidden class="anchor" aria-hidden="true" href="#router-challenges">#</a></h3>
<p>There are a couple fundamental challenges to overcome for routers at scale.</p>
<ol>
<li>Bandwidth and Internet population scaling
<ul>
<li>Rapidly increasing number of devices (endpoints)</li>
<li>Rapidly increasing volume of data</li>
<li>New types of links like optical links (fiber) which increase transfer but increase complexity</li>
</ul>
</li>
<li>Services at high speeds</li>
</ol>
<h4 id="common-bottlenecks">Common bottlenecks<a hidden class="anchor" aria-hidden="true" href="#common-bottlenecks">#</a></h4>
<p><img alt="common bottlenecks table" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.15.27%20PM.png"></p>
<p>A little bit more detail:</p>
<p><strong>Longest prefix matching</strong> - Due to the ever increasing number of devices on the internet, it&rsquo;s impossible to hold a table for <em>all</em> of them. So instead devices are grouped into prefixes. But then you need good algorithms to deal with the prefixes.</p>
<p><strong>Service differentiation</strong> - If you want to be able to provide priority to some packets and not to others, you need more complex logic to handle that. At scale.</p>
<p><strong>Switching Limitations</strong> - At high speeds, the hardware can become a problem, causing bottlenecks at the I/O ports or even on the switching hardware.</p>
<p><strong>Bottlenecks about services</strong> - Providing a reliable, fast, secure service that is <strong>guaranteed</strong> is difficult. Entire companies are built around doing this so that others don&rsquo;t have to.</p>
<h3 id="prefix-matching">Prefix matching<a hidden class="anchor" aria-hidden="true" href="#prefix-matching">#</a></h3>
<p>Prefixing is a way to group endpoints together to make lookup tables less large.</p>
<p><strong>Prefix Notation:</strong></p>
<p>There are several ways to notate prefixes.</p>
<ol>
<li>Dot decimal
<ul>
<li>16 bit (132.234) becomes binary of 1000010011101010</li>
</ul>
</li>
<li>Slash notation
<ul>
<li>A/L, A=Address, L=Length</li>
<li>132.238.0.0/16</li>
</ul>
</li>
<li>Masking
<ul>
<li>123.234.0.0/16 is written as 123.234.0.0 with a mask 255.255.0.0</li>
<li>The mask 255.255.0.0 denotes that only the first 16 bits are important.</li>
</ul>
</li>
</ol>
<p>This prefixing helped, because we were running out of IP addresses, quickly. But it introduced the issue of <em>longest matching prefix lookup</em>.</p>
<p>The main router performance metric is how quickly it can do a full lookup. There are four common problem areas:</p>
<ol>
<li>A large amount of traffic is concurrent flows of short duration, making caching not very useful.</li>
<li>Lookup speed is important, the most costly part of that is accessing memory</li>
<li>An unstable routing protocol may result in more updates to the table and slower updates, adding milliseconds of time to the table update time.</li>
<li>Cost vs performance, really expensive memory is fast, cheaper memory is slower
<ul>
<li>how to decide which is which likely depends on application</li>
</ul>
</li>
</ol>
<p><img alt="common issues" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-7.png"></p>
<h4 id="unibit-tries">Unibit Tries<a hidden class="anchor" aria-hidden="true" href="#unibit-tries">#</a></h4>
<p>Given this prefix db:</p>
<p><img alt="unibit db" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20Diagram%20Recreations%20Ben%20updated-1.png"></p>
<p>Results in this trie:</p>
<p><img alt="unibit trie" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20Diagram%20Recreations%20Ben%20updated-2.png"></p>
<p>These are the steps we follow to perform a prefix match:</p>
<ol>
<li>We begin the search for a longest prefix match by tracing the trie path.</li>
<li>We continue the search until we fail (no match or an empty pointer)</li>
<li>When our search fails, the last known successful prefix traced in the path is our match and our returned value.</li>
</ol>
<p>Two notes:</p>
<ol>
<li>
<p>If a prefix is a substring of another prefix, the smaller string is stored in the path to the longer (more specific prefix). For example, P4 = 1<em>is a substring of P2 = 111</em>, and thus P4 is stored inside a node towards the path to P2.</p>
</li>
<li>
<p>One-way branches. There may be nodes that only contain one pointer. For example, let’s consider the prefix P3 = 11001. After we match 110 we will be expecting to match 01. But in our prefix database, we don’t have any prefixes that share more than the first 3 bits with P3. So if we had such nodes represented in our trie, we would have nodes with only one pointer. The nodes with only one pointer each are called one-way branches. For efficiency, we compress these one-way branches to a single text string with 2 bits (shown as node P9).</p>
</li>
</ol>
<h4 id="multibit-tries">Multibit Tries<a hidden class="anchor" aria-hidden="true" href="#multibit-tries">#</a></h4>
<p>Unibit tries are very efficient but it requires a large amount of memory accesses to achieve. For highspeed links it is not plausible to access memory that many times. Instead we use strides. A stride is the number of bits to check at each step.</p>
<p>So an alternative to unibit tries are the multibit tries. A multibit trie is a trie where each node has 2k  children, where k is the stride. Next, we will see that we can have two flavors of multibit tries: fixed-length stride tries and variable-length stride tries.</p>
<h5 id="prefix-expansion">Prefix expansion<a hidden class="anchor" aria-hidden="true" href="#prefix-expansion">#</a></h5>
<p>One quick problem you may run into with multibit, is if you have a stride length of 2, you could miss prefixes like 101* so this is handled via expansion:</p>
<p><img alt="prefix expansion table" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-9.png"></p>
<h4 id="fixed-stride-example">Fixed Stride Example<a hidden class="anchor" aria-hidden="true" href="#fixed-stride-example">#</a></h4>
<p>Using a fixed stride length of three, let&rsquo;s do an example. Using the same database as the prior example.</p>
<p>Some key points to note here:</p>
<ol>
<li>Every element in a trie represents two pieces of information: a pointer and a prefix value.</li>
<li>The prefix search moves ahead with the preset length in n-bits (3 in this case)</li>
<li>When the path is traced by a pointer, we remember the last matched prefix (if any).</li>
<li>Our search ends when an empty pointer is met. At that time, we return the last matched prefix as our final prefix match.</li>
</ol>
<p><img alt="routing image fixed stride length" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-8%20Fixed%20Stride.jpg"></p>
<h4 id="variable-stride-length">Variable Stride Length<a hidden class="anchor" aria-hidden="true" href="#variable-stride-length">#</a></h4>
<p>Variable Stride length allows us to save memory and still get all of the addresses.</p>
<p><img alt="variable example image" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-9%20Variable%20Stride.jpg"></p>
<p>Some key points about variable stride:</p>
<ol>
<li>Every node can have a different number of bits to be explored.</li>
<li>The optimizations to the stride length for each node are all done to save trie memory and the least memory accesses.</li>
<li>An optimum variable stride is selected by using dynamic programming</li>
</ol>
<h3 id="packet-classification">Packet Classification<a hidden class="anchor" aria-hidden="true" href="#packet-classification">#</a></h3>
<p>We&rsquo;ve talked aout prefix matching and how it attempts to solve the issue of an ever growing internet with many devices and many ip addresses.</p>
<p>What it doesn&rsquo;t do is provide advanced features like paying attention to source addresses, tcp flags, etc.</p>
<p>Packet classification tackles those challenges.</p>
<p>Common examples:</p>
<ol>
<li>Firewalls - Routers implement firewalls to filter inbound and outbound traffic based on a pre-determined set of policies.</li>
<li>Resource Reservation Protocols - To reserve bandwidth between a source and destination</li>
<li>Routing based on traffic type - If a certain type of traffic is more time sensitive, move it to the front of the queue</li>
</ol>
<p><img alt="example advanced routing" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.20.46%20PM.png"></p>
<h4 id="simple-classifiers">Simple Classifiers<a hidden class="anchor" aria-hidden="true" href="#simple-classifiers">#</a></h4>
<ul>
<li>Linear Search - Perform a search through a rules database for every packet, works fine for simple rules, struggles at large amounts of rules</li>
<li>Caching - Caching is usefule but has issues
<ul>
<li>Even an 80-90% cache rate still results in many searches</li>
<li>A 90% cache rate still has ~0.1 milliseconds of search, which is pretty slow in this context</li>
</ul>
</li>
<li>Passing Labels - Setup &ldquo;Label Switched Paths&rdquo; between sites,
<ul>
<li>Multiprotocol Label Switching (MPLS) and DiffServ use this</li>
<li>MPLS: router A does classification, and then all intermediate routers just read it and use it, instead of doing their own classification</li>
<li>DiffServ: Applies special markers at the edges to mark a packet for special quality-of-service</li>
</ul>
</li>
</ul>
<h4 id="fast-searching---using-set-pruning-tries">Fast Searching - Using Set Pruning Tries<a hidden class="anchor" aria-hidden="true" href="#fast-searching---using-set-pruning-tries">#</a></h4>
<p>Assume a two dimensional rule that only cares about source and destination IPs.</p>
<p><img alt="two dimensional rule table" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-11%20Example%20with%207%20Destination%20Source%20Rules.jpg"></p>
<p>We can build a trie (similar to earlier in this section), where each leaf node is another trie</p>
<p><img alt="trie graph" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-12%20Packet%20Classification.jpg"></p>
<blockquote>
<p>By S1, we denote the source prefix of rule R1, S2 of rule R2, etc. Thus for every destination prefix D in the destination trie, we &ldquo;prune&rdquo; the set of rules to those compatible with D.
We first match the destination IP address in a packet in the destination trie. Then we traverse the corresponding source trie to find the longest prefix match for the source IP. The algorithm keeps track of the lowest-cost matching rule. Finally, the algorithm concludes with the least-cost rule.
Challenge: The problem that we need to solve now is which source prefixes to store at the sources tries? For example, let&rsquo;s consider the destination D = 00*. Both rules R4 and R5 have D as the destination prefix. So the source tries for D will need to include the source prefixes 1* and 11*.
But if we restrict to 1* and 11*, this is not sufficient. Because the prefix 0*, also matches 00*,  and it is found in rules R1, R2, R3, R7. So we will need to include all the corresponding source prefixes.
Moving forward, the problem with the set pruning tries is memory explosion. Because a source prefix can occur in multiple destination tries.</p></blockquote>
<h4 id="reducing-memory-using-backtracking">Reducing Memory Using Backtracking<a hidden class="anchor" aria-hidden="true" href="#reducing-memory-using-backtracking">#</a></h4>
<p>Set pruning has a high cost in memory to reduce time. So we can trade memory for time and try to solve this problem.</p>
<p>From the lecture:</p>
<blockquote>
<p>The set pruning approach has a high cost in memory to reduce time.
The opposite approach is to pay in time to reduce memory.
Let&rsquo;s assume a destination prefix D. The backtracking approach has each destination prefix D point to a source trie that stores the rules whose destination field is exactly D. The search algorithm then performs a &ldquo;backtracking&rdquo; search on the source tries associated with all ancestors of D.
So first, the algorithm goes through the destination trie and finds the longest destination prefix D matching the header. Then it works its way back up the destination trie and searches the source trie associated with every ancestor prefix of D that points to a nonempty source trie.
Since each rule is stored exactly once, the memory requirements are lower than the previous scheme. But, the lookup cost for backtracking is worse than for set-pruning tries.</p></blockquote>
<h4 id="grid-of-tries">Grid of Tries<a hidden class="anchor" aria-hidden="true" href="#grid-of-tries">#</a></h4>
<p>We&rsquo;ve tried Backtracking (high time lower memory), and set pruning (memory explosion). Both fail for their own reasons.</p>
<p>Grid of tries approach takes backtracking and reduces wasted time by precomputing. When backtracking if there is a failure point in the source trie, we have a &ldquo;switch pointer&rdquo; which takes you directly to the next possible source trie containing a matching rule.</p>
<p><img alt="trie network" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.24.35%20PM.png"></p>
<p>At places where there may be a failure to get to a matching rule, we can go directly to the next most likely place to find a rule, with precomputed switch pointers.</p>
<p><img alt="trie network with switch pointers" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.25.59%20PM.png"></p>
<h3 id="scheduling">Scheduling<a hidden class="anchor" aria-hidden="true" href="#scheduling">#</a></h3>
<p>Now we talk about scheduling. Given a N-by-N crossbar switch with N input lines, N output lines, and N2 crosspoint we need to ensure that each input link is only connected to one output link at any given time <em>and</em> we want to maximize throughput by having the as many parallel routes open at one time as possible.</p>
<h4 id="take-a-ticket-algorithm">Take a Ticket Algorithm<a hidden class="anchor" aria-hidden="true" href="#take-a-ticket-algorithm">#</a></h4>
<p>Every output link has a queue, when an input link would like to use that queue it gets a ticket, and waits until it is called to send its packet and the route is opened.</p>
<p>Round 1:</p>
<p><img alt="take a ticket graph" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6%20take_a_ticket_1.png"></p>
<p>Round 2:</p>
<p><img alt="take a ticket round 2" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6%20take_a_ticket_2.png"></p>
<p>Round 3:
<img alt="take a ticket round 3" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6%20take_a_ticket_3.jpg"></p>
<p>and here is an overview of how this all plays out:</p>
<p><img alt="overview of take a ticket" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.33.12%20PM.png"></p>
<p>One thing to note here is that all of the other messages that are going to other nodes are blocked by the fact that they all wanted to go to output 1 first. This is &ldquo;Head of line&rdquo; blocking caused by take a ticket.</p>
<h4 id="avoiding-head-of-line-with-take-a-ticket">Avoiding Head of Line with Take a Ticket<a hidden class="anchor" aria-hidden="true" href="#avoiding-head-of-line-with-take-a-ticket">#</a></h4>
<h4 id="output-queuing">Output Queuing<a hidden class="anchor" aria-hidden="true" href="#output-queuing">#</a></h4>
<p>Given an N-by-N crossbar switch can we try to send to an output link without queuing? Then it would only need to block packets which are headed for the same destination. To do this the fabric must run N times faster than the input links.</p>
<p>A practical approach to this is the knockout scheme. It breaks up packets into fixed sizes k (which is smaller than N). Then if the fabric needs to only run k times as fast as an input link instead of N.</p>
<p>In some cases this can be broken and there are primitive switching rules to handle this.</p>
<ul>
<li>k = 1 and N = 2. Randomly pick the output that is chosen. The switching element, in this case, is called a concentrator.</li>
<li>k = 1 and N &gt; 2. One output is chosen out of N possible outputs. We can use the same strategy of multiple 2-by-2 concentrators in this case.</li>
<li>k needs to be chosen out of N possible cells, with k and N arbitrary values. We create k knockout trees to calculate the first k winners.</li>
</ul>
<p>The drawback of this approach is it is complex to implement.</p>
<h4 id="parallel-iterative-matching">Parallel Iterative Matching<a hidden class="anchor" aria-hidden="true" href="#parallel-iterative-matching">#</a></h4>
<p>This approach still allows queuing but in a way that avoids head-of-line blocking. It starts with taking each incoming link&rsquo;s queue and breaking it into virtual queues for each output link.</p>
<p><img alt="iterative queue 1" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.41.14%20PM.png"></p>
<p><img alt="interative queue 2" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.42.38%20PM.png"></p>
<p><img alt="iterative queue 3" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.43.46%20PM.png"></p>
<p>If an input receives multiple grants, it randomly picks between the two. This allows more packets to attempt to go through more quickly at the same time, and is more efficient than take-a-ticket.</p>
<h4 id="scheduling-intro">Scheduling Intro<a hidden class="anchor" aria-hidden="true" href="#scheduling-intro">#</a></h4>
<p>Busy routers rely on scheduling for routing updates, management queries, and data packets. Since linkspeeds are climbing over 40 gigabit, this needs to be done <strong>very</strong> quickly.</p>
<h5 id="fifo-with-tail-drop">FIFO with tail drop<a hidden class="anchor" aria-hidden="true" href="#fifo-with-tail-drop">#</a></h5>
<p>This is a simple first in first out queue, but if the queue is larger than its limit, the packets at the &ldquo;tail&rdquo; are dropped off.</p>
<h5 id="quality-of-service">Quality of Service<a hidden class="anchor" aria-hidden="true" href="#quality-of-service">#</a></h5>
<p>The FIFO approach has pretty bad quality of service with not guaranteed delivery due to dropping packets in the tail.</p>
<p>This is bad for the following reasons:</p>
<h6 id="router-support-for-congestion">Router support for congestion<a hidden class="anchor" aria-hidden="true" href="#router-support-for-congestion">#</a></h6>
<p>Congestion in the internet is increasingly possible as the usage has increased faster than the link speeds. While most traffic is based on TCP (which has its own ways to handle congestion), additional router support can improve the throughput of sources by helping handle congestion.</p>
<h6 id="providing-qos-guarantees-to-flows">Providing QoS guarantees to flows<a hidden class="anchor" aria-hidden="true" href="#providing-qos-guarantees-to-flows">#</a></h6>
<p>During periods of backup, these packets tend to flood the buffers at an output link. If we use FIFO with tail drop, this blocks other flows, resulting in important connections on the clients’ end freezing. This provides a sub-optimal experience to the user, indicating a change is necessary!</p>
<h6 id="fair-sharing-of-links-among-competing-flows">Fair sharing of links among competing flows<a hidden class="anchor" aria-hidden="true" href="#fair-sharing-of-links-among-competing-flows">#</a></h6>
<p>One way to enable fair sharing is to guarantee certain bandwidths to a flow. Another way is to guarantee the delay through a router for a flow. This is noticeably important for video flows – without a bound on delays, live video streaming will not work well.</p>
<h4 id="bit-by-bit-round-robin">Bit by Bit Round Robin<a hidden class="anchor" aria-hidden="true" href="#bit-by-bit-round-robin">#</a></h4>
<p>FIFO might drop packets. So we can use round robin to fix that. Pure round robin struggles though if one link has different packet sizes than the other, which might result in one link getting better service than the other.</p>
<p>Bit by Bit fixes this. The idea is that even though we can&rsquo;t split packets up bit by bit, we can kind of do it virtually to help inform scheduling decisions. Using a lot of fancy math we can determine the round in which a packet finishes sending.</p>
<p>The Bit by Bit round robin then works by sending the packet which has the smallest finishing round number. Consider the following example:</p>
<p><img alt="round robin bit by bit queue" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-13.png"></p>
<p>F is their finishing number, in their respective queues.</p>
<p><img alt="round robin bit by  bit rnd 2" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-14.png"></p>
<p>We can see F=1002 is sent first, because it had the earliers round finishing number. It was the &ldquo;most starved&rdquo; packet during the prior scheduling round.</p>
<p><img alt="rnd 3" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-15.png"></p>
<p><img alt="rnd 4" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5%20&%20L6%20updated%20Mary%20Ben%20reviewed-16.png"></p>
<p>This is fair, but introduces new complexities. Specifically maintaining a priority queue becomes very expensive, and takes a long time, which isn&rsquo;t feasible at gigabit speeds.</p>
<h4 id="deficit-round-robin">Deficit Round Robin<a hidden class="anchor" aria-hidden="true" href="#deficit-round-robin">#</a></h4>
<p>Round robin guaranteed delay and bandwidth fairness, but many applications only care aobut bandwidth fairness. So a simple constant-time round robin could get that done much more simply.</p>
<blockquote>
<p>We assign a quantum size, Qi, and a deficit counter, Di, for each flow. The quantum size determines the share of bandwidth allocated to that flow. For each turn of round-robin, the algorithm will serve as many packets in the flow i with size less than (Qi + Di). If packets remain in the queue, it will store the remaining bandwidth in Di for the next run. However, if all packets in the queue are serviced in that turn, it will clear Di to 0 for the next turn.</p></blockquote>
<p>Consider the following:</p>
<p><img alt="deficit 1" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-14%20Deficit%20Round%20robin.jpg"></p>
<p><img alt="deficit 2" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-15%20Deficit%20Round%20robin%202.jpg"></p>
<blockquote>
<p>In this router, there are four flows – F1, F2, F3, and F4. The quantum size for all flows is 500. Initially, the deficit counters for all flows are set to 0. Initially, the round-robin pointer points to the first flow. The first packet of size 200 will be sent through. However, the funds are insufficient to send the second packet of size 750. Thus, a deficit of 300 will remain in D1. For F2, the first packet of size 500 will be sent, leaving D2 empty.
Similarly, the first packets of F3 and F4 will be sent with D3 = 400 and D4 = 320 after the first iteration. For the second iteration, the D1+ Q1 = 800, meaning there are sufficient funds to send the second and third packets through. Since there are no remaining packets, D1 will be set to 0 instead of 30 (the actual remaining amount).</p></blockquote>
<h4 id="token-bucket">Token Bucket<a hidden class="anchor" aria-hidden="true" href="#token-bucket">#</a></h4>
<p>Sometimes we want to limit flows of certain data types without having to put them into another queue.</p>
<p>Token bucket shaping can accomplish this through things like limiting burstiness of flow by limiting the average rate, and limiting the burst maximum size allowed.</p>
<p><img alt="token bucket flow" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/Screen%20Shot%202020-02-05%20at%206.48.08%20PM.png"></p>
<p>If a packet comes and needs to hit the bucket, the bucket has to have enough available tokens, otherwise it fails. That&rsquo;s how you limit burst.</p>
<p>The problem with this is only one queue per flow. If a flow has a full token bucket it may block other flows. Token policing solves this.</p>
<h4 id="leaky-bucket-token-policing">Leaky Bucket (Token Policing)<a hidden class="anchor" aria-hidden="true" href="#leaky-bucket-token-policing">#</a></h4>
<p>Policing and shaping both help limit the output of a link but in different ways.</p>
<p><img alt="policing vs shaping" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-18%20Leaky%20Bucket.jpg"></p>
<ul>
<li>Policer: When the traffic rate reaches the maximum configured rate, excess traffic is dropped, or the packet&rsquo;s setting or &ldquo;marking&rdquo; is changed. The output rate appears as a saw-toothed wave.</li>
<li>Shaper: A shaper typically retains excess packets in a queue or a buffer, and this excess is scheduled for later transmission. The result is that excess traffic is delayed instead of dropped. Thus, the flow is shaped or smoothed when the data rate is higher than the configured rate. Traffic shaping and policing can work in tandem.</li>
</ul>
<p>Leaky bucket refers to the Token Bucket implementation with a constant output rate. If a packet were to make a bucket overflow it is discarded, but the same time things aren&rsquo;t sent in burst, but at a constant &ldquo;leak&rdquo; rate.</p>
<p><img alt="leaky bucket" loading="lazy" src="/codetrails/posts/4-computer-networks-notes/L5+6-19Leaky%20bucket%202.jpg"></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://nathanemb.github.io/codetrails/tags/school/">School</a></li>
      <li><a href="https://nathanemb.github.io/codetrails/tags/omscs/">OMSCS</a></li>
      <li><a href="https://nathanemb.github.io/codetrails/tags/computer-networks/">Computer Networks</a></li>
      <li><a href="https://nathanemb.github.io/codetrails/tags/notes/">Notes</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://nathanemb.github.io/codetrails/">Nathan Embaugh | codetrails</a></span>

</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
